Jan  9 22:37:57.829: INFO: Overriding default scale value of zero to 1
Jan  9 22:37:57.829: INFO: Overriding default milliseconds value of zero to 5000
I0109 22:37:58.275526      16 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-076648363
I0109 22:37:58.275629      16 e2e.go:304] Starting e2e run "3653f488-145f-11e9-a046-02505600000d" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1547073477 - Will randomize all specs
Will run 188 of 1814 specs

Jan  9 22:37:58.411: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 22:37:58.414: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jan  9 22:37:58.425: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan  9 22:37:58.448: INFO: 6 / 6 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan  9 22:37:58.448: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Jan  9 22:37:58.448: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jan  9 22:37:58.454: INFO: e2e test version: v1.12.1
Jan  9 22:37:58.455: INFO: kube-apiserver version: v1.12.4
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:37:58.455: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename downward-api
Jan  9 22:37:58.539: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Jan  9 22:37:58.556: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-vq9ft
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 22:37:58.680: INFO: Waiting up to 5m0s for pod "downwardapi-volume-36e1d2f5-145f-11e9-a046-02505600000d" in namespace "e2e-tests-downward-api-vq9ft" to be "success or failure"
Jan  9 22:37:58.685: INFO: Pod "downwardapi-volume-36e1d2f5-145f-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.647065ms
Jan  9 22:38:00.689: INFO: Pod "downwardapi-volume-36e1d2f5-145f-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008722537s
Jan  9 22:38:02.693: INFO: Pod "downwardapi-volume-36e1d2f5-145f-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012376357s
Jan  9 22:38:04.696: INFO: Pod "downwardapi-volume-36e1d2f5-145f-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015966297s
STEP: Saw pod success
Jan  9 22:38:04.696: INFO: Pod "downwardapi-volume-36e1d2f5-145f-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:38:04.699: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod downwardapi-volume-36e1d2f5-145f-11e9-a046-02505600000d container client-container: <nil>
STEP: delete the pod
Jan  9 22:38:04.735: INFO: Waiting for pod downwardapi-volume-36e1d2f5-145f-11e9-a046-02505600000d to disappear
Jan  9 22:38:04.741: INFO: Pod downwardapi-volume-36e1d2f5-145f-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:38:04.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vq9ft" for this suite.
Jan  9 22:38:10.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:38:10.865: INFO: namespace: e2e-tests-downward-api-vq9ft, resource: bindings, ignored listing per whitelist
Jan  9 22:38:10.873: INFO: namespace e2e-tests-downward-api-vq9ft deletion completed in 6.128543505s

• [SLOW TEST:12.417 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:38:10.874: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-btg2t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  9 22:38:11.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-btg2t'
Jan  9 22:38:11.835: INFO: stderr: ""
Jan  9 22:38:11.835: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Jan  9 22:38:11.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-btg2t'
Jan  9 22:38:15.051: INFO: stderr: ""
Jan  9 22:38:15.051: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:38:15.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-btg2t" for this suite.
Jan  9 22:38:21.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:38:21.127: INFO: namespace: e2e-tests-kubectl-btg2t, resource: bindings, ignored listing per whitelist
Jan  9 22:38:21.153: INFO: namespace e2e-tests-kubectl-btg2t deletion completed in 6.097939738s

• [SLOW TEST:10.279 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:38:21.153: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jb2ks
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 22:38:21.341: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4463cdeb-145f-11e9-a046-02505600000d" in namespace "e2e-tests-projected-jb2ks" to be "success or failure"
Jan  9 22:38:21.349: INFO: Pod "downwardapi-volume-4463cdeb-145f-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.589321ms
Jan  9 22:38:23.352: INFO: Pod "downwardapi-volume-4463cdeb-145f-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01087343s
Jan  9 22:38:25.356: INFO: Pod "downwardapi-volume-4463cdeb-145f-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015348518s
STEP: Saw pod success
Jan  9 22:38:25.357: INFO: Pod "downwardapi-volume-4463cdeb-145f-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:38:25.359: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod downwardapi-volume-4463cdeb-145f-11e9-a046-02505600000d container client-container: <nil>
STEP: delete the pod
Jan  9 22:38:25.392: INFO: Waiting for pod downwardapi-volume-4463cdeb-145f-11e9-a046-02505600000d to disappear
Jan  9 22:38:25.395: INFO: Pod downwardapi-volume-4463cdeb-145f-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:38:25.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jb2ks" for this suite.
Jan  9 22:38:31.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:38:31.448: INFO: namespace: e2e-tests-projected-jb2ks, resource: bindings, ignored listing per whitelist
Jan  9 22:38:31.488: INFO: namespace e2e-tests-projected-jb2ks deletion completed in 6.090255423s

• [SLOW TEST:10.335 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:38:31.489: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-jvghv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-g5xw
STEP: Creating a pod to test atomic-volume-subpath
Jan  9 22:38:31.703: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-g5xw" in namespace "e2e-tests-subpath-jvghv" to be "success or failure"
Jan  9 22:38:31.706: INFO: Pod "pod-subpath-test-projected-g5xw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.624748ms
Jan  9 22:38:33.711: INFO: Pod "pod-subpath-test-projected-g5xw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007752731s
Jan  9 22:38:35.715: INFO: Pod "pod-subpath-test-projected-g5xw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011851275s
Jan  9 22:38:37.718: INFO: Pod "pod-subpath-test-projected-g5xw": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014892999s
Jan  9 22:38:39.723: INFO: Pod "pod-subpath-test-projected-g5xw": Phase="Running", Reason="", readiness=false. Elapsed: 8.018999893s
Jan  9 22:38:41.726: INFO: Pod "pod-subpath-test-projected-g5xw": Phase="Running", Reason="", readiness=false. Elapsed: 10.022710381s
Jan  9 22:38:43.731: INFO: Pod "pod-subpath-test-projected-g5xw": Phase="Running", Reason="", readiness=false. Elapsed: 12.026898681s
Jan  9 22:38:45.734: INFO: Pod "pod-subpath-test-projected-g5xw": Phase="Running", Reason="", readiness=false. Elapsed: 14.030310474s
Jan  9 22:38:47.737: INFO: Pod "pod-subpath-test-projected-g5xw": Phase="Running", Reason="", readiness=false. Elapsed: 16.033749406s
Jan  9 22:38:49.742: INFO: Pod "pod-subpath-test-projected-g5xw": Phase="Running", Reason="", readiness=false. Elapsed: 18.037940085s
Jan  9 22:38:51.745: INFO: Pod "pod-subpath-test-projected-g5xw": Phase="Running", Reason="", readiness=false. Elapsed: 20.04142322s
Jan  9 22:38:53.749: INFO: Pod "pod-subpath-test-projected-g5xw": Phase="Running", Reason="", readiness=false. Elapsed: 22.045257477s
Jan  9 22:38:55.753: INFO: Pod "pod-subpath-test-projected-g5xw": Phase="Running", Reason="", readiness=false. Elapsed: 24.049102426s
Jan  9 22:38:57.758: INFO: Pod "pod-subpath-test-projected-g5xw": Phase="Running", Reason="", readiness=false. Elapsed: 26.054004505s
Jan  9 22:38:59.762: INFO: Pod "pod-subpath-test-projected-g5xw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.058155754s
STEP: Saw pod success
Jan  9 22:38:59.762: INFO: Pod "pod-subpath-test-projected-g5xw" satisfied condition "success or failure"
Jan  9 22:38:59.765: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-subpath-test-projected-g5xw container test-container-subpath-projected-g5xw: <nil>
STEP: delete the pod
Jan  9 22:38:59.806: INFO: Waiting for pod pod-subpath-test-projected-g5xw to disappear
Jan  9 22:38:59.809: INFO: Pod pod-subpath-test-projected-g5xw no longer exists
STEP: Deleting pod pod-subpath-test-projected-g5xw
Jan  9 22:38:59.809: INFO: Deleting pod "pod-subpath-test-projected-g5xw" in namespace "e2e-tests-subpath-jvghv"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:38:59.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-jvghv" for this suite.
Jan  9 22:39:05.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:39:05.890: INFO: namespace: e2e-tests-subpath-jvghv, resource: bindings, ignored listing per whitelist
Jan  9 22:39:05.911: INFO: namespace e2e-tests-subpath-jvghv deletion completed in 6.09407676s

• [SLOW TEST:34.422 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:39:05.912: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rtrt6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Jan  9 22:39:06.101: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-076648363 proxy --unix-socket=/tmp/kubectl-proxy-unix500833038/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:39:06.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rtrt6" for this suite.
Jan  9 22:39:12.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:39:12.264: INFO: namespace: e2e-tests-kubectl-rtrt6, resource: bindings, ignored listing per whitelist
Jan  9 22:39:12.305: INFO: namespace e2e-tests-kubectl-rtrt6 deletion completed in 6.09501718s

• [SLOW TEST:6.394 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:39:12.306: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-ksw4n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-ksw4n/secret-test-62e06670-145f-11e9-a046-02505600000d
STEP: Creating a pod to test consume secrets
Jan  9 22:39:12.495: INFO: Waiting up to 5m0s for pod "pod-configmaps-62e1992f-145f-11e9-a046-02505600000d" in namespace "e2e-tests-secrets-ksw4n" to be "success or failure"
Jan  9 22:39:12.498: INFO: Pod "pod-configmaps-62e1992f-145f-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.057694ms
Jan  9 22:39:14.503: INFO: Pod "pod-configmaps-62e1992f-145f-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00734478s
STEP: Saw pod success
Jan  9 22:39:14.503: INFO: Pod "pod-configmaps-62e1992f-145f-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:39:14.506: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-configmaps-62e1992f-145f-11e9-a046-02505600000d container env-test: <nil>
STEP: delete the pod
Jan  9 22:39:14.534: INFO: Waiting for pod pod-configmaps-62e1992f-145f-11e9-a046-02505600000d to disappear
Jan  9 22:39:14.535: INFO: Pod pod-configmaps-62e1992f-145f-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:39:14.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ksw4n" for this suite.
Jan  9 22:39:20.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:39:20.608: INFO: namespace: e2e-tests-secrets-ksw4n, resource: bindings, ignored listing per whitelist
Jan  9 22:39:20.640: INFO: namespace e2e-tests-secrets-ksw4n deletion completed in 6.101885859s

• [SLOW TEST:8.335 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:39:20.641: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-4zsm8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Jan  9 22:39:20.830: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-076648363 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:39:20.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4zsm8" for this suite.
Jan  9 22:39:26.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:39:26.952: INFO: namespace: e2e-tests-kubectl-4zsm8, resource: bindings, ignored listing per whitelist
Jan  9 22:39:27.029: INFO: namespace e2e-tests-kubectl-4zsm8 deletion completed in 6.098037164s

• [SLOW TEST:6.387 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:39:27.032: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jv2sh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-6baf6853-145f-11e9-a046-02505600000d
STEP: Creating a pod to test consume secrets
Jan  9 22:39:27.276: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6bb01134-145f-11e9-a046-02505600000d" in namespace "e2e-tests-projected-jv2sh" to be "success or failure"
Jan  9 22:39:27.289: INFO: Pod "pod-projected-secrets-6bb01134-145f-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.695912ms
Jan  9 22:39:29.292: INFO: Pod "pod-projected-secrets-6bb01134-145f-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01623977s
Jan  9 22:39:31.296: INFO: Pod "pod-projected-secrets-6bb01134-145f-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020055439s
STEP: Saw pod success
Jan  9 22:39:31.296: INFO: Pod "pod-projected-secrets-6bb01134-145f-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:39:31.299: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-projected-secrets-6bb01134-145f-11e9-a046-02505600000d container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan  9 22:39:31.325: INFO: Waiting for pod pod-projected-secrets-6bb01134-145f-11e9-a046-02505600000d to disappear
Jan  9 22:39:31.334: INFO: Pod pod-projected-secrets-6bb01134-145f-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:39:31.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jv2sh" for this suite.
Jan  9 22:39:37.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:39:37.360: INFO: namespace: e2e-tests-projected-jv2sh, resource: bindings, ignored listing per whitelist
Jan  9 22:39:37.478: INFO: namespace e2e-tests-projected-jv2sh deletion completed in 6.140224665s

• [SLOW TEST:10.447 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:39:37.479: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-xhkp6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan  9 22:39:37.669: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan  9 22:39:37.676: INFO: Waiting for terminating namespaces to be deleted...
Jan  9 22:39:37.678: INFO: 
Logging pods the kubelet thinks is on node 362e6945-cc10-4a7c-ad11-8cf4815006e1 before test
Jan  9 22:39:37.685: INFO: heapster-85647cf566-dbhkz from kube-system started at 2019-01-09 20:59:03 +0000 UTC (1 container statuses recorded)
Jan  9 22:39:37.686: INFO: 	Container heapster ready: true, restart count 0
Jan  9 22:39:37.686: INFO: kubernetes-dashboard-5f4b59b97f-jtrxq from kube-system started at 2019-01-09 20:59:08 +0000 UTC (1 container statuses recorded)
Jan  9 22:39:37.686: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jan  9 22:39:37.686: INFO: fluent-bit-v8nfk from pks-system started at 2019-01-09 20:59:12 +0000 UTC (2 container statuses recorded)
Jan  9 22:39:37.686: INFO: 	Container fluent-bit ready: true, restart count 0
Jan  9 22:39:37.686: INFO: 	Container ghostunnel ready: true, restart count 0
Jan  9 22:39:37.686: INFO: event-controller-6c77ddd949-gfsgs from pks-system started at 2019-01-09 20:59:12 +0000 UTC (2 container statuses recorded)
Jan  9 22:39:37.686: INFO: 	Container event-controller ready: true, restart count 1
Jan  9 22:39:37.686: INFO: 	Container ghostunnel ready: true, restart count 0
Jan  9 22:39:37.686: INFO: sink-controller-65595c498b-m5gzm from pks-system started at 2019-01-09 20:59:12 +0000 UTC (1 container statuses recorded)
Jan  9 22:39:37.686: INFO: 	Container sink-controller ready: true, restart count 0
Jan  9 22:39:37.686: INFO: telemetry-agent-559f9c8855-t6jq6 from pks-system started at 2019-01-09 21:04:33 +0000 UTC (1 container statuses recorded)
Jan  9 22:39:37.686: INFO: 	Container fluent-bit ready: true, restart count 0
Jan  9 22:39:37.686: INFO: sonobuoy-systemd-logs-daemon-set-6feb07c93b6e401e-cnswx from heptio-sonobuoy started at 2019-01-09 22:37:31 +0000 UTC (2 container statuses recorded)
Jan  9 22:39:37.686: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan  9 22:39:37.686: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan  9 22:39:37.686: INFO: 
Logging pods the kubelet thinks is on node 50ed3ea8-4626-444e-b102-822e7e7faeed before test
Jan  9 22:39:37.708: INFO: metrics-server-555d98886f-l762x from kube-system started at 2019-01-09 20:59:01 +0000 UTC (1 container statuses recorded)
Jan  9 22:39:37.709: INFO: 	Container metrics-server ready: true, restart count 0
Jan  9 22:39:37.709: INFO: monitoring-influxdb-cdcf4674-w7x2z from kube-system started at 2019-01-09 20:59:06 +0000 UTC (1 container statuses recorded)
Jan  9 22:39:37.709: INFO: 	Container influxdb ready: true, restart count 0
Jan  9 22:39:37.709: INFO: cert-generator-v0.11-9ntzp from pks-system started at 2019-01-09 20:59:12 +0000 UTC (1 container statuses recorded)
Jan  9 22:39:37.709: INFO: 	Container cert-generator ready: false, restart count 0
Jan  9 22:39:37.709: INFO: fluent-bit-gqfg4 from pks-system started at 2019-01-09 20:59:12 +0000 UTC (2 container statuses recorded)
Jan  9 22:39:37.709: INFO: 	Container fluent-bit ready: true, restart count 0
Jan  9 22:39:37.709: INFO: 	Container ghostunnel ready: true, restart count 0
Jan  9 22:39:37.709: INFO: wavefront-proxy-bf5f4c667-sbklh from kube-system started at 2019-01-09 21:01:51 +0000 UTC (4 container statuses recorded)
Jan  9 22:39:37.709: INFO: 	Container heapster ready: true, restart count 0
Jan  9 22:39:37.709: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jan  9 22:39:37.709: INFO: 	Container telegraf ready: true, restart count 0
Jan  9 22:39:37.709: INFO: 	Container wavefront-proxy ready: true, restart count 0
Jan  9 22:39:37.709: INFO: sonobuoy-systemd-logs-daemon-set-6feb07c93b6e401e-lpnvh from heptio-sonobuoy started at 2019-01-09 22:37:31 +0000 UTC (2 container statuses recorded)
Jan  9 22:39:37.709: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan  9 22:39:37.709: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan  9 22:39:37.709: INFO: 
Logging pods the kubelet thinks is on node 582539c0-37f1-42db-85f2-2655dcef1574 before test
Jan  9 22:39:37.726: INFO: fluent-bit-4rtck from pks-system started at 2019-01-09 20:59:12 +0000 UTC (2 container statuses recorded)
Jan  9 22:39:37.726: INFO: 	Container fluent-bit ready: true, restart count 0
Jan  9 22:39:37.726: INFO: 	Container ghostunnel ready: true, restart count 0
Jan  9 22:39:37.726: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-09 22:37:25 +0000 UTC (1 container statuses recorded)
Jan  9 22:39:37.726: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan  9 22:39:37.726: INFO: sonobuoy-e2e-job-28ffb20a9ad5428e from heptio-sonobuoy started at 2019-01-09 22:37:31 +0000 UTC (2 container statuses recorded)
Jan  9 22:39:37.726: INFO: 	Container e2e ready: true, restart count 0
Jan  9 22:39:37.726: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan  9 22:39:37.726: INFO: sonobuoy-systemd-logs-daemon-set-6feb07c93b6e401e-fvdm7 from heptio-sonobuoy started at 2019-01-09 22:37:31 +0000 UTC (2 container statuses recorded)
Jan  9 22:39:37.726: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan  9 22:39:37.726: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan  9 22:39:37.726: INFO: kube-dns-7559c96fc4-l8tbn from kube-system started at 2019-01-09 20:58:49 +0000 UTC (3 container statuses recorded)
Jan  9 22:39:37.726: INFO: 	Container dnsmasq ready: true, restart count 0
Jan  9 22:39:37.726: INFO: 	Container kubedns ready: true, restart count 0
Jan  9 22:39:37.726: INFO: 	Container sidecar ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 362e6945-cc10-4a7c-ad11-8cf4815006e1
STEP: verifying the node has the label node 50ed3ea8-4626-444e-b102-822e7e7faeed
STEP: verifying the node has the label node 582539c0-37f1-42db-85f2-2655dcef1574
Jan  9 22:39:37.776: INFO: Pod sonobuoy requesting resource cpu=0m on Node 582539c0-37f1-42db-85f2-2655dcef1574
Jan  9 22:39:37.776: INFO: Pod sonobuoy-e2e-job-28ffb20a9ad5428e requesting resource cpu=0m on Node 582539c0-37f1-42db-85f2-2655dcef1574
Jan  9 22:39:37.776: INFO: Pod sonobuoy-systemd-logs-daemon-set-6feb07c93b6e401e-cnswx requesting resource cpu=0m on Node 362e6945-cc10-4a7c-ad11-8cf4815006e1
Jan  9 22:39:37.776: INFO: Pod sonobuoy-systemd-logs-daemon-set-6feb07c93b6e401e-fvdm7 requesting resource cpu=0m on Node 582539c0-37f1-42db-85f2-2655dcef1574
Jan  9 22:39:37.776: INFO: Pod sonobuoy-systemd-logs-daemon-set-6feb07c93b6e401e-lpnvh requesting resource cpu=0m on Node 50ed3ea8-4626-444e-b102-822e7e7faeed
Jan  9 22:39:37.776: INFO: Pod heapster-85647cf566-dbhkz requesting resource cpu=0m on Node 362e6945-cc10-4a7c-ad11-8cf4815006e1
Jan  9 22:39:37.776: INFO: Pod kube-dns-7559c96fc4-l8tbn requesting resource cpu=260m on Node 582539c0-37f1-42db-85f2-2655dcef1574
Jan  9 22:39:37.776: INFO: Pod kubernetes-dashboard-5f4b59b97f-jtrxq requesting resource cpu=50m on Node 362e6945-cc10-4a7c-ad11-8cf4815006e1
Jan  9 22:39:37.776: INFO: Pod metrics-server-555d98886f-l762x requesting resource cpu=0m on Node 50ed3ea8-4626-444e-b102-822e7e7faeed
Jan  9 22:39:37.776: INFO: Pod monitoring-influxdb-cdcf4674-w7x2z requesting resource cpu=0m on Node 50ed3ea8-4626-444e-b102-822e7e7faeed
Jan  9 22:39:37.776: INFO: Pod wavefront-proxy-bf5f4c667-sbklh requesting resource cpu=0m on Node 50ed3ea8-4626-444e-b102-822e7e7faeed
Jan  9 22:39:37.776: INFO: Pod event-controller-6c77ddd949-gfsgs requesting resource cpu=0m on Node 362e6945-cc10-4a7c-ad11-8cf4815006e1
Jan  9 22:39:37.776: INFO: Pod fluent-bit-4rtck requesting resource cpu=0m on Node 582539c0-37f1-42db-85f2-2655dcef1574
Jan  9 22:39:37.776: INFO: Pod fluent-bit-gqfg4 requesting resource cpu=0m on Node 50ed3ea8-4626-444e-b102-822e7e7faeed
Jan  9 22:39:37.776: INFO: Pod fluent-bit-v8nfk requesting resource cpu=0m on Node 362e6945-cc10-4a7c-ad11-8cf4815006e1
Jan  9 22:39:37.776: INFO: Pod sink-controller-65595c498b-m5gzm requesting resource cpu=0m on Node 362e6945-cc10-4a7c-ad11-8cf4815006e1
Jan  9 22:39:37.776: INFO: Pod telemetry-agent-559f9c8855-t6jq6 requesting resource cpu=0m on Node 362e6945-cc10-4a7c-ad11-8cf4815006e1
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-71f3ef63-145f-11e9-a046-02505600000d.15784f38e5d3c3c6], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-xhkp6/filler-pod-71f3ef63-145f-11e9-a046-02505600000d to 362e6945-cc10-4a7c-ad11-8cf4815006e1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-71f3ef63-145f-11e9-a046-02505600000d.15784f3931a391ec], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-71f3ef63-145f-11e9-a046-02505600000d.15784f3935e754cf], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-71f3ef63-145f-11e9-a046-02505600000d.15784f3941e203ab], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-71f4d5df-145f-11e9-a046-02505600000d.15784f38e6ef4348], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-xhkp6/filler-pod-71f4d5df-145f-11e9-a046-02505600000d to 50ed3ea8-4626-444e-b102-822e7e7faeed]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-71f4d5df-145f-11e9-a046-02505600000d.15784f397417ca9d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-71f4d5df-145f-11e9-a046-02505600000d.15784f3978a1f90d], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-71f4d5df-145f-11e9-a046-02505600000d.15784f3982c8d2b7], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-71f59a02-145f-11e9-a046-02505600000d.15784f38e76801cd], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-xhkp6/filler-pod-71f59a02-145f-11e9-a046-02505600000d to 582539c0-37f1-42db-85f2-2655dcef1574]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-71f59a02-145f-11e9-a046-02505600000d.15784f396f0d1070], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-71f59a02-145f-11e9-a046-02505600000d.15784f39725b2b5b], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-71f59a02-145f-11e9-a046-02505600000d.15784f397f0e6f82], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15784f39d7d322c0], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 362e6945-cc10-4a7c-ad11-8cf4815006e1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 50ed3ea8-4626-444e-b102-822e7e7faeed
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 582539c0-37f1-42db-85f2-2655dcef1574
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:39:42.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-xhkp6" for this suite.
Jan  9 22:39:48.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:39:48.994: INFO: namespace: e2e-tests-sched-pred-xhkp6, resource: bindings, ignored listing per whitelist
Jan  9 22:39:49.010: INFO: namespace e2e-tests-sched-pred-xhkp6 deletion completed in 6.094403615s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:11.532 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:39:49.013: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-dpsmw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-78c4ae4c-145f-11e9-a046-02505600000d
STEP: Creating a pod to test consume secrets
Jan  9 22:39:49.223: INFO: Waiting up to 5m0s for pod "pod-secrets-78c53f0d-145f-11e9-a046-02505600000d" in namespace "e2e-tests-secrets-dpsmw" to be "success or failure"
Jan  9 22:39:49.238: INFO: Pod "pod-secrets-78c53f0d-145f-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.613221ms
Jan  9 22:39:51.241: INFO: Pod "pod-secrets-78c53f0d-145f-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018085934s
Jan  9 22:39:53.245: INFO: Pod "pod-secrets-78c53f0d-145f-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021432285s
Jan  9 22:39:55.248: INFO: Pod "pod-secrets-78c53f0d-145f-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.024603003s
STEP: Saw pod success
Jan  9 22:39:55.248: INFO: Pod "pod-secrets-78c53f0d-145f-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:39:55.250: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-secrets-78c53f0d-145f-11e9-a046-02505600000d container secret-volume-test: <nil>
STEP: delete the pod
Jan  9 22:39:55.276: INFO: Waiting for pod pod-secrets-78c53f0d-145f-11e9-a046-02505600000d to disappear
Jan  9 22:39:55.279: INFO: Pod pod-secrets-78c53f0d-145f-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:39:55.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dpsmw" for this suite.
Jan  9 22:40:01.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:40:01.319: INFO: namespace: e2e-tests-secrets-dpsmw, resource: bindings, ignored listing per whitelist
Jan  9 22:40:01.385: INFO: namespace e2e-tests-secrets-dpsmw deletion completed in 6.102751268s

• [SLOW TEST:12.372 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:40:01.391: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-8c6q2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan  9 22:40:06.133: INFO: Successfully updated pod "labelsupdate8024fea1-145f-11e9-a046-02505600000d"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:40:08.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8c6q2" for this suite.
Jan  9 22:40:30.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:40:30.219: INFO: namespace: e2e-tests-downward-api-8c6q2, resource: bindings, ignored listing per whitelist
Jan  9 22:40:30.251: INFO: namespace e2e-tests-downward-api-8c6q2 deletion completed in 22.096052304s

• [SLOW TEST:28.861 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:40:30.254: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xqh2g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan  9 22:40:30.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 create -f - --namespace=e2e-tests-kubectl-xqh2g'
Jan  9 22:40:30.764: INFO: stderr: ""
Jan  9 22:40:30.765: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan  9 22:40:31.769: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 22:40:31.769: INFO: Found 0 / 1
Jan  9 22:40:32.769: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 22:40:32.769: INFO: Found 0 / 1
Jan  9 22:40:33.768: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 22:40:33.768: INFO: Found 0 / 1
Jan  9 22:40:34.768: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 22:40:34.768: INFO: Found 0 / 1
Jan  9 22:40:35.768: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 22:40:35.768: INFO: Found 1 / 1
Jan  9 22:40:35.768: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jan  9 22:40:35.771: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 22:40:35.771: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan  9 22:40:35.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 patch pod redis-master-7kdpt --namespace=e2e-tests-kubectl-xqh2g -p {"metadata":{"annotations":{"x":"y"}}}'
Jan  9 22:40:35.885: INFO: stderr: ""
Jan  9 22:40:35.885: INFO: stdout: "pod/redis-master-7kdpt patched\n"
STEP: checking annotations
Jan  9 22:40:35.888: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 22:40:35.888: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:40:35.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xqh2g" for this suite.
Jan  9 22:40:57.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:40:57.955: INFO: namespace: e2e-tests-kubectl-xqh2g, resource: bindings, ignored listing per whitelist
Jan  9 22:40:57.993: INFO: namespace e2e-tests-kubectl-xqh2g deletion completed in 22.101876568s

• [SLOW TEST:27.741 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:40:57.994: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-xwrhg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan  9 22:40:58.190: INFO: PodSpec: initContainers in spec.initContainers
Jan  9 22:41:46.942: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-a1e214de-145f-11e9-a046-02505600000d", GenerateName:"", Namespace:"e2e-tests-init-container-xwrhg", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-xwrhg/pods/pod-init-a1e214de-145f-11e9-a046-02505600000d", UID:"a1e2d978-145f-11e9-9de1-005056902d46", ResourceVersion:"10776", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63682670458, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"190838776"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-tr6zw", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421f9e040), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-tr6zw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-tr6zw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}, "cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-tr6zw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4222c2108), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"582539c0-37f1-42db-85f2-2655dcef1574", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc42218c000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4222c2180)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4222c21a0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4222c21a8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682670458, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682670458, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682670458, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682670458, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"30.0.3.3", PodIP:"40.0.5.2", StartTime:(*v1.Time)(0xc421f26040), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4222c6070)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4222c60e0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://e7e104057728075def00a385ed1d1758a7efd3393963a1683a754bd8f2c5ed4c"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421f26080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421f26060), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:41:46.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-xwrhg" for this suite.
Jan  9 22:41:58.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:41:59.021: INFO: namespace: e2e-tests-init-container-xwrhg, resource: bindings, ignored listing per whitelist
Jan  9 22:41:59.035: INFO: namespace e2e-tests-init-container-xwrhg deletion completed in 12.085542563s

• [SLOW TEST:61.042 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:41:59.038: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-jvpd6
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-c642d131-145f-11e9-a046-02505600000d
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:42:05.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jvpd6" for this suite.
Jan  9 22:42:27.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:42:27.330: INFO: namespace: e2e-tests-configmap-jvpd6, resource: bindings, ignored listing per whitelist
Jan  9 22:42:27.360: INFO: namespace e2e-tests-configmap-jvpd6 deletion completed in 22.09515365s

• [SLOW TEST:28.323 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:42:27.361: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-pfl9m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 22:42:33.602: INFO: Waiting up to 5m0s for pod "client-envvars-dabfb305-145f-11e9-a046-02505600000d" in namespace "e2e-tests-pods-pfl9m" to be "success or failure"
Jan  9 22:42:33.609: INFO: Pod "client-envvars-dabfb305-145f-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.647253ms
Jan  9 22:42:35.613: INFO: Pod "client-envvars-dabfb305-145f-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010771025s
STEP: Saw pod success
Jan  9 22:42:35.614: INFO: Pod "client-envvars-dabfb305-145f-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:42:35.617: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod client-envvars-dabfb305-145f-11e9-a046-02505600000d container env3cont: <nil>
STEP: delete the pod
Jan  9 22:42:35.655: INFO: Waiting for pod client-envvars-dabfb305-145f-11e9-a046-02505600000d to disappear
Jan  9 22:42:35.664: INFO: Pod client-envvars-dabfb305-145f-11e9-a046-02505600000d no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:42:35.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-pfl9m" for this suite.
Jan  9 22:43:13.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:43:13.766: INFO: namespace: e2e-tests-pods-pfl9m, resource: bindings, ignored listing per whitelist
Jan  9 22:43:13.773: INFO: namespace e2e-tests-pods-pfl9m deletion completed in 38.095979049s

• [SLOW TEST:46.413 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:43:13.774: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-chk56
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-f2cd21b4-145f-11e9-a046-02505600000d
STEP: Creating a pod to test consume secrets
Jan  9 22:43:13.960: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f2cdb33b-145f-11e9-a046-02505600000d" in namespace "e2e-tests-projected-chk56" to be "success or failure"
Jan  9 22:43:13.972: INFO: Pod "pod-projected-secrets-f2cdb33b-145f-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.513504ms
Jan  9 22:43:15.976: INFO: Pod "pod-projected-secrets-f2cdb33b-145f-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015248791s
Jan  9 22:43:17.979: INFO: Pod "pod-projected-secrets-f2cdb33b-145f-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018562864s
STEP: Saw pod success
Jan  9 22:43:17.979: INFO: Pod "pod-projected-secrets-f2cdb33b-145f-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:43:17.981: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-projected-secrets-f2cdb33b-145f-11e9-a046-02505600000d container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan  9 22:43:18.010: INFO: Waiting for pod pod-projected-secrets-f2cdb33b-145f-11e9-a046-02505600000d to disappear
Jan  9 22:43:18.014: INFO: Pod pod-projected-secrets-f2cdb33b-145f-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:43:18.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-chk56" for this suite.
Jan  9 22:43:24.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:43:24.095: INFO: namespace: e2e-tests-projected-chk56, resource: bindings, ignored listing per whitelist
Jan  9 22:43:24.108: INFO: namespace e2e-tests-projected-chk56 deletion completed in 6.091093109s

• [SLOW TEST:10.334 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:43:24.108: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-dzvrj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Jan  9 22:43:24.322: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-dzvrj" to be "success or failure"
Jan  9 22:43:24.334: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 12.360485ms
Jan  9 22:43:26.340: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018256625s
Jan  9 22:43:28.344: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021936047s
STEP: Saw pod success
Jan  9 22:43:28.344: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jan  9 22:43:28.347: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jan  9 22:43:28.382: INFO: Waiting for pod pod-host-path-test to disappear
Jan  9 22:43:28.385: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:43:28.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-dzvrj" for this suite.
Jan  9 22:43:34.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:43:34.477: INFO: namespace: e2e-tests-hostpath-dzvrj, resource: bindings, ignored listing per whitelist
Jan  9 22:43:34.507: INFO: namespace e2e-tests-hostpath-dzvrj deletion completed in 6.116542172s

• [SLOW TEST:10.399 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:43:34.508: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-zw5p4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-96z8
STEP: Creating a pod to test atomic-volume-subpath
Jan  9 22:43:34.720: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-96z8" in namespace "e2e-tests-subpath-zw5p4" to be "success or failure"
Jan  9 22:43:34.748: INFO: Pod "pod-subpath-test-configmap-96z8": Phase="Pending", Reason="", readiness=false. Elapsed: 27.154842ms
Jan  9 22:43:36.751: INFO: Pod "pod-subpath-test-configmap-96z8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030745668s
Jan  9 22:43:38.755: INFO: Pod "pod-subpath-test-configmap-96z8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03481284s
Jan  9 22:43:40.759: INFO: Pod "pod-subpath-test-configmap-96z8": Phase="Running", Reason="", readiness=false. Elapsed: 6.038522833s
Jan  9 22:43:42.764: INFO: Pod "pod-subpath-test-configmap-96z8": Phase="Running", Reason="", readiness=false. Elapsed: 8.043523074s
Jan  9 22:43:44.769: INFO: Pod "pod-subpath-test-configmap-96z8": Phase="Running", Reason="", readiness=false. Elapsed: 10.048158232s
Jan  9 22:43:46.772: INFO: Pod "pod-subpath-test-configmap-96z8": Phase="Running", Reason="", readiness=false. Elapsed: 12.052022733s
Jan  9 22:43:48.776: INFO: Pod "pod-subpath-test-configmap-96z8": Phase="Running", Reason="", readiness=false. Elapsed: 14.055400909s
Jan  9 22:43:50.780: INFO: Pod "pod-subpath-test-configmap-96z8": Phase="Running", Reason="", readiness=false. Elapsed: 16.059264059s
Jan  9 22:43:52.783: INFO: Pod "pod-subpath-test-configmap-96z8": Phase="Running", Reason="", readiness=false. Elapsed: 18.062226796s
Jan  9 22:43:54.786: INFO: Pod "pod-subpath-test-configmap-96z8": Phase="Running", Reason="", readiness=false. Elapsed: 20.065869983s
Jan  9 22:43:56.790: INFO: Pod "pod-subpath-test-configmap-96z8": Phase="Running", Reason="", readiness=false. Elapsed: 22.069959611s
Jan  9 22:43:58.794: INFO: Pod "pod-subpath-test-configmap-96z8": Phase="Running", Reason="", readiness=false. Elapsed: 24.073654552s
Jan  9 22:44:00.798: INFO: Pod "pod-subpath-test-configmap-96z8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.077261951s
STEP: Saw pod success
Jan  9 22:44:00.798: INFO: Pod "pod-subpath-test-configmap-96z8" satisfied condition "success or failure"
Jan  9 22:44:00.800: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-subpath-test-configmap-96z8 container test-container-subpath-configmap-96z8: <nil>
STEP: delete the pod
Jan  9 22:44:00.820: INFO: Waiting for pod pod-subpath-test-configmap-96z8 to disappear
Jan  9 22:44:00.824: INFO: Pod pod-subpath-test-configmap-96z8 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-96z8
Jan  9 22:44:00.824: INFO: Deleting pod "pod-subpath-test-configmap-96z8" in namespace "e2e-tests-subpath-zw5p4"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:44:00.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-zw5p4" for this suite.
Jan  9 22:44:06.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:44:06.928: INFO: namespace: e2e-tests-subpath-zw5p4, resource: bindings, ignored listing per whitelist
Jan  9 22:44:06.931: INFO: namespace e2e-tests-subpath-zw5p4 deletion completed in 6.099982642s

• [SLOW TEST:32.424 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:44:06.934: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-krh2n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan  9 22:44:15.680: INFO: Successfully updated pod "pod-update-activedeadlineseconds-127e4e28-1460-11e9-a046-02505600000d"
Jan  9 22:44:15.680: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-127e4e28-1460-11e9-a046-02505600000d" in namespace "e2e-tests-pods-krh2n" to be "terminated due to deadline exceeded"
Jan  9 22:44:15.685: INFO: Pod "pod-update-activedeadlineseconds-127e4e28-1460-11e9-a046-02505600000d": Phase="Running", Reason="", readiness=true. Elapsed: 5.701565ms
Jan  9 22:44:17.689: INFO: Pod "pod-update-activedeadlineseconds-127e4e28-1460-11e9-a046-02505600000d": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.0095929s
Jan  9 22:44:17.690: INFO: Pod "pod-update-activedeadlineseconds-127e4e28-1460-11e9-a046-02505600000d" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:44:17.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-krh2n" for this suite.
Jan  9 22:44:23.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:44:23.743: INFO: namespace: e2e-tests-pods-krh2n, resource: bindings, ignored listing per whitelist
Jan  9 22:44:23.779: INFO: namespace e2e-tests-pods-krh2n deletion completed in 6.087007338s

• [SLOW TEST:16.846 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:44:23.780: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-grnsw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan  9 22:44:23.964: INFO: Waiting up to 5m0s for pod "pod-1c87ddcc-1460-11e9-a046-02505600000d" in namespace "e2e-tests-emptydir-grnsw" to be "success or failure"
Jan  9 22:44:23.968: INFO: Pod "pod-1c87ddcc-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.258652ms
Jan  9 22:44:25.971: INFO: Pod "pod-1c87ddcc-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006717179s
Jan  9 22:44:27.975: INFO: Pod "pod-1c87ddcc-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010512759s
Jan  9 22:44:29.978: INFO: Pod "pod-1c87ddcc-1460-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013556733s
STEP: Saw pod success
Jan  9 22:44:29.978: INFO: Pod "pod-1c87ddcc-1460-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:44:29.981: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-1c87ddcc-1460-11e9-a046-02505600000d container test-container: <nil>
STEP: delete the pod
Jan  9 22:44:30.004: INFO: Waiting for pod pod-1c87ddcc-1460-11e9-a046-02505600000d to disappear
Jan  9 22:44:30.006: INFO: Pod pod-1c87ddcc-1460-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:44:30.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-grnsw" for this suite.
Jan  9 22:44:36.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:44:36.091: INFO: namespace: e2e-tests-emptydir-grnsw, resource: bindings, ignored listing per whitelist
Jan  9 22:44:36.096: INFO: namespace e2e-tests-emptydir-grnsw deletion completed in 6.086905555s

• [SLOW TEST:12.316 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:44:36.099: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ltd57
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan  9 22:44:40.830: INFO: Successfully updated pod "annotationupdate23df1e26-1460-11e9-a046-02505600000d"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:44:42.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ltd57" for this suite.
Jan  9 22:45:04.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:45:04.945: INFO: namespace: e2e-tests-projected-ltd57, resource: bindings, ignored listing per whitelist
Jan  9 22:45:04.949: INFO: namespace e2e-tests-projected-ltd57 deletion completed in 22.097507093s

• [SLOW TEST:28.850 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:45:04.949: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-x4mfm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 22:45:05.129: INFO: Waiting up to 5m0s for pod "downwardapi-volume-35111bc9-1460-11e9-a046-02505600000d" in namespace "e2e-tests-projected-x4mfm" to be "success or failure"
Jan  9 22:45:05.133: INFO: Pod "downwardapi-volume-35111bc9-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.279789ms
Jan  9 22:45:07.136: INFO: Pod "downwardapi-volume-35111bc9-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006951393s
Jan  9 22:45:09.143: INFO: Pod "downwardapi-volume-35111bc9-1460-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013481133s
STEP: Saw pod success
Jan  9 22:45:09.143: INFO: Pod "downwardapi-volume-35111bc9-1460-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:45:09.146: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod downwardapi-volume-35111bc9-1460-11e9-a046-02505600000d container client-container: <nil>
STEP: delete the pod
Jan  9 22:45:09.172: INFO: Waiting for pod downwardapi-volume-35111bc9-1460-11e9-a046-02505600000d to disappear
Jan  9 22:45:09.175: INFO: Pod downwardapi-volume-35111bc9-1460-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:45:09.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x4mfm" for this suite.
Jan  9 22:45:15.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:45:15.225: INFO: namespace: e2e-tests-projected-x4mfm, resource: bindings, ignored listing per whitelist
Jan  9 22:45:15.294: INFO: namespace e2e-tests-projected-x4mfm deletion completed in 6.114389057s

• [SLOW TEST:10.345 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:45:15.296: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-k27z8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan  9 22:45:15.505: INFO: Waiting up to 5m0s for pod "downward-api-3b404022-1460-11e9-a046-02505600000d" in namespace "e2e-tests-downward-api-k27z8" to be "success or failure"
Jan  9 22:45:15.508: INFO: Pod "downward-api-3b404022-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.723968ms
Jan  9 22:45:17.511: INFO: Pod "downward-api-3b404022-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006046734s
Jan  9 22:45:19.515: INFO: Pod "downward-api-3b404022-1460-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009573027s
STEP: Saw pod success
Jan  9 22:45:19.515: INFO: Pod "downward-api-3b404022-1460-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:45:19.518: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod downward-api-3b404022-1460-11e9-a046-02505600000d container dapi-container: <nil>
STEP: delete the pod
Jan  9 22:45:19.548: INFO: Waiting for pod downward-api-3b404022-1460-11e9-a046-02505600000d to disappear
Jan  9 22:45:19.550: INFO: Pod downward-api-3b404022-1460-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:45:19.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-k27z8" for this suite.
Jan  9 22:45:25.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:45:25.577: INFO: namespace: e2e-tests-downward-api-k27z8, resource: bindings, ignored listing per whitelist
Jan  9 22:45:25.636: INFO: namespace e2e-tests-downward-api-k27z8 deletion completed in 6.082889972s

• [SLOW TEST:10.340 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:45:25.637: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-gjf4t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-4166afb5-1460-11e9-a046-02505600000d
STEP: Creating a pod to test consume secrets
Jan  9 22:45:25.838: INFO: Waiting up to 5m0s for pod "pod-secrets-4168b04c-1460-11e9-a046-02505600000d" in namespace "e2e-tests-secrets-gjf4t" to be "success or failure"
Jan  9 22:45:25.850: INFO: Pod "pod-secrets-4168b04c-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.950097ms
Jan  9 22:45:27.853: INFO: Pod "pod-secrets-4168b04c-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015403s
Jan  9 22:45:29.859: INFO: Pod "pod-secrets-4168b04c-1460-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021334001s
STEP: Saw pod success
Jan  9 22:45:29.859: INFO: Pod "pod-secrets-4168b04c-1460-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:45:29.862: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-secrets-4168b04c-1460-11e9-a046-02505600000d container secret-volume-test: <nil>
STEP: delete the pod
Jan  9 22:45:29.883: INFO: Waiting for pod pod-secrets-4168b04c-1460-11e9-a046-02505600000d to disappear
Jan  9 22:45:29.886: INFO: Pod pod-secrets-4168b04c-1460-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:45:29.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gjf4t" for this suite.
Jan  9 22:45:35.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:45:35.961: INFO: namespace: e2e-tests-secrets-gjf4t, resource: bindings, ignored listing per whitelist
Jan  9 22:45:35.992: INFO: namespace e2e-tests-secrets-gjf4t deletion completed in 6.101825509s

• [SLOW TEST:10.355 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:45:35.994: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2445q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-479259a3-1460-11e9-a046-02505600000d
STEP: Creating secret with name secret-projected-all-test-volume-47925983-1460-11e9-a046-02505600000d
STEP: Creating a pod to test Check all projections for projected volume plugin
Jan  9 22:45:36.213: INFO: Waiting up to 5m0s for pod "projected-volume-4792594a-1460-11e9-a046-02505600000d" in namespace "e2e-tests-projected-2445q" to be "success or failure"
Jan  9 22:45:36.216: INFO: Pod "projected-volume-4792594a-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.913494ms
Jan  9 22:45:38.219: INFO: Pod "projected-volume-4792594a-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006620725s
Jan  9 22:45:40.223: INFO: Pod "projected-volume-4792594a-1460-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010432068s
STEP: Saw pod success
Jan  9 22:45:40.223: INFO: Pod "projected-volume-4792594a-1460-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:45:40.225: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod projected-volume-4792594a-1460-11e9-a046-02505600000d container projected-all-volume-test: <nil>
STEP: delete the pod
Jan  9 22:45:40.247: INFO: Waiting for pod projected-volume-4792594a-1460-11e9-a046-02505600000d to disappear
Jan  9 22:45:40.252: INFO: Pod projected-volume-4792594a-1460-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:45:40.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2445q" for this suite.
Jan  9 22:45:46.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:45:46.294: INFO: namespace: e2e-tests-projected-2445q, resource: bindings, ignored listing per whitelist
Jan  9 22:45:46.355: INFO: namespace e2e-tests-projected-2445q deletion completed in 6.098065516s

• [SLOW TEST:10.361 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:45:46.355: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-8q9vb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Jan  9 22:45:46.553: INFO: Waiting up to 5m0s for pod "client-containers-4dc18ec8-1460-11e9-a046-02505600000d" in namespace "e2e-tests-containers-8q9vb" to be "success or failure"
Jan  9 22:45:46.561: INFO: Pod "client-containers-4dc18ec8-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.838378ms
Jan  9 22:45:48.565: INFO: Pod "client-containers-4dc18ec8-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01262547s
Jan  9 22:45:50.568: INFO: Pod "client-containers-4dc18ec8-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015476183s
Jan  9 22:45:52.571: INFO: Pod "client-containers-4dc18ec8-1460-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018709922s
STEP: Saw pod success
Jan  9 22:45:52.571: INFO: Pod "client-containers-4dc18ec8-1460-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:45:52.574: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod client-containers-4dc18ec8-1460-11e9-a046-02505600000d container test-container: <nil>
STEP: delete the pod
Jan  9 22:45:52.590: INFO: Waiting for pod client-containers-4dc18ec8-1460-11e9-a046-02505600000d to disappear
Jan  9 22:45:52.607: INFO: Pod client-containers-4dc18ec8-1460-11e9-a046-02505600000d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:45:52.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-8q9vb" for this suite.
Jan  9 22:45:58.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:45:58.669: INFO: namespace: e2e-tests-containers-8q9vb, resource: bindings, ignored listing per whitelist
Jan  9 22:45:58.694: INFO: namespace e2e-tests-containers-8q9vb deletion completed in 6.084190309s

• [SLOW TEST:12.339 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:45:58.697: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-c24rx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-551b995d-1460-11e9-a046-02505600000d
STEP: Creating a pod to test consume configMaps
Jan  9 22:45:58.894: INFO: Waiting up to 5m0s for pod "pod-configmaps-551c2dfe-1460-11e9-a046-02505600000d" in namespace "e2e-tests-configmap-c24rx" to be "success or failure"
Jan  9 22:45:58.901: INFO: Pod "pod-configmaps-551c2dfe-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.483485ms
Jan  9 22:46:00.906: INFO: Pod "pod-configmaps-551c2dfe-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012314144s
Jan  9 22:46:02.910: INFO: Pod "pod-configmaps-551c2dfe-1460-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016111516s
STEP: Saw pod success
Jan  9 22:46:02.910: INFO: Pod "pod-configmaps-551c2dfe-1460-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:46:02.913: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-configmaps-551c2dfe-1460-11e9-a046-02505600000d container configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 22:46:02.932: INFO: Waiting for pod pod-configmaps-551c2dfe-1460-11e9-a046-02505600000d to disappear
Jan  9 22:46:02.935: INFO: Pod pod-configmaps-551c2dfe-1460-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:46:02.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-c24rx" for this suite.
Jan  9 22:46:08.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:46:08.973: INFO: namespace: e2e-tests-configmap-c24rx, resource: bindings, ignored listing per whitelist
Jan  9 22:46:09.022: INFO: namespace e2e-tests-configmap-c24rx deletion completed in 6.084419193s

• [SLOW TEST:10.326 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:46:09.024: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-87bzj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-87bzj
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Jan  9 22:46:09.221: INFO: Found 0 stateful pods, waiting for 3
Jan  9 22:46:19.227: INFO: Found 2 stateful pods, waiting for 3
Jan  9 22:46:29.226: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan  9 22:46:29.227: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan  9 22:46:29.228: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jan  9 22:46:29.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-87bzj ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 22:46:29.484: INFO: stderr: ""
Jan  9 22:46:29.485: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 22:46:29.485: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan  9 22:46:39.517: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jan  9 22:46:49.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-87bzj ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 22:46:49.767: INFO: stderr: ""
Jan  9 22:46:49.767: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  9 22:46:49.767: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  9 22:47:09.785: INFO: Waiting for StatefulSet e2e-tests-statefulset-87bzj/ss2 to complete update
Jan  9 22:47:09.786: INFO: Waiting for Pod e2e-tests-statefulset-87bzj/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Jan  9 22:47:19.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-87bzj ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 22:47:20.012: INFO: stderr: ""
Jan  9 22:47:20.012: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 22:47:20.012: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  9 22:47:30.043: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jan  9 22:47:40.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-87bzj ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 22:47:40.261: INFO: stderr: ""
Jan  9 22:47:40.261: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  9 22:47:40.261: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  9 22:48:00.278: INFO: Waiting for StatefulSet e2e-tests-statefulset-87bzj/ss2 to complete update
Jan  9 22:48:00.278: INFO: Waiting for Pod e2e-tests-statefulset-87bzj/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan  9 22:48:10.285: INFO: Deleting all statefulset in ns e2e-tests-statefulset-87bzj
Jan  9 22:48:10.287: INFO: Scaling statefulset ss2 to 0
Jan  9 22:48:20.300: INFO: Waiting for statefulset status.replicas updated to 0
Jan  9 22:48:20.303: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:48:20.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-87bzj" for this suite.
Jan  9 22:48:26.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:48:26.391: INFO: namespace: e2e-tests-statefulset-87bzj, resource: bindings, ignored listing per whitelist
Jan  9 22:48:26.433: INFO: namespace e2e-tests-statefulset-87bzj deletion completed in 6.093568639s

• [SLOW TEST:137.409 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:48:26.434: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-96qkh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-96qkh/configmap-test-ad2b817a-1460-11e9-a046-02505600000d
STEP: Creating a pod to test consume configMaps
Jan  9 22:48:26.635: INFO: Waiting up to 5m0s for pod "pod-configmaps-ad2c13df-1460-11e9-a046-02505600000d" in namespace "e2e-tests-configmap-96qkh" to be "success or failure"
Jan  9 22:48:26.640: INFO: Pod "pod-configmaps-ad2c13df-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.280794ms
Jan  9 22:48:28.643: INFO: Pod "pod-configmaps-ad2c13df-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008099538s
Jan  9 22:48:30.648: INFO: Pod "pod-configmaps-ad2c13df-1460-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013131234s
STEP: Saw pod success
Jan  9 22:48:30.649: INFO: Pod "pod-configmaps-ad2c13df-1460-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:48:30.653: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-configmaps-ad2c13df-1460-11e9-a046-02505600000d container env-test: <nil>
STEP: delete the pod
Jan  9 22:48:30.674: INFO: Waiting for pod pod-configmaps-ad2c13df-1460-11e9-a046-02505600000d to disappear
Jan  9 22:48:30.676: INFO: Pod pod-configmaps-ad2c13df-1460-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:48:30.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-96qkh" for this suite.
Jan  9 22:48:36.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:48:36.755: INFO: namespace: e2e-tests-configmap-96qkh, resource: bindings, ignored listing per whitelist
Jan  9 22:48:36.782: INFO: namespace e2e-tests-configmap-96qkh deletion completed in 6.093198018s

• [SLOW TEST:10.348 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:48:36.783: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-lkq7r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan  9 22:48:36.964: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:48:42.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-lkq7r" for this suite.
Jan  9 22:48:49.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:48:49.023: INFO: namespace: e2e-tests-init-container-lkq7r, resource: bindings, ignored listing per whitelist
Jan  9 22:48:49.084: INFO: namespace e2e-tests-init-container-lkq7r deletion completed in 6.091490058s

• [SLOW TEST:12.301 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:48:49.084: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-vw42r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-baab8b31-1460-11e9-a046-02505600000d
STEP: Creating a pod to test consume configMaps
Jan  9 22:48:49.288: INFO: Waiting up to 5m0s for pod "pod-configmaps-baac19fc-1460-11e9-a046-02505600000d" in namespace "e2e-tests-configmap-vw42r" to be "success or failure"
Jan  9 22:48:49.299: INFO: Pod "pod-configmaps-baac19fc-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.089048ms
Jan  9 22:48:51.303: INFO: Pod "pod-configmaps-baac19fc-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014873611s
Jan  9 22:48:53.306: INFO: Pod "pod-configmaps-baac19fc-1460-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018236747s
STEP: Saw pod success
Jan  9 22:48:53.306: INFO: Pod "pod-configmaps-baac19fc-1460-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:48:53.309: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-configmaps-baac19fc-1460-11e9-a046-02505600000d container configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 22:48:53.330: INFO: Waiting for pod pod-configmaps-baac19fc-1460-11e9-a046-02505600000d to disappear
Jan  9 22:48:53.333: INFO: Pod pod-configmaps-baac19fc-1460-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:48:53.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vw42r" for this suite.
Jan  9 22:48:59.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:48:59.378: INFO: namespace: e2e-tests-configmap-vw42r, resource: bindings, ignored listing per whitelist
Jan  9 22:48:59.434: INFO: namespace e2e-tests-configmap-vw42r deletion completed in 6.09817123s

• [SLOW TEST:10.350 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:48:59.436: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-7hbnc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan  9 22:48:59.636: INFO: Waiting up to 5m0s for pod "downward-api-c0d7b6cf-1460-11e9-a046-02505600000d" in namespace "e2e-tests-downward-api-7hbnc" to be "success or failure"
Jan  9 22:48:59.642: INFO: Pod "downward-api-c0d7b6cf-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.221982ms
Jan  9 22:49:01.646: INFO: Pod "downward-api-c0d7b6cf-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009392072s
Jan  9 22:49:03.650: INFO: Pod "downward-api-c0d7b6cf-1460-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01341758s
STEP: Saw pod success
Jan  9 22:49:03.650: INFO: Pod "downward-api-c0d7b6cf-1460-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:49:03.653: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod downward-api-c0d7b6cf-1460-11e9-a046-02505600000d container dapi-container: <nil>
STEP: delete the pod
Jan  9 22:49:03.676: INFO: Waiting for pod downward-api-c0d7b6cf-1460-11e9-a046-02505600000d to disappear
Jan  9 22:49:03.678: INFO: Pod downward-api-c0d7b6cf-1460-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:49:03.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7hbnc" for this suite.
Jan  9 22:49:09.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:49:09.762: INFO: namespace: e2e-tests-downward-api-7hbnc, resource: bindings, ignored listing per whitelist
Jan  9 22:49:09.775: INFO: namespace e2e-tests-downward-api-7hbnc deletion completed in 6.093125953s

• [SLOW TEST:10.339 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:49:09.775: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-b7st4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-b7st4.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-b7st4.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-b7st4.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-b7st4.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-b7st4.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-b7st4.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan  9 22:49:38.073: INFO: DNS probes using e2e-tests-dns-b7st4/dns-test-c700a485-1460-11e9-a046-02505600000d succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:49:38.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-b7st4" for this suite.
Jan  9 22:49:44.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:49:44.146: INFO: namespace: e2e-tests-dns-b7st4, resource: bindings, ignored listing per whitelist
Jan  9 22:49:44.220: INFO: namespace e2e-tests-dns-b7st4 deletion completed in 6.121570207s

• [SLOW TEST:34.445 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:49:44.223: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-hz9rz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-hz9rz/configmap-test-db897b0b-1460-11e9-a046-02505600000d
STEP: Creating a pod to test consume configMaps
Jan  9 22:49:44.426: INFO: Waiting up to 5m0s for pod "pod-configmaps-db8a2cde-1460-11e9-a046-02505600000d" in namespace "e2e-tests-configmap-hz9rz" to be "success or failure"
Jan  9 22:49:44.442: INFO: Pod "pod-configmaps-db8a2cde-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 15.944822ms
Jan  9 22:49:46.446: INFO: Pod "pod-configmaps-db8a2cde-1460-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019804575s
Jan  9 22:49:48.450: INFO: Pod "pod-configmaps-db8a2cde-1460-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023418836s
STEP: Saw pod success
Jan  9 22:49:48.450: INFO: Pod "pod-configmaps-db8a2cde-1460-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:49:48.453: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-configmaps-db8a2cde-1460-11e9-a046-02505600000d container env-test: <nil>
STEP: delete the pod
Jan  9 22:49:48.476: INFO: Waiting for pod pod-configmaps-db8a2cde-1460-11e9-a046-02505600000d to disappear
Jan  9 22:49:48.480: INFO: Pod pod-configmaps-db8a2cde-1460-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:49:48.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hz9rz" for this suite.
Jan  9 22:49:54.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:49:54.539: INFO: namespace: e2e-tests-configmap-hz9rz, resource: bindings, ignored listing per whitelist
Jan  9 22:49:54.572: INFO: namespace e2e-tests-configmap-hz9rz deletion completed in 6.087437577s

• [SLOW TEST:10.350 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:49:54.573: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-j755s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jan  9 22:50:00.809: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-e1b389c9-1460-11e9-a046-02505600000d", GenerateName:"", Namespace:"e2e-tests-pods-j755s", SelfLink:"/api/v1/namespaces/e2e-tests-pods-j755s/pods/pod-submit-remove-e1b389c9-1460-11e9-a046-02505600000d", UID:"e1b498ad-1460-11e9-9de1-005056902d46", ResourceVersion:"12490", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63682670994, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"756658405"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-4xxms", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc4222212c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4xxms", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421ae8518), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"362e6945-cc10-4a7c-ad11-8cf4815006e1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421578de0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421ae8550)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421ae8570)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421ae8578), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682670994, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682670998, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682670998, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682670994, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"30.0.3.4", PodIP:"40.0.5.2", StartTime:(*v1.Time)(0xc421d0ea60), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc421d0ea80), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96", ContainerID:"docker://acba2bcfadaddc509835a63af5d8a9ca1637ad0e83fc4bb25737a7de5bb25067"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:50:07.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-j755s" for this suite.
Jan  9 22:50:13.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:50:13.170: INFO: namespace: e2e-tests-pods-j755s, resource: bindings, ignored listing per whitelist
Jan  9 22:50:13.212: INFO: namespace e2e-tests-pods-j755s deletion completed in 6.083074609s

• [SLOW TEST:18.639 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:50:13.213: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-nkwp2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-nkwp2
I0109 22:50:13.421689      16 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-nkwp2, replica count: 1
I0109 22:50:14.472340      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0109 22:50:15.472549      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0109 22:50:16.472879      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0109 22:50:17.473273      16 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan  9 22:50:17.584: INFO: Created: latency-svc-jpzqp
Jan  9 22:50:17.602: INFO: Got endpoints: latency-svc-jpzqp [28.337317ms]
Jan  9 22:50:17.616: INFO: Created: latency-svc-xbrgp
Jan  9 22:50:17.621: INFO: Got endpoints: latency-svc-xbrgp [19.13947ms]
Jan  9 22:50:17.628: INFO: Created: latency-svc-kzxh8
Jan  9 22:50:17.633: INFO: Created: latency-svc-dznnz
Jan  9 22:50:17.642: INFO: Got endpoints: latency-svc-kzxh8 [39.195383ms]
Jan  9 22:50:17.652: INFO: Got endpoints: latency-svc-dznnz [48.904909ms]
Jan  9 22:50:17.654: INFO: Created: latency-svc-l8mrh
Jan  9 22:50:17.666: INFO: Created: latency-svc-s4968
Jan  9 22:50:17.677: INFO: Created: latency-svc-2rctq
Jan  9 22:50:17.677: INFO: Got endpoints: latency-svc-s4968 [74.705944ms]
Jan  9 22:50:17.678: INFO: Got endpoints: latency-svc-l8mrh [75.189759ms]
Jan  9 22:50:17.689: INFO: Got endpoints: latency-svc-2rctq [86.286197ms]
Jan  9 22:50:17.690: INFO: Created: latency-svc-nwcxp
Jan  9 22:50:17.695: INFO: Got endpoints: latency-svc-nwcxp [91.951559ms]
Jan  9 22:50:17.696: INFO: Created: latency-svc-gnh7s
Jan  9 22:50:17.702: INFO: Created: latency-svc-csksz
Jan  9 22:50:17.718: INFO: Got endpoints: latency-svc-csksz [115.084786ms]
Jan  9 22:50:17.718: INFO: Got endpoints: latency-svc-gnh7s [115.709937ms]
Jan  9 22:50:17.728: INFO: Created: latency-svc-txdqm
Jan  9 22:50:17.739: INFO: Created: latency-svc-ddhrr
Jan  9 22:50:17.742: INFO: Got endpoints: latency-svc-txdqm [139.470393ms]
Jan  9 22:50:17.752: INFO: Got endpoints: latency-svc-ddhrr [149.500212ms]
Jan  9 22:50:17.753: INFO: Created: latency-svc-nhqqm
Jan  9 22:50:17.753: INFO: Created: latency-svc-xg2ls
Jan  9 22:50:17.753: INFO: Created: latency-svc-d72xf
Jan  9 22:50:17.767: INFO: Created: latency-svc-nqgfw
Jan  9 22:50:17.771: INFO: Got endpoints: latency-svc-xg2ls [167.715071ms]
Jan  9 22:50:17.771: INFO: Got endpoints: latency-svc-nhqqm [168.09829ms]
Jan  9 22:50:17.771: INFO: Got endpoints: latency-svc-nqgfw [168.18261ms]
Jan  9 22:50:17.771: INFO: Got endpoints: latency-svc-d72xf [28.844125ms]
Jan  9 22:50:17.776: INFO: Created: latency-svc-gdkg7
Jan  9 22:50:17.785: INFO: Got endpoints: latency-svc-gdkg7 [182.063583ms]
Jan  9 22:50:17.787: INFO: Created: latency-svc-ps8zl
Jan  9 22:50:17.793: INFO: Got endpoints: latency-svc-ps8zl [171.690262ms]
Jan  9 22:50:17.805: INFO: Created: latency-svc-drtwl
Jan  9 22:50:17.815: INFO: Created: latency-svc-dz4rz
Jan  9 22:50:17.815: INFO: Got endpoints: latency-svc-dz4rz [173.094648ms]
Jan  9 22:50:17.823: INFO: Created: latency-svc-988jv
Jan  9 22:50:17.825: INFO: Got endpoints: latency-svc-drtwl [173.467072ms]
Jan  9 22:50:17.830: INFO: Got endpoints: latency-svc-988jv [152.397636ms]
Jan  9 22:50:17.843: INFO: Created: latency-svc-glmrs
Jan  9 22:50:17.846: INFO: Created: latency-svc-v2hxl
Jan  9 22:50:17.847: INFO: Got endpoints: latency-svc-glmrs [169.634605ms]
Jan  9 22:50:17.856: INFO: Got endpoints: latency-svc-v2hxl [166.846457ms]
Jan  9 22:50:17.862: INFO: Created: latency-svc-mhb4s
Jan  9 22:50:17.870: INFO: Got endpoints: latency-svc-mhb4s [175.226593ms]
Jan  9 22:50:17.877: INFO: Created: latency-svc-cqz94
Jan  9 22:50:17.883: INFO: Got endpoints: latency-svc-cqz94 [165.452361ms]
Jan  9 22:50:17.891: INFO: Created: latency-svc-4xv6w
Jan  9 22:50:17.899: INFO: Created: latency-svc-cbv67
Jan  9 22:50:17.903: INFO: Got endpoints: latency-svc-4xv6w [184.556992ms]
Jan  9 22:50:17.912: INFO: Created: latency-svc-s2lll
Jan  9 22:50:17.916: INFO: Got endpoints: latency-svc-s2lll [145.603882ms]
Jan  9 22:50:17.917: INFO: Got endpoints: latency-svc-cbv67 [164.282233ms]
Jan  9 22:50:17.924: INFO: Created: latency-svc-dtlmt
Jan  9 22:50:17.934: INFO: Created: latency-svc-9x5n5
Jan  9 22:50:17.936: INFO: Got endpoints: latency-svc-dtlmt [165.326249ms]
Jan  9 22:50:17.951: INFO: Got endpoints: latency-svc-9x5n5 [179.815921ms]
Jan  9 22:50:17.958: INFO: Created: latency-svc-qb4jp
Jan  9 22:50:17.969: INFO: Got endpoints: latency-svc-qb4jp [198.257306ms]
Jan  9 22:50:17.974: INFO: Created: latency-svc-j2hcp
Jan  9 22:50:17.981: INFO: Created: latency-svc-8ljnm
Jan  9 22:50:17.984: INFO: Got endpoints: latency-svc-j2hcp [198.728338ms]
Jan  9 22:50:17.991: INFO: Got endpoints: latency-svc-8ljnm [197.688162ms]
Jan  9 22:50:17.995: INFO: Created: latency-svc-qxm22
Jan  9 22:50:18.001: INFO: Got endpoints: latency-svc-qxm22 [186.517492ms]
Jan  9 22:50:18.006: INFO: Created: latency-svc-rs42v
Jan  9 22:50:18.009: INFO: Created: latency-svc-gbc5q
Jan  9 22:50:18.022: INFO: Got endpoints: latency-svc-gbc5q [192.039355ms]
Jan  9 22:50:18.022: INFO: Got endpoints: latency-svc-rs42v [196.561067ms]
Jan  9 22:50:18.026: INFO: Created: latency-svc-tf4t4
Jan  9 22:50:18.040: INFO: Created: latency-svc-h9xjx
Jan  9 22:50:18.047: INFO: Got endpoints: latency-svc-h9xjx [190.7454ms]
Jan  9 22:50:18.048: INFO: Got endpoints: latency-svc-tf4t4 [200.09898ms]
Jan  9 22:50:18.059: INFO: Created: latency-svc-kjt7q
Jan  9 22:50:18.059: INFO: Got endpoints: latency-svc-kjt7q [189.242288ms]
Jan  9 22:50:18.070: INFO: Created: latency-svc-sgds2
Jan  9 22:50:18.081: INFO: Created: latency-svc-mtlft
Jan  9 22:50:18.090: INFO: Created: latency-svc-2zgfx
Jan  9 22:50:18.094: INFO: Got endpoints: latency-svc-sgds2 [210.366318ms]
Jan  9 22:50:18.102: INFO: Created: latency-svc-5mvd4
Jan  9 22:50:18.110: INFO: Created: latency-svc-s44jx
Jan  9 22:50:18.121: INFO: Created: latency-svc-bmgjd
Jan  9 22:50:18.131: INFO: Created: latency-svc-9m6hw
Jan  9 22:50:18.141: INFO: Created: latency-svc-g798z
Jan  9 22:50:18.141: INFO: Created: latency-svc-8kwqk
Jan  9 22:50:18.145: INFO: Got endpoints: latency-svc-mtlft [241.978342ms]
Jan  9 22:50:18.157: INFO: Created: latency-svc-rv7nk
Jan  9 22:50:18.157: INFO: Created: latency-svc-vblh5
Jan  9 22:50:18.166: INFO: Created: latency-svc-m6d9j
Jan  9 22:50:18.179: INFO: Created: latency-svc-pqt9v
Jan  9 22:50:18.185: INFO: Created: latency-svc-bmvxl
Jan  9 22:50:18.198: INFO: Created: latency-svc-rfc67
Jan  9 22:50:18.201: INFO: Got endpoints: latency-svc-2zgfx [284.302744ms]
Jan  9 22:50:18.215: INFO: Created: latency-svc-98x48
Jan  9 22:50:18.217: INFO: Created: latency-svc-s2sxx
Jan  9 22:50:18.226: INFO: Created: latency-svc-4ccrc
Jan  9 22:50:18.238: INFO: Got endpoints: latency-svc-5mvd4 [321.786957ms]
Jan  9 22:50:18.253: INFO: Created: latency-svc-2hnsq
Jan  9 22:50:18.286: INFO: Got endpoints: latency-svc-s44jx [349.796089ms]
Jan  9 22:50:18.295: INFO: Created: latency-svc-mq8tf
Jan  9 22:50:18.337: INFO: Got endpoints: latency-svc-bmgjd [386.161725ms]
Jan  9 22:50:18.345: INFO: Created: latency-svc-n8pgp
Jan  9 22:50:18.387: INFO: Got endpoints: latency-svc-9m6hw [417.708754ms]
Jan  9 22:50:18.396: INFO: Created: latency-svc-s7d44
Jan  9 22:50:18.442: INFO: Got endpoints: latency-svc-g798z [458.238769ms]
Jan  9 22:50:18.455: INFO: Created: latency-svc-wfp69
Jan  9 22:50:18.486: INFO: Got endpoints: latency-svc-8kwqk [494.847959ms]
Jan  9 22:50:18.502: INFO: Created: latency-svc-mjmhr
Jan  9 22:50:18.536: INFO: Got endpoints: latency-svc-rv7nk [534.435393ms]
Jan  9 22:50:18.545: INFO: Created: latency-svc-g6dh9
Jan  9 22:50:18.587: INFO: Got endpoints: latency-svc-vblh5 [564.996158ms]
Jan  9 22:50:18.600: INFO: Created: latency-svc-6knxh
Jan  9 22:50:18.635: INFO: Got endpoints: latency-svc-m6d9j [613.394455ms]
Jan  9 22:50:18.646: INFO: Created: latency-svc-bdsch
Jan  9 22:50:18.686: INFO: Got endpoints: latency-svc-pqt9v [638.69861ms]
Jan  9 22:50:18.699: INFO: Created: latency-svc-dqgf9
Jan  9 22:50:18.735: INFO: Got endpoints: latency-svc-bmvxl [688.542159ms]
Jan  9 22:50:18.747: INFO: Created: latency-svc-tmsdp
Jan  9 22:50:18.786: INFO: Got endpoints: latency-svc-rfc67 [726.513128ms]
Jan  9 22:50:18.795: INFO: Created: latency-svc-rmzn9
Jan  9 22:50:18.835: INFO: Got endpoints: latency-svc-98x48 [741.465049ms]
Jan  9 22:50:18.845: INFO: Created: latency-svc-f5v97
Jan  9 22:50:18.886: INFO: Got endpoints: latency-svc-s2sxx [740.960196ms]
Jan  9 22:50:18.895: INFO: Created: latency-svc-ctcdk
Jan  9 22:50:18.941: INFO: Got endpoints: latency-svc-4ccrc [739.986158ms]
Jan  9 22:50:18.956: INFO: Created: latency-svc-zww7c
Jan  9 22:50:18.986: INFO: Got endpoints: latency-svc-2hnsq [747.117938ms]
Jan  9 22:50:18.998: INFO: Created: latency-svc-zbflh
Jan  9 22:50:19.037: INFO: Got endpoints: latency-svc-mq8tf [750.380966ms]
Jan  9 22:50:19.044: INFO: Created: latency-svc-cj5fc
Jan  9 22:50:19.086: INFO: Got endpoints: latency-svc-n8pgp [748.965322ms]
Jan  9 22:50:19.094: INFO: Created: latency-svc-fg56c
Jan  9 22:50:19.137: INFO: Got endpoints: latency-svc-s7d44 [750.209796ms]
Jan  9 22:50:19.152: INFO: Created: latency-svc-5tmmw
Jan  9 22:50:19.186: INFO: Got endpoints: latency-svc-wfp69 [743.873583ms]
Jan  9 22:50:19.195: INFO: Created: latency-svc-fg9bn
Jan  9 22:50:19.237: INFO: Got endpoints: latency-svc-mjmhr [751.561535ms]
Jan  9 22:50:19.245: INFO: Created: latency-svc-sjlqp
Jan  9 22:50:19.288: INFO: Got endpoints: latency-svc-g6dh9 [752.344838ms]
Jan  9 22:50:19.296: INFO: Created: latency-svc-h8fbh
Jan  9 22:50:19.339: INFO: Got endpoints: latency-svc-6knxh [751.325996ms]
Jan  9 22:50:19.354: INFO: Created: latency-svc-t4gch
Jan  9 22:50:19.386: INFO: Got endpoints: latency-svc-bdsch [750.682955ms]
Jan  9 22:50:19.400: INFO: Created: latency-svc-s7pql
Jan  9 22:50:19.435: INFO: Got endpoints: latency-svc-dqgf9 [748.753933ms]
Jan  9 22:50:19.448: INFO: Created: latency-svc-drgh6
Jan  9 22:50:19.490: INFO: Got endpoints: latency-svc-tmsdp [754.306184ms]
Jan  9 22:50:19.501: INFO: Created: latency-svc-sxcc9
Jan  9 22:50:19.538: INFO: Got endpoints: latency-svc-rmzn9 [751.985247ms]
Jan  9 22:50:19.545: INFO: Created: latency-svc-fl6r7
Jan  9 22:50:19.587: INFO: Got endpoints: latency-svc-f5v97 [751.664571ms]
Jan  9 22:50:19.594: INFO: Created: latency-svc-dpvsx
Jan  9 22:50:19.636: INFO: Got endpoints: latency-svc-ctcdk [749.492793ms]
Jan  9 22:50:19.647: INFO: Created: latency-svc-llph4
Jan  9 22:50:19.686: INFO: Got endpoints: latency-svc-zww7c [745.468353ms]
Jan  9 22:50:19.696: INFO: Created: latency-svc-htv5j
Jan  9 22:50:19.738: INFO: Got endpoints: latency-svc-zbflh [752.056913ms]
Jan  9 22:50:19.751: INFO: Created: latency-svc-7trp9
Jan  9 22:50:19.786: INFO: Got endpoints: latency-svc-cj5fc [749.545148ms]
Jan  9 22:50:19.795: INFO: Created: latency-svc-chlr2
Jan  9 22:50:19.836: INFO: Got endpoints: latency-svc-fg56c [750.233352ms]
Jan  9 22:50:19.845: INFO: Created: latency-svc-km8tp
Jan  9 22:50:19.887: INFO: Got endpoints: latency-svc-5tmmw [748.922045ms]
Jan  9 22:50:19.895: INFO: Created: latency-svc-fp926
Jan  9 22:50:19.936: INFO: Got endpoints: latency-svc-fg9bn [749.993769ms]
Jan  9 22:50:19.947: INFO: Created: latency-svc-slcm4
Jan  9 22:50:19.986: INFO: Got endpoints: latency-svc-sjlqp [748.751593ms]
Jan  9 22:50:19.998: INFO: Created: latency-svc-xrlzk
Jan  9 22:50:20.036: INFO: Got endpoints: latency-svc-h8fbh [747.429095ms]
Jan  9 22:50:20.047: INFO: Created: latency-svc-2d67m
Jan  9 22:50:20.085: INFO: Got endpoints: latency-svc-t4gch [746.619778ms]
Jan  9 22:50:20.098: INFO: Created: latency-svc-xwhp2
Jan  9 22:50:20.137: INFO: Got endpoints: latency-svc-s7pql [750.798527ms]
Jan  9 22:50:20.147: INFO: Created: latency-svc-mbxqg
Jan  9 22:50:20.187: INFO: Got endpoints: latency-svc-drgh6 [751.253756ms]
Jan  9 22:50:20.200: INFO: Created: latency-svc-2xf5s
Jan  9 22:50:20.237: INFO: Got endpoints: latency-svc-sxcc9 [747.51443ms]
Jan  9 22:50:20.245: INFO: Created: latency-svc-n4bgd
Jan  9 22:50:20.288: INFO: Got endpoints: latency-svc-fl6r7 [750.018072ms]
Jan  9 22:50:20.301: INFO: Created: latency-svc-h7lnw
Jan  9 22:50:20.338: INFO: Got endpoints: latency-svc-dpvsx [750.793093ms]
Jan  9 22:50:20.348: INFO: Created: latency-svc-sd5sw
Jan  9 22:50:20.385: INFO: Got endpoints: latency-svc-llph4 [749.424925ms]
Jan  9 22:50:20.399: INFO: Created: latency-svc-ldh99
Jan  9 22:50:20.438: INFO: Got endpoints: latency-svc-htv5j [751.95654ms]
Jan  9 22:50:20.454: INFO: Created: latency-svc-lfsft
Jan  9 22:50:20.487: INFO: Got endpoints: latency-svc-7trp9 [749.146763ms]
Jan  9 22:50:20.501: INFO: Created: latency-svc-2tnjd
Jan  9 22:50:20.536: INFO: Got endpoints: latency-svc-chlr2 [749.433685ms]
Jan  9 22:50:20.546: INFO: Created: latency-svc-fm7pf
Jan  9 22:50:20.586: INFO: Got endpoints: latency-svc-km8tp [749.105656ms]
Jan  9 22:50:20.603: INFO: Created: latency-svc-xwbk9
Jan  9 22:50:20.637: INFO: Got endpoints: latency-svc-fp926 [750.86756ms]
Jan  9 22:50:20.647: INFO: Created: latency-svc-q2q8r
Jan  9 22:50:20.685: INFO: Got endpoints: latency-svc-slcm4 [748.725423ms]
Jan  9 22:50:20.695: INFO: Created: latency-svc-kplxq
Jan  9 22:50:20.737: INFO: Got endpoints: latency-svc-xrlzk [750.623772ms]
Jan  9 22:50:20.747: INFO: Created: latency-svc-4cfzm
Jan  9 22:50:20.786: INFO: Got endpoints: latency-svc-2d67m [749.929241ms]
Jan  9 22:50:20.804: INFO: Created: latency-svc-rb2n5
Jan  9 22:50:20.841: INFO: Got endpoints: latency-svc-xwhp2 [755.575761ms]
Jan  9 22:50:20.854: INFO: Created: latency-svc-4snrx
Jan  9 22:50:20.893: INFO: Got endpoints: latency-svc-mbxqg [755.673625ms]
Jan  9 22:50:20.900: INFO: Created: latency-svc-2ptz6
Jan  9 22:50:20.935: INFO: Got endpoints: latency-svc-2xf5s [748.620358ms]
Jan  9 22:50:20.942: INFO: Created: latency-svc-hpdrm
Jan  9 22:50:20.985: INFO: Got endpoints: latency-svc-n4bgd [747.946005ms]
Jan  9 22:50:20.994: INFO: Created: latency-svc-4x657
Jan  9 22:50:21.043: INFO: Got endpoints: latency-svc-h7lnw [754.508504ms]
Jan  9 22:50:21.056: INFO: Created: latency-svc-fxvwj
Jan  9 22:50:21.085: INFO: Got endpoints: latency-svc-sd5sw [746.622902ms]
Jan  9 22:50:21.099: INFO: Created: latency-svc-dpcjk
Jan  9 22:50:21.137: INFO: Got endpoints: latency-svc-ldh99 [751.334692ms]
Jan  9 22:50:21.145: INFO: Created: latency-svc-48mrq
Jan  9 22:50:21.188: INFO: Got endpoints: latency-svc-lfsft [749.283752ms]
Jan  9 22:50:21.199: INFO: Created: latency-svc-snhpj
Jan  9 22:50:21.235: INFO: Got endpoints: latency-svc-2tnjd [747.808174ms]
Jan  9 22:50:21.250: INFO: Created: latency-svc-kwpws
Jan  9 22:50:21.289: INFO: Got endpoints: latency-svc-fm7pf [752.556215ms]
Jan  9 22:50:21.297: INFO: Created: latency-svc-vphkl
Jan  9 22:50:21.337: INFO: Got endpoints: latency-svc-xwbk9 [750.976355ms]
Jan  9 22:50:21.346: INFO: Created: latency-svc-9zchq
Jan  9 22:50:21.386: INFO: Got endpoints: latency-svc-q2q8r [748.740601ms]
Jan  9 22:50:21.400: INFO: Created: latency-svc-xvxdr
Jan  9 22:50:21.438: INFO: Got endpoints: latency-svc-kplxq [753.259073ms]
Jan  9 22:50:21.458: INFO: Created: latency-svc-767tc
Jan  9 22:50:21.485: INFO: Got endpoints: latency-svc-4cfzm [747.746737ms]
Jan  9 22:50:21.492: INFO: Created: latency-svc-vmctm
Jan  9 22:50:21.541: INFO: Got endpoints: latency-svc-rb2n5 [755.10828ms]
Jan  9 22:50:21.558: INFO: Created: latency-svc-nc9zs
Jan  9 22:50:21.586: INFO: Got endpoints: latency-svc-4snrx [744.583975ms]
Jan  9 22:50:21.595: INFO: Created: latency-svc-rhhmq
Jan  9 22:50:21.637: INFO: Got endpoints: latency-svc-2ptz6 [743.907999ms]
Jan  9 22:50:21.651: INFO: Created: latency-svc-g9qwg
Jan  9 22:50:21.686: INFO: Got endpoints: latency-svc-hpdrm [750.859231ms]
Jan  9 22:50:21.695: INFO: Created: latency-svc-6cvl7
Jan  9 22:50:21.737: INFO: Got endpoints: latency-svc-4x657 [751.293756ms]
Jan  9 22:50:21.749: INFO: Created: latency-svc-xp2hx
Jan  9 22:50:21.785: INFO: Got endpoints: latency-svc-fxvwj [742.322297ms]
Jan  9 22:50:21.793: INFO: Created: latency-svc-cgtcs
Jan  9 22:50:21.836: INFO: Got endpoints: latency-svc-dpcjk [751.390751ms]
Jan  9 22:50:21.845: INFO: Created: latency-svc-gx22k
Jan  9 22:50:21.889: INFO: Got endpoints: latency-svc-48mrq [752.186713ms]
Jan  9 22:50:21.896: INFO: Created: latency-svc-lk7gb
Jan  9 22:50:21.935: INFO: Got endpoints: latency-svc-snhpj [747.14613ms]
Jan  9 22:50:21.947: INFO: Created: latency-svc-k286d
Jan  9 22:50:21.989: INFO: Got endpoints: latency-svc-kwpws [753.797342ms]
Jan  9 22:50:22.006: INFO: Created: latency-svc-rnbkw
Jan  9 22:50:22.038: INFO: Got endpoints: latency-svc-vphkl [748.888998ms]
Jan  9 22:50:22.046: INFO: Created: latency-svc-9vpjh
Jan  9 22:50:22.085: INFO: Got endpoints: latency-svc-9zchq [748.080107ms]
Jan  9 22:50:22.094: INFO: Created: latency-svc-l255l
Jan  9 22:50:22.137: INFO: Got endpoints: latency-svc-xvxdr [749.909148ms]
Jan  9 22:50:22.149: INFO: Created: latency-svc-2rb8z
Jan  9 22:50:22.190: INFO: Got endpoints: latency-svc-767tc [751.095707ms]
Jan  9 22:50:22.199: INFO: Created: latency-svc-9hh66
Jan  9 22:50:22.238: INFO: Got endpoints: latency-svc-vmctm [752.240163ms]
Jan  9 22:50:22.246: INFO: Created: latency-svc-psk2h
Jan  9 22:50:22.289: INFO: Got endpoints: latency-svc-nc9zs [747.431894ms]
Jan  9 22:50:22.299: INFO: Created: latency-svc-sphk9
Jan  9 22:50:22.337: INFO: Got endpoints: latency-svc-rhhmq [750.758423ms]
Jan  9 22:50:22.344: INFO: Created: latency-svc-tn6gp
Jan  9 22:50:22.387: INFO: Got endpoints: latency-svc-g9qwg [749.732144ms]
Jan  9 22:50:22.404: INFO: Created: latency-svc-g44t5
Jan  9 22:50:22.438: INFO: Got endpoints: latency-svc-6cvl7 [751.703708ms]
Jan  9 22:50:22.448: INFO: Created: latency-svc-sm2xm
Jan  9 22:50:22.486: INFO: Got endpoints: latency-svc-xp2hx [749.371285ms]
Jan  9 22:50:22.497: INFO: Created: latency-svc-hjzvx
Jan  9 22:50:22.536: INFO: Got endpoints: latency-svc-cgtcs [750.493726ms]
Jan  9 22:50:22.545: INFO: Created: latency-svc-5pnsc
Jan  9 22:50:22.587: INFO: Got endpoints: latency-svc-gx22k [750.957174ms]
Jan  9 22:50:22.601: INFO: Created: latency-svc-57pbs
Jan  9 22:50:22.638: INFO: Got endpoints: latency-svc-lk7gb [749.117063ms]
Jan  9 22:50:22.645: INFO: Created: latency-svc-cxbfz
Jan  9 22:50:22.686: INFO: Got endpoints: latency-svc-k286d [751.349853ms]
Jan  9 22:50:22.698: INFO: Created: latency-svc-lgksn
Jan  9 22:50:22.736: INFO: Got endpoints: latency-svc-rnbkw [746.557408ms]
Jan  9 22:50:22.747: INFO: Created: latency-svc-zcz76
Jan  9 22:50:22.785: INFO: Got endpoints: latency-svc-9vpjh [747.129159ms]
Jan  9 22:50:22.792: INFO: Created: latency-svc-8p7g8
Jan  9 22:50:22.837: INFO: Got endpoints: latency-svc-l255l [751.723532ms]
Jan  9 22:50:22.846: INFO: Created: latency-svc-cf96x
Jan  9 22:50:22.886: INFO: Got endpoints: latency-svc-2rb8z [749.268849ms]
Jan  9 22:50:22.896: INFO: Created: latency-svc-r2wtp
Jan  9 22:50:22.937: INFO: Got endpoints: latency-svc-9hh66 [746.812779ms]
Jan  9 22:50:22.949: INFO: Created: latency-svc-5lc7k
Jan  9 22:50:22.985: INFO: Got endpoints: latency-svc-psk2h [746.961091ms]
Jan  9 22:50:22.996: INFO: Created: latency-svc-4pjxg
Jan  9 22:50:23.035: INFO: Got endpoints: latency-svc-sphk9 [746.058098ms]
Jan  9 22:50:23.044: INFO: Created: latency-svc-8cwbm
Jan  9 22:50:23.086: INFO: Got endpoints: latency-svc-tn6gp [748.668057ms]
Jan  9 22:50:23.093: INFO: Created: latency-svc-7nqt7
Jan  9 22:50:23.137: INFO: Got endpoints: latency-svc-g44t5 [749.602053ms]
Jan  9 22:50:23.143: INFO: Created: latency-svc-nfljz
Jan  9 22:50:23.186: INFO: Got endpoints: latency-svc-sm2xm [748.216011ms]
Jan  9 22:50:23.194: INFO: Created: latency-svc-m5dzp
Jan  9 22:50:23.235: INFO: Got endpoints: latency-svc-hjzvx [748.681004ms]
Jan  9 22:50:23.243: INFO: Created: latency-svc-nv987
Jan  9 22:50:23.286: INFO: Got endpoints: latency-svc-5pnsc [749.78303ms]
Jan  9 22:50:23.294: INFO: Created: latency-svc-hh5mm
Jan  9 22:50:23.335: INFO: Got endpoints: latency-svc-57pbs [747.393749ms]
Jan  9 22:50:23.341: INFO: Created: latency-svc-jcqv5
Jan  9 22:50:23.386: INFO: Got endpoints: latency-svc-cxbfz [748.00558ms]
Jan  9 22:50:23.394: INFO: Created: latency-svc-9pz72
Jan  9 22:50:23.437: INFO: Got endpoints: latency-svc-lgksn [750.761597ms]
Jan  9 22:50:23.446: INFO: Created: latency-svc-7x86v
Jan  9 22:50:23.486: INFO: Got endpoints: latency-svc-zcz76 [749.865839ms]
Jan  9 22:50:23.499: INFO: Created: latency-svc-2tdfr
Jan  9 22:50:23.538: INFO: Got endpoints: latency-svc-8p7g8 [752.491896ms]
Jan  9 22:50:23.549: INFO: Created: latency-svc-l4wmt
Jan  9 22:50:23.585: INFO: Got endpoints: latency-svc-cf96x [748.26444ms]
Jan  9 22:50:23.595: INFO: Created: latency-svc-sw89g
Jan  9 22:50:23.635: INFO: Got endpoints: latency-svc-r2wtp [749.227378ms]
Jan  9 22:50:23.649: INFO: Created: latency-svc-stmdj
Jan  9 22:50:23.688: INFO: Got endpoints: latency-svc-5lc7k [751.263934ms]
Jan  9 22:50:23.703: INFO: Created: latency-svc-bttgl
Jan  9 22:50:23.736: INFO: Got endpoints: latency-svc-4pjxg [750.836818ms]
Jan  9 22:50:23.753: INFO: Created: latency-svc-xvd87
Jan  9 22:50:23.785: INFO: Got endpoints: latency-svc-8cwbm [750.48154ms]
Jan  9 22:50:23.795: INFO: Created: latency-svc-rzglh
Jan  9 22:50:23.837: INFO: Got endpoints: latency-svc-7nqt7 [750.734242ms]
Jan  9 22:50:23.849: INFO: Created: latency-svc-lhg42
Jan  9 22:50:23.886: INFO: Got endpoints: latency-svc-nfljz [749.016727ms]
Jan  9 22:50:23.901: INFO: Created: latency-svc-hwnjq
Jan  9 22:50:23.936: INFO: Got endpoints: latency-svc-m5dzp [749.580847ms]
Jan  9 22:50:23.945: INFO: Created: latency-svc-k596v
Jan  9 22:50:23.986: INFO: Got endpoints: latency-svc-nv987 [750.910215ms]
Jan  9 22:50:24.003: INFO: Created: latency-svc-6j5kh
Jan  9 22:50:24.040: INFO: Got endpoints: latency-svc-hh5mm [753.986541ms]
Jan  9 22:50:24.053: INFO: Created: latency-svc-446sg
Jan  9 22:50:24.087: INFO: Got endpoints: latency-svc-jcqv5 [751.999119ms]
Jan  9 22:50:24.094: INFO: Created: latency-svc-rfbb6
Jan  9 22:50:24.135: INFO: Got endpoints: latency-svc-9pz72 [748.308201ms]
Jan  9 22:50:24.143: INFO: Created: latency-svc-49d9x
Jan  9 22:50:24.188: INFO: Got endpoints: latency-svc-7x86v [751.360911ms]
Jan  9 22:50:24.198: INFO: Created: latency-svc-zr6nd
Jan  9 22:50:24.234: INFO: Got endpoints: latency-svc-2tdfr [748.097907ms]
Jan  9 22:50:24.247: INFO: Created: latency-svc-s6b4k
Jan  9 22:50:24.287: INFO: Got endpoints: latency-svc-l4wmt [749.47589ms]
Jan  9 22:50:24.297: INFO: Created: latency-svc-msjdp
Jan  9 22:50:24.337: INFO: Got endpoints: latency-svc-sw89g [751.762538ms]
Jan  9 22:50:24.350: INFO: Created: latency-svc-rxrs8
Jan  9 22:50:24.386: INFO: Got endpoints: latency-svc-stmdj [751.041283ms]
Jan  9 22:50:24.404: INFO: Created: latency-svc-7r48q
Jan  9 22:50:24.437: INFO: Got endpoints: latency-svc-bttgl [748.766473ms]
Jan  9 22:50:24.449: INFO: Created: latency-svc-sj5fd
Jan  9 22:50:24.487: INFO: Got endpoints: latency-svc-xvd87 [750.625865ms]
Jan  9 22:50:24.504: INFO: Created: latency-svc-6sqcq
Jan  9 22:50:24.536: INFO: Got endpoints: latency-svc-rzglh [750.492215ms]
Jan  9 22:50:24.543: INFO: Created: latency-svc-f4w6j
Jan  9 22:50:24.588: INFO: Got endpoints: latency-svc-lhg42 [751.17384ms]
Jan  9 22:50:24.596: INFO: Created: latency-svc-9gq22
Jan  9 22:50:24.636: INFO: Got endpoints: latency-svc-hwnjq [749.723878ms]
Jan  9 22:50:24.646: INFO: Created: latency-svc-pmlr7
Jan  9 22:50:24.686: INFO: Got endpoints: latency-svc-k596v [749.595787ms]
Jan  9 22:50:24.698: INFO: Created: latency-svc-klwt9
Jan  9 22:50:24.736: INFO: Got endpoints: latency-svc-6j5kh [750.288772ms]
Jan  9 22:50:24.742: INFO: Created: latency-svc-h2l4c
Jan  9 22:50:24.787: INFO: Got endpoints: latency-svc-446sg [747.175155ms]
Jan  9 22:50:24.803: INFO: Created: latency-svc-lrpsr
Jan  9 22:50:24.836: INFO: Got endpoints: latency-svc-rfbb6 [748.808353ms]
Jan  9 22:50:24.842: INFO: Created: latency-svc-wvzrp
Jan  9 22:50:24.889: INFO: Got endpoints: latency-svc-49d9x [753.82388ms]
Jan  9 22:50:24.896: INFO: Created: latency-svc-7shgx
Jan  9 22:50:24.936: INFO: Got endpoints: latency-svc-zr6nd [747.95649ms]
Jan  9 22:50:24.944: INFO: Created: latency-svc-q4jnr
Jan  9 22:50:24.985: INFO: Got endpoints: latency-svc-s6b4k [750.88324ms]
Jan  9 22:50:25.006: INFO: Created: latency-svc-pspzm
Jan  9 22:50:25.037: INFO: Got endpoints: latency-svc-msjdp [749.609963ms]
Jan  9 22:50:25.044: INFO: Created: latency-svc-f89zq
Jan  9 22:50:25.086: INFO: Got endpoints: latency-svc-rxrs8 [749.036792ms]
Jan  9 22:50:25.100: INFO: Created: latency-svc-qhwrd
Jan  9 22:50:25.135: INFO: Got endpoints: latency-svc-7r48q [748.672714ms]
Jan  9 22:50:25.146: INFO: Created: latency-svc-6crj5
Jan  9 22:50:25.192: INFO: Got endpoints: latency-svc-sj5fd [755.01471ms]
Jan  9 22:50:25.204: INFO: Created: latency-svc-kqbc8
Jan  9 22:50:25.237: INFO: Got endpoints: latency-svc-6sqcq [749.965998ms]
Jan  9 22:50:25.245: INFO: Created: latency-svc-7m2xl
Jan  9 22:50:25.286: INFO: Got endpoints: latency-svc-f4w6j [749.605003ms]
Jan  9 22:50:25.297: INFO: Created: latency-svc-5qzv4
Jan  9 22:50:25.335: INFO: Got endpoints: latency-svc-9gq22 [747.41335ms]
Jan  9 22:50:25.343: INFO: Created: latency-svc-2vqmd
Jan  9 22:50:25.387: INFO: Got endpoints: latency-svc-pmlr7 [751.45228ms]
Jan  9 22:50:25.396: INFO: Created: latency-svc-458jc
Jan  9 22:50:25.439: INFO: Got endpoints: latency-svc-klwt9 [753.043822ms]
Jan  9 22:50:25.489: INFO: Got endpoints: latency-svc-h2l4c [752.533704ms]
Jan  9 22:50:25.535: INFO: Got endpoints: latency-svc-lrpsr [747.882703ms]
Jan  9 22:50:25.588: INFO: Got endpoints: latency-svc-wvzrp [752.241478ms]
Jan  9 22:50:25.635: INFO: Got endpoints: latency-svc-7shgx [746.671693ms]
Jan  9 22:50:25.687: INFO: Got endpoints: latency-svc-q4jnr [750.150025ms]
Jan  9 22:50:25.736: INFO: Got endpoints: latency-svc-pspzm [750.860867ms]
Jan  9 22:50:25.786: INFO: Got endpoints: latency-svc-f89zq [748.875035ms]
Jan  9 22:50:25.835: INFO: Got endpoints: latency-svc-qhwrd [748.752602ms]
Jan  9 22:50:25.884: INFO: Got endpoints: latency-svc-6crj5 [749.131752ms]
Jan  9 22:50:25.936: INFO: Got endpoints: latency-svc-kqbc8 [744.108721ms]
Jan  9 22:50:25.985: INFO: Got endpoints: latency-svc-7m2xl [748.136958ms]
Jan  9 22:50:26.035: INFO: Got endpoints: latency-svc-5qzv4 [749.486336ms]
Jan  9 22:50:26.085: INFO: Got endpoints: latency-svc-2vqmd [749.437642ms]
Jan  9 22:50:26.137: INFO: Got endpoints: latency-svc-458jc [749.698299ms]
Jan  9 22:50:26.137: INFO: Latencies: [19.13947ms 28.844125ms 39.195383ms 48.904909ms 74.705944ms 75.189759ms 86.286197ms 91.951559ms 115.084786ms 115.709937ms 139.470393ms 145.603882ms 149.500212ms 152.397636ms 164.282233ms 165.326249ms 165.452361ms 166.846457ms 167.715071ms 168.09829ms 168.18261ms 169.634605ms 171.690262ms 173.094648ms 173.467072ms 175.226593ms 179.815921ms 182.063583ms 184.556992ms 186.517492ms 189.242288ms 190.7454ms 192.039355ms 196.561067ms 197.688162ms 198.257306ms 198.728338ms 200.09898ms 210.366318ms 241.978342ms 284.302744ms 321.786957ms 349.796089ms 386.161725ms 417.708754ms 458.238769ms 494.847959ms 534.435393ms 564.996158ms 613.394455ms 638.69861ms 688.542159ms 726.513128ms 739.986158ms 740.960196ms 741.465049ms 742.322297ms 743.873583ms 743.907999ms 744.108721ms 744.583975ms 745.468353ms 746.058098ms 746.557408ms 746.619778ms 746.622902ms 746.671693ms 746.812779ms 746.961091ms 747.117938ms 747.129159ms 747.14613ms 747.175155ms 747.393749ms 747.41335ms 747.429095ms 747.431894ms 747.51443ms 747.746737ms 747.808174ms 747.882703ms 747.946005ms 747.95649ms 748.00558ms 748.080107ms 748.097907ms 748.136958ms 748.216011ms 748.26444ms 748.308201ms 748.620358ms 748.668057ms 748.672714ms 748.681004ms 748.725423ms 748.740601ms 748.751593ms 748.752602ms 748.753933ms 748.766473ms 748.808353ms 748.875035ms 748.888998ms 748.922045ms 748.965322ms 749.016727ms 749.036792ms 749.105656ms 749.117063ms 749.131752ms 749.146763ms 749.227378ms 749.268849ms 749.283752ms 749.371285ms 749.424925ms 749.433685ms 749.437642ms 749.47589ms 749.486336ms 749.492793ms 749.545148ms 749.580847ms 749.595787ms 749.602053ms 749.605003ms 749.609963ms 749.698299ms 749.723878ms 749.732144ms 749.78303ms 749.865839ms 749.909148ms 749.929241ms 749.965998ms 749.993769ms 750.018072ms 750.150025ms 750.209796ms 750.233352ms 750.288772ms 750.380966ms 750.48154ms 750.492215ms 750.493726ms 750.623772ms 750.625865ms 750.682955ms 750.734242ms 750.758423ms 750.761597ms 750.793093ms 750.798527ms 750.836818ms 750.859231ms 750.860867ms 750.86756ms 750.88324ms 750.910215ms 750.957174ms 750.976355ms 751.041283ms 751.095707ms 751.17384ms 751.253756ms 751.263934ms 751.293756ms 751.325996ms 751.334692ms 751.349853ms 751.360911ms 751.390751ms 751.45228ms 751.561535ms 751.664571ms 751.703708ms 751.723532ms 751.762538ms 751.95654ms 751.985247ms 751.999119ms 752.056913ms 752.186713ms 752.240163ms 752.241478ms 752.344838ms 752.491896ms 752.533704ms 752.556215ms 753.043822ms 753.259073ms 753.797342ms 753.82388ms 753.986541ms 754.306184ms 754.508504ms 755.01471ms 755.10828ms 755.575761ms 755.673625ms]
Jan  9 22:50:26.137: INFO: 50 %ile: 748.808353ms
Jan  9 22:50:26.137: INFO: 90 %ile: 751.999119ms
Jan  9 22:50:26.137: INFO: 99 %ile: 755.575761ms
Jan  9 22:50:26.137: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:50:26.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-nkwp2" for this suite.
Jan  9 22:50:36.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:50:36.240: INFO: namespace: e2e-tests-svc-latency-nkwp2, resource: bindings, ignored listing per whitelist
Jan  9 22:50:36.249: INFO: namespace e2e-tests-svc-latency-nkwp2 deletion completed in 10.106785492s

• [SLOW TEST:23.036 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:50:36.249: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-cvt4k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan  9 22:50:36.455: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:50:41.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-cvt4k" for this suite.
Jan  9 22:51:03.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:51:03.463: INFO: namespace: e2e-tests-init-container-cvt4k, resource: bindings, ignored listing per whitelist
Jan  9 22:51:03.508: INFO: namespace e2e-tests-init-container-cvt4k deletion completed in 22.095692034s

• [SLOW TEST:27.260 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:51:03.512: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-clmnf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-clmnf
Jan  9 22:51:07.731: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-clmnf
STEP: checking the pod's current state and verifying that restartCount is present
Jan  9 22:51:07.734: INFO: Initial restart count of pod liveness-exec is 0
Jan  9 22:51:55.825: INFO: Restart count of pod e2e-tests-container-probe-clmnf/liveness-exec is now 1 (48.09184805s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:51:55.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-clmnf" for this suite.
Jan  9 22:52:01.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:52:01.911: INFO: namespace: e2e-tests-container-probe-clmnf, resource: bindings, ignored listing per whitelist
Jan  9 22:52:01.949: INFO: namespace e2e-tests-container-probe-clmnf deletion completed in 6.109346647s

• [SLOW TEST:58.437 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:52:01.950: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-kqphh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan  9 22:52:02.138: INFO: Waiting up to 5m0s for pod "pod-2d9f52d3-1461-11e9-a046-02505600000d" in namespace "e2e-tests-emptydir-kqphh" to be "success or failure"
Jan  9 22:52:02.146: INFO: Pod "pod-2d9f52d3-1461-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.87451ms
Jan  9 22:52:04.149: INFO: Pod "pod-2d9f52d3-1461-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010818781s
Jan  9 22:52:06.152: INFO: Pod "pod-2d9f52d3-1461-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013691779s
STEP: Saw pod success
Jan  9 22:52:06.152: INFO: Pod "pod-2d9f52d3-1461-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:52:06.154: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-2d9f52d3-1461-11e9-a046-02505600000d container test-container: <nil>
STEP: delete the pod
Jan  9 22:52:06.172: INFO: Waiting for pod pod-2d9f52d3-1461-11e9-a046-02505600000d to disappear
Jan  9 22:52:06.177: INFO: Pod pod-2d9f52d3-1461-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:52:06.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kqphh" for this suite.
Jan  9 22:52:12.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:52:12.241: INFO: namespace: e2e-tests-emptydir-kqphh, resource: bindings, ignored listing per whitelist
Jan  9 22:52:12.265: INFO: namespace e2e-tests-emptydir-kqphh deletion completed in 6.083176998s

• [SLOW TEST:10.316 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:52:12.267: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-f269r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 22:52:12.442: INFO: Creating deployment "test-recreate-deployment"
Jan  9 22:52:12.446: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jan  9 22:52:12.466: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Jan  9 22:52:14.473: INFO: Waiting deployment "test-recreate-deployment" to complete
Jan  9 22:52:14.476: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682671132, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682671132, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682671132, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682671132, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  9 22:52:16.482: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682671132, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682671132, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682671132, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682671132, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  9 22:52:18.479: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jan  9 22:52:18.488: INFO: Updating deployment test-recreate-deployment
Jan  9 22:52:18.488: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan  9 22:52:18.619: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-f269r,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-f269r/deployments/test-recreate-deployment,UID:33c4f958-1461-11e9-9de1-005056902d46,ResourceVersion:14170,Generation:2,CreationTimestamp:2019-01-09 22:52:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-01-09 22:52:18 +0000 UTC 2019-01-09 22:52:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-01-09 22:52:18 +0000 UTC 2019-01-09 22:52:12 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jan  9 22:52:18.622: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-f269r,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-f269r/replicasets/test-recreate-deployment-7cf749666b,UID:37678912-1461-11e9-9de1-005056902d46,ResourceVersion:14169,Generation:1,CreationTimestamp:2019-01-09 22:52:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 33c4f958-1461-11e9-9de1-005056902d46 0xc420f1cb77 0xc420f1cb78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan  9 22:52:18.622: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jan  9 22:52:18.622: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-f269r,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-f269r/replicasets/test-recreate-deployment-79f694ff59,UID:33c6457b-1461-11e9-9de1-005056902d46,ResourceVersion:14158,Generation:2,CreationTimestamp:2019-01-09 22:52:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 33c4f958-1461-11e9-9de1-005056902d46 0xc420f1c917 0xc420f1c918}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan  9 22:52:18.625: INFO: Pod "test-recreate-deployment-7cf749666b-d77sx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-d77sx,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-f269r,SelfLink:/api/v1/namespaces/e2e-tests-deployment-f269r/pods/test-recreate-deployment-7cf749666b-d77sx,UID:3768bc77-1461-11e9-9de1-005056902d46,ResourceVersion:14168,Generation:0,CreationTimestamp:2019-01-09 22:52:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 37678912-1461-11e9-9de1-005056902d46 0xc420f1d7e7 0xc420f1d7e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-85pjc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-85pjc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-85pjc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:362e6945-cc10-4a7c-ad11-8cf4815006e1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420f1d850} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420f1d880}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:52:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:52:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:52:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:52:18 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.4,PodIP:,StartTime:2019-01-09 22:52:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:52:18.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-f269r" for this suite.
Jan  9 22:52:24.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:52:24.652: INFO: namespace: e2e-tests-deployment-f269r, resource: bindings, ignored listing per whitelist
Jan  9 22:52:24.749: INFO: namespace e2e-tests-deployment-f269r deletion completed in 6.120231202s

• [SLOW TEST:12.483 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:52:24.750: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-qqmm4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jan  9 22:52:34.992: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qqmm4 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 22:52:34.992: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 22:52:35.101: INFO: Exec stderr: ""
Jan  9 22:52:35.101: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qqmm4 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 22:52:35.101: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 22:52:35.188: INFO: Exec stderr: ""
Jan  9 22:52:35.188: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qqmm4 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 22:52:35.188: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 22:52:35.302: INFO: Exec stderr: ""
Jan  9 22:52:35.302: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qqmm4 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 22:52:35.302: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 22:52:35.408: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jan  9 22:52:35.408: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qqmm4 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 22:52:35.408: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 22:52:35.497: INFO: Exec stderr: ""
Jan  9 22:52:35.497: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qqmm4 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 22:52:35.497: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 22:52:35.597: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jan  9 22:52:35.598: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qqmm4 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 22:52:35.598: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 22:52:35.701: INFO: Exec stderr: ""
Jan  9 22:52:35.701: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qqmm4 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 22:52:35.701: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 22:52:35.797: INFO: Exec stderr: ""
Jan  9 22:52:35.797: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qqmm4 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 22:52:35.797: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 22:52:35.899: INFO: Exec stderr: ""
Jan  9 22:52:35.899: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qqmm4 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 22:52:35.899: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 22:52:35.987: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:52:35.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-qqmm4" for this suite.
Jan  9 22:53:18.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:53:18.017: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-qqmm4, resource: bindings, ignored listing per whitelist
Jan  9 22:53:18.083: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-qqmm4 deletion completed in 42.092624321s

• [SLOW TEST:53.334 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:53:18.085: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-b6td4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan  9 22:53:18.281: INFO: Waiting up to 5m0s for pod "pod-5b01cd98-1461-11e9-a046-02505600000d" in namespace "e2e-tests-emptydir-b6td4" to be "success or failure"
Jan  9 22:53:18.283: INFO: Pod "pod-5b01cd98-1461-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.804455ms
Jan  9 22:53:20.286: INFO: Pod "pod-5b01cd98-1461-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005263658s
Jan  9 22:53:22.290: INFO: Pod "pod-5b01cd98-1461-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008700216s
STEP: Saw pod success
Jan  9 22:53:22.290: INFO: Pod "pod-5b01cd98-1461-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:53:22.292: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-5b01cd98-1461-11e9-a046-02505600000d container test-container: <nil>
STEP: delete the pod
Jan  9 22:53:22.314: INFO: Waiting for pod pod-5b01cd98-1461-11e9-a046-02505600000d to disappear
Jan  9 22:53:22.317: INFO: Pod pod-5b01cd98-1461-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:53:22.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-b6td4" for this suite.
Jan  9 22:53:28.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:53:28.378: INFO: namespace: e2e-tests-emptydir-b6td4, resource: bindings, ignored listing per whitelist
Jan  9 22:53:28.418: INFO: namespace e2e-tests-emptydir-b6td4 deletion completed in 6.096120876s

• [SLOW TEST:10.334 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:53:28.421: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-qt4jn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 22:53:28.607: INFO: Creating ReplicaSet my-hostname-basic-612aa310-1461-11e9-a046-02505600000d
Jan  9 22:53:28.619: INFO: Pod name my-hostname-basic-612aa310-1461-11e9-a046-02505600000d: Found 0 pods out of 1
Jan  9 22:53:33.623: INFO: Pod name my-hostname-basic-612aa310-1461-11e9-a046-02505600000d: Found 1 pods out of 1
Jan  9 22:53:33.623: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-612aa310-1461-11e9-a046-02505600000d" is running
Jan  9 22:53:33.625: INFO: Pod "my-hostname-basic-612aa310-1461-11e9-a046-02505600000d-hgg9q" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-09 22:53:28 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-09 22:53:33 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-09 22:53:33 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-09 22:53:28 +0000 UTC Reason: Message:}])
Jan  9 22:53:33.625: INFO: Trying to dial the pod
Jan  9 22:53:38.637: INFO: Controller my-hostname-basic-612aa310-1461-11e9-a046-02505600000d: Got expected result from replica 1 [my-hostname-basic-612aa310-1461-11e9-a046-02505600000d-hgg9q]: "my-hostname-basic-612aa310-1461-11e9-a046-02505600000d-hgg9q", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:53:38.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-qt4jn" for this suite.
Jan  9 22:53:44.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:53:44.738: INFO: namespace: e2e-tests-replicaset-qt4jn, resource: bindings, ignored listing per whitelist
Jan  9 22:53:44.744: INFO: namespace e2e-tests-replicaset-qt4jn deletion completed in 6.102692799s

• [SLOW TEST:16.324 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:53:44.745: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-kvl94
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  9 22:53:44.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-kvl94'
Jan  9 22:53:45.770: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan  9 22:53:45.770: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Jan  9 22:53:45.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-kvl94'
Jan  9 22:53:45.921: INFO: stderr: ""
Jan  9 22:53:45.921: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:53:45.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kvl94" for this suite.
Jan  9 22:54:07.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:54:08.027: INFO: namespace: e2e-tests-kubectl-kvl94, resource: bindings, ignored listing per whitelist
Jan  9 22:54:08.039: INFO: namespace e2e-tests-kubectl-kvl94 deletion completed in 22.108702976s

• [SLOW TEST:23.294 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:54:08.041: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-hcxh7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Jan  9 22:54:08.231: INFO: Waiting up to 5m0s for pod "var-expansion-78c7f277-1461-11e9-a046-02505600000d" in namespace "e2e-tests-var-expansion-hcxh7" to be "success or failure"
Jan  9 22:54:08.239: INFO: Pod "var-expansion-78c7f277-1461-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.444463ms
Jan  9 22:54:10.242: INFO: Pod "var-expansion-78c7f277-1461-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010953277s
Jan  9 22:54:12.245: INFO: Pod "var-expansion-78c7f277-1461-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014246717s
STEP: Saw pod success
Jan  9 22:54:12.246: INFO: Pod "var-expansion-78c7f277-1461-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:54:12.249: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod var-expansion-78c7f277-1461-11e9-a046-02505600000d container dapi-container: <nil>
STEP: delete the pod
Jan  9 22:54:12.272: INFO: Waiting for pod var-expansion-78c7f277-1461-11e9-a046-02505600000d to disappear
Jan  9 22:54:12.277: INFO: Pod var-expansion-78c7f277-1461-11e9-a046-02505600000d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:54:12.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-hcxh7" for this suite.
Jan  9 22:54:18.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:54:18.395: INFO: namespace: e2e-tests-var-expansion-hcxh7, resource: bindings, ignored listing per whitelist
Jan  9 22:54:18.405: INFO: namespace e2e-tests-var-expansion-hcxh7 deletion completed in 6.124644515s

• [SLOW TEST:10.365 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:54:18.408: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-cz4vq
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Jan  9 22:54:18.618: INFO: Waiting up to 5m0s for pod "pod-7ef8931c-1461-11e9-a046-02505600000d" in namespace "e2e-tests-emptydir-cz4vq" to be "success or failure"
Jan  9 22:54:18.621: INFO: Pod "pod-7ef8931c-1461-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.445901ms
Jan  9 22:54:20.625: INFO: Pod "pod-7ef8931c-1461-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00688464s
Jan  9 22:54:22.629: INFO: Pod "pod-7ef8931c-1461-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01091454s
STEP: Saw pod success
Jan  9 22:54:22.629: INFO: Pod "pod-7ef8931c-1461-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:54:22.631: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-7ef8931c-1461-11e9-a046-02505600000d container test-container: <nil>
STEP: delete the pod
Jan  9 22:54:22.652: INFO: Waiting for pod pod-7ef8931c-1461-11e9-a046-02505600000d to disappear
Jan  9 22:54:22.655: INFO: Pod pod-7ef8931c-1461-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:54:22.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cz4vq" for this suite.
Jan  9 22:54:28.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:54:28.720: INFO: namespace: e2e-tests-emptydir-cz4vq, resource: bindings, ignored listing per whitelist
Jan  9 22:54:28.745: INFO: namespace e2e-tests-emptydir-cz4vq deletion completed in 6.086521719s

• [SLOW TEST:10.337 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:54:28.745: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-tttdm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tttdm A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-tttdm;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tttdm A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-tttdm;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tttdm.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-tttdm.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tttdm.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-tttdm.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tttdm.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-tttdm.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tttdm.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tttdm.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tttdm.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-tttdm.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tttdm.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-tttdm.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tttdm.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 204.200.100.10.in-addr.arpa. PTR)" && echo OK > /results/10.100.200.204_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 204.200.100.10.in-addr.arpa. PTR)" && echo OK > /results/10.100.200.204_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tttdm A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-tttdm;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tttdm A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-tttdm;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tttdm.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-tttdm.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tttdm.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-tttdm.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tttdm.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-tttdm.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tttdm.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tttdm.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tttdm.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-tttdm.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tttdm.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-tttdm.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tttdm.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 204.200.100.10.in-addr.arpa. PTR)" && echo OK > /results/10.100.200.204_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 204.200.100.10.in-addr.arpa. PTR)" && echo OK > /results/10.100.200.204_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan  9 22:54:43.125: INFO: DNS probes using e2e-tests-dns-tttdm/dns-test-85254646-1461-11e9-a046-02505600000d succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:54:43.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-tttdm" for this suite.
Jan  9 22:54:49.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:54:49.286: INFO: namespace: e2e-tests-dns-tttdm, resource: bindings, ignored listing per whitelist
Jan  9 22:54:49.290: INFO: namespace e2e-tests-dns-tttdm deletion completed in 6.093546747s

• [SLOW TEST:20.545 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:54:49.293: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-hjjl5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan  9 22:54:49.491: INFO: Waiting up to 5m0s for pod "pod-915eaf5d-1461-11e9-a046-02505600000d" in namespace "e2e-tests-emptydir-hjjl5" to be "success or failure"
Jan  9 22:54:49.500: INFO: Pod "pod-915eaf5d-1461-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.50833ms
Jan  9 22:54:51.504: INFO: Pod "pod-915eaf5d-1461-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012322845s
Jan  9 22:54:53.507: INFO: Pod "pod-915eaf5d-1461-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015835954s
STEP: Saw pod success
Jan  9 22:54:53.508: INFO: Pod "pod-915eaf5d-1461-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:54:53.510: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-915eaf5d-1461-11e9-a046-02505600000d container test-container: <nil>
STEP: delete the pod
Jan  9 22:54:53.531: INFO: Waiting for pod pod-915eaf5d-1461-11e9-a046-02505600000d to disappear
Jan  9 22:54:53.535: INFO: Pod pod-915eaf5d-1461-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:54:53.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hjjl5" for this suite.
Jan  9 22:54:59.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:54:59.573: INFO: namespace: e2e-tests-emptydir-hjjl5, resource: bindings, ignored listing per whitelist
Jan  9 22:54:59.636: INFO: namespace e2e-tests-emptydir-hjjl5 deletion completed in 6.097256218s

• [SLOW TEST:10.343 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:54:59.638: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-5qkw9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 22:54:59.881: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"978e928d-1461-11e9-9de1-005056902d46", Controller:(*bool)(0xc420f1d7a6), BlockOwnerDeletion:(*bool)(0xc420f1d7a7)}}
Jan  9 22:54:59.886: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"978abe3b-1461-11e9-9de1-005056902d46", Controller:(*bool)(0xc4213d7bb6), BlockOwnerDeletion:(*bool)(0xc4213d7bb7)}}
Jan  9 22:54:59.903: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"978ba4ce-1461-11e9-9de1-005056902d46", Controller:(*bool)(0xc420f1d9fe), BlockOwnerDeletion:(*bool)(0xc420f1d9ff)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:55:04.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-5qkw9" for this suite.
Jan  9 22:55:10.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:55:10.997: INFO: namespace: e2e-tests-gc-5qkw9, resource: bindings, ignored listing per whitelist
Jan  9 22:55:11.007: INFO: namespace e2e-tests-gc-5qkw9 deletion completed in 6.087771502s

• [SLOW TEST:11.369 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:55:11.008: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-nfn46
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 22:55:11.192: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9e4e6174-1461-11e9-a046-02505600000d" in namespace "e2e-tests-downward-api-nfn46" to be "success or failure"
Jan  9 22:55:11.223: INFO: Pod "downwardapi-volume-9e4e6174-1461-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 30.670455ms
Jan  9 22:55:13.226: INFO: Pod "downwardapi-volume-9e4e6174-1461-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034354168s
Jan  9 22:55:15.232: INFO: Pod "downwardapi-volume-9e4e6174-1461-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040265805s
STEP: Saw pod success
Jan  9 22:55:15.232: INFO: Pod "downwardapi-volume-9e4e6174-1461-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:55:15.235: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod downwardapi-volume-9e4e6174-1461-11e9-a046-02505600000d container client-container: <nil>
STEP: delete the pod
Jan  9 22:55:15.255: INFO: Waiting for pod downwardapi-volume-9e4e6174-1461-11e9-a046-02505600000d to disappear
Jan  9 22:55:15.259: INFO: Pod downwardapi-volume-9e4e6174-1461-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:55:15.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nfn46" for this suite.
Jan  9 22:55:21.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:55:21.322: INFO: namespace: e2e-tests-downward-api-nfn46, resource: bindings, ignored listing per whitelist
Jan  9 22:55:21.359: INFO: namespace e2e-tests-downward-api-nfn46 deletion completed in 6.095738623s

• [SLOW TEST:10.351 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:55:21.362: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-r978s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 22:55:21.570: INFO: Creating deployment "nginx-deployment"
Jan  9 22:55:21.578: INFO: Waiting for observed generation 1
Jan  9 22:55:23.586: INFO: Waiting for all required pods to come up
Jan  9 22:55:23.593: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jan  9 22:55:27.605: INFO: Waiting for deployment "nginx-deployment" to complete
Jan  9 22:55:27.612: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jan  9 22:55:27.620: INFO: Updating deployment nginx-deployment
Jan  9 22:55:27.620: INFO: Waiting for observed generation 2
Jan  9 22:55:29.627: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jan  9 22:55:29.629: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jan  9 22:55:29.632: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan  9 22:55:29.638: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jan  9 22:55:29.638: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jan  9 22:55:29.640: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan  9 22:55:29.644: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jan  9 22:55:29.644: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jan  9 22:55:29.652: INFO: Updating deployment nginx-deployment
Jan  9 22:55:29.652: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jan  9 22:55:29.659: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jan  9 22:55:29.665: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan  9 22:55:29.719: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-r978s,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-r978s/deployments/nginx-deployment,UID:a47fc339-1461-11e9-9de1-005056902d46,ResourceVersion:15020,Generation:3,CreationTimestamp:2019-01-09 22:55:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-01-09 22:55:27 +0000 UTC 2019-01-09 22:55:21 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.} {Available False 2019-01-09 22:55:29 +0000 UTC 2019-01-09 22:55:29 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Jan  9 22:55:29.741: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-r978s,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-r978s/replicasets/nginx-deployment-7dc8f79789,UID:a81ac1f1-1461-11e9-9de1-005056902d46,ResourceVersion:15001,Generation:3,CreationTimestamp:2019-01-09 22:55:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment a47fc339-1461-11e9-9de1-005056902d46 0xc420de8b97 0xc420de8b98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan  9 22:55:29.741: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jan  9 22:55:29.741: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-r978s,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-r978s/replicasets/nginx-deployment-7f9675fb8b,UID:a482088e-1461-11e9-9de1-005056902d46,ResourceVersion:14999,Generation:3,CreationTimestamp:2019-01-09 22:55:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment a47fc339-1461-11e9-9de1-005056902d46 0xc420de8c57 0xc420de8c58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jan  9 22:55:29.777: INFO: Pod "nginx-deployment-7dc8f79789-6tfvc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-6tfvc,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7dc8f79789-6tfvc,UID:a81b9703-1461-11e9-9de1-005056902d46,ResourceVersion:14960,Generation:0,CreationTimestamp:2019-01-09 22:55:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 a81ac1f1-1461-11e9-9de1-005056902d46 0xc420de9507 0xc420de9508}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:582539c0-37f1-42db-85f2-2655dcef1574,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420de9570} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420de9590}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:,StartTime:2019-01-09 22:55:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.777: INFO: Pod "nginx-deployment-7dc8f79789-8k4s9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-8k4s9,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7dc8f79789-8k4s9,UID:a957c20c-1461-11e9-9de1-005056902d46,ResourceVersion:15013,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 a81ac1f1-1461-11e9-9de1-005056902d46 0xc420de9650 0xc420de9651}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420de96c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420de96e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.778: INFO: Pod "nginx-deployment-7dc8f79789-f4kvb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-f4kvb,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7dc8f79789-f4kvb,UID:a95c9331-1461-11e9-9de1-005056902d46,ResourceVersion:15023,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 a81ac1f1-1461-11e9-9de1-005056902d46 0xc420de9737 0xc420de9738}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420de97a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420de97c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.778: INFO: Pod "nginx-deployment-7dc8f79789-fpqzn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-fpqzn,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7dc8f79789-fpqzn,UID:a953d8bc-1461-11e9-9de1-005056902d46,ResourceVersion:15019,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 a81ac1f1-1461-11e9-9de1-005056902d46 0xc420de9817 0xc420de9818}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:582539c0-37f1-42db-85f2-2655dcef1574,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420de9880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420de98a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.778: INFO: Pod "nginx-deployment-7dc8f79789-k8vhn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-k8vhn,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7dc8f79789-k8vhn,UID:a9586aeb-1461-11e9-9de1-005056902d46,ResourceVersion:15018,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 a81ac1f1-1461-11e9-9de1-005056902d46 0xc420de9910 0xc420de9911}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420de9980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420de99a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.778: INFO: Pod "nginx-deployment-7dc8f79789-nf6lg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-nf6lg,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7dc8f79789-nf6lg,UID:a95da6c0-1461-11e9-9de1-005056902d46,ResourceVersion:15029,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 a81ac1f1-1461-11e9-9de1-005056902d46 0xc420de99f7 0xc420de99f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420de9a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420de9a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.779: INFO: Pod "nginx-deployment-7dc8f79789-nfbf6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-nfbf6,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7dc8f79789-nfbf6,UID:a82ae168-1461-11e9-9de1-005056902d46,ResourceVersion:14989,Generation:0,CreationTimestamp:2019-01-09 22:55:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 a81ac1f1-1461-11e9-9de1-005056902d46 0xc420de9ad7 0xc420de9ad8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:362e6945-cc10-4a7c-ad11-8cf4815006e1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420de9b40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420de9b60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.4,PodIP:,StartTime:2019-01-09 22:55:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.779: INFO: Pod "nginx-deployment-7dc8f79789-prqjw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-prqjw,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7dc8f79789-prqjw,UID:a81d3421-1461-11e9-9de1-005056902d46,ResourceVersion:14968,Generation:0,CreationTimestamp:2019-01-09 22:55:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 a81ac1f1-1461-11e9-9de1-005056902d46 0xc420de9c20 0xc420de9c21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:362e6945-cc10-4a7c-ad11-8cf4815006e1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420de9c90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420de9cb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.4,PodIP:,StartTime:2019-01-09 22:55:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.780: INFO: Pod "nginx-deployment-7dc8f79789-s2wln" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-s2wln,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7dc8f79789-s2wln,UID:a81d0b50-1461-11e9-9de1-005056902d46,ResourceVersion:14963,Generation:0,CreationTimestamp:2019-01-09 22:55:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 a81ac1f1-1461-11e9-9de1-005056902d46 0xc420de9d70 0xc420de9d71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:50ed3ea8-4626-444e-b102-822e7e7faeed,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420de9de0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420de9e00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.5,PodIP:,StartTime:2019-01-09 22:55:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.780: INFO: Pod "nginx-deployment-7dc8f79789-sghcp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-sghcp,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7dc8f79789-sghcp,UID:a95db199-1461-11e9-9de1-005056902d46,ResourceVersion:15030,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 a81ac1f1-1461-11e9-9de1-005056902d46 0xc420de9ec0 0xc420de9ec1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420de9f30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420de9f50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.780: INFO: Pod "nginx-deployment-7dc8f79789-tq6rt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-tq6rt,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7dc8f79789-tq6rt,UID:a95d90bb-1461-11e9-9de1-005056902d46,ResourceVersion:15027,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 a81ac1f1-1461-11e9-9de1-005056902d46 0xc420de9fa7 0xc420de9fa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42121c020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42121c050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.781: INFO: Pod "nginx-deployment-7dc8f79789-xd6mm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-xd6mm,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7dc8f79789-xd6mm,UID:a828b215-1461-11e9-9de1-005056902d46,ResourceVersion:14983,Generation:0,CreationTimestamp:2019-01-09 22:55:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 a81ac1f1-1461-11e9-9de1-005056902d46 0xc42121c0b7 0xc42121c0b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:50ed3ea8-4626-444e-b102-822e7e7faeed,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42121c130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42121c150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:27 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.5,PodIP:,StartTime:2019-01-09 22:55:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.781: INFO: Pod "nginx-deployment-7f9675fb8b-4xg2r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-4xg2r,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-4xg2r,UID:a95dd4e0-1461-11e9-9de1-005056902d46,ResourceVersion:15032,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc42121c210 0xc42121c211}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42121c270} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42121c290}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.782: INFO: Pod "nginx-deployment-7f9675fb8b-4xhjq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-4xhjq,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-4xhjq,UID:a48d5945-1461-11e9-9de1-005056902d46,ResourceVersion:14919,Generation:0,CreationTimestamp:2019-01-09 22:55:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc42121c2f7 0xc42121c2f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:582539c0-37f1-42db-85f2-2655dcef1574,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42121c370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42121c3c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:21 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:40.0.5.6,StartTime:2019-01-09 22:55:21 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-09 22:55:25 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://48b2fcf555a6f8b31e58ce8ffe58ad2986776e97806ca26a39525cc2799c2a1a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.782: INFO: Pod "nginx-deployment-7f9675fb8b-5zs9n" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-5zs9n,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-5zs9n,UID:a48d1ce7-1461-11e9-9de1-005056902d46,ResourceVersion:14901,Generation:0,CreationTimestamp:2019-01-09 22:55:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc42121c477 0xc42121c478}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:50ed3ea8-4626-444e-b102-822e7e7faeed,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42121c4e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42121c500}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:21 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.5,PodIP:40.0.5.5,StartTime:2019-01-09 22:55:21 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-09 22:55:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://32e44c54df8d7bd1d5269de7451f2d655705917624af1e6b8f719e78ff0d7067}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.782: INFO: Pod "nginx-deployment-7f9675fb8b-cd8p6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-cd8p6,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-cd8p6,UID:a95760bd-1461-11e9-9de1-005056902d46,ResourceVersion:15022,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc42121c5c7 0xc42121c5c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:582539c0-37f1-42db-85f2-2655dcef1574,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42121c630} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42121c650}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.783: INFO: Pod "nginx-deployment-7f9675fb8b-ddr7f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ddr7f,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-ddr7f,UID:a95d9c71-1461-11e9-9de1-005056902d46,ResourceVersion:15028,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc42121c6d0 0xc42121c6d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42121c970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42121c990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.783: INFO: Pod "nginx-deployment-7f9675fb8b-flxgk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-flxgk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-flxgk,UID:a4865898-1461-11e9-9de1-005056902d46,ResourceVersion:14881,Generation:0,CreationTimestamp:2019-01-09 22:55:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc42121c9e7 0xc42121c9e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:50ed3ea8-4626-444e-b102-822e7e7faeed,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42121ca50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42121ca70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:21 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.5,PodIP:40.0.5.3,StartTime:2019-01-09 22:55:21 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-09 22:55:23 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://c9c7c17314ea9f6c9ddb7701d21cb80f7ed5f4fdab3bf6e37839fc112fe9bde5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.783: INFO: Pod "nginx-deployment-7f9675fb8b-h8d9l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-h8d9l,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-h8d9l,UID:a95d73dd-1461-11e9-9de1-005056902d46,ResourceVersion:15025,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc42121cbb7 0xc42121cbb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42121cc20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42121cc40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.784: INFO: Pod "nginx-deployment-7f9675fb8b-hh947" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hh947,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-hh947,UID:a48d8fe0-1461-11e9-9de1-005056902d46,ResourceVersion:14928,Generation:0,CreationTimestamp:2019-01-09 22:55:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc42121cfa7 0xc42121cfa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:50ed3ea8-4626-444e-b102-822e7e7faeed,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42121d010} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42121d030}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:21 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.5,PodIP:40.0.5.7,StartTime:2019-01-09 22:55:21 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-09 22:55:25 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://f80cfc9865caff1f296b149eff1d643d86911498add2781d1ea304da0297a565}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.784: INFO: Pod "nginx-deployment-7f9675fb8b-jg2p9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jg2p9,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-jg2p9,UID:a95465cc-1461-11e9-9de1-005056902d46,ResourceVersion:15014,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc42121d0e7 0xc42121d0e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:362e6945-cc10-4a7c-ad11-8cf4815006e1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42121d420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42121d440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.784: INFO: Pod "nginx-deployment-7f9675fb8b-lzfgj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-lzfgj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-lzfgj,UID:a9539034-1461-11e9-9de1-005056902d46,ResourceVersion:15006,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc42121d4b0 0xc42121d4b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:362e6945-cc10-4a7c-ad11-8cf4815006e1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42121d510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42121d540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:29 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.785: INFO: Pod "nginx-deployment-7f9675fb8b-mn2wv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mn2wv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-mn2wv,UID:a49255b2-1461-11e9-9de1-005056902d46,ResourceVersion:14923,Generation:0,CreationTimestamp:2019-01-09 22:55:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc42121d860 0xc42121d861}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:582539c0-37f1-42db-85f2-2655dcef1574,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42121d8c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42121d8e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:21 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:40.0.5.9,StartTime:2019-01-09 22:55:21 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-09 22:55:25 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://186428e31e946235bd82ff5b272d83716e81642ccbcdec90f2a1ef8b4d406299}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.785: INFO: Pod "nginx-deployment-7f9675fb8b-pdlk4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-pdlk4,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-pdlk4,UID:a95d5e91-1461-11e9-9de1-005056902d46,ResourceVersion:15024,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc42121db47 0xc42121db48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42121dbb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42121dbd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.785: INFO: Pod "nginx-deployment-7f9675fb8b-pgqlp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-pgqlp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-pgqlp,UID:a95853ab-1461-11e9-9de1-005056902d46,ResourceVersion:15017,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc42121dc27 0xc42121dc28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42121dd00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42121dd20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.786: INFO: Pod "nginx-deployment-7f9675fb8b-pqp8g" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-pqp8g,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-pqp8g,UID:a48511ea-1461-11e9-9de1-005056902d46,ResourceVersion:14892,Generation:0,CreationTimestamp:2019-01-09 22:55:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc42121dd77 0xc42121dd78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:362e6945-cc10-4a7c-ad11-8cf4815006e1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42121dde0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42121de00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:21 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.4,PodIP:40.0.5.2,StartTime:2019-01-09 22:55:21 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-09 22:55:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://a563cd962ba4b3749a5230b730e15d1286a9d8268a15bd1be2a564ff45d1a586}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.786: INFO: Pod "nginx-deployment-7f9675fb8b-psdzw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-psdzw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-psdzw,UID:a492f725-1461-11e9-9de1-005056902d46,ResourceVersion:14926,Generation:0,CreationTimestamp:2019-01-09 22:55:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc42121def7 0xc42121def8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:50ed3ea8-4626-444e-b102-822e7e7faeed,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42121df60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42121df80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:21 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.5,PodIP:40.0.5.10,StartTime:2019-01-09 22:55:21 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-09 22:55:25 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://83f3391fb8c3edc105398b456c58c10d24fbfaac5bbd8102c5476ba2631a2a81}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.787: INFO: Pod "nginx-deployment-7f9675fb8b-rnq5z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rnq5z,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-rnq5z,UID:a95dc9ba-1461-11e9-9de1-005056902d46,ResourceVersion:15031,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc422c64070 0xc422c64071}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c640d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c640f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.787: INFO: Pod "nginx-deployment-7f9675fb8b-w65zc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-w65zc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-w65zc,UID:a95814f6-1461-11e9-9de1-005056902d46,ResourceVersion:15015,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc422c64147 0xc422c64148}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c64230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c64250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.787: INFO: Pod "nginx-deployment-7f9675fb8b-wpx2z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-wpx2z,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-wpx2z,UID:a95836eb-1461-11e9-9de1-005056902d46,ResourceVersion:15016,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc422c642a7 0xc422c642a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c64310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c64340}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.787: INFO: Pod "nginx-deployment-7f9675fb8b-xhgsw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xhgsw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-xhgsw,UID:a487b065-1461-11e9-9de1-005056902d46,ResourceVersion:14894,Generation:0,CreationTimestamp:2019-01-09 22:55:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc422c64417 0xc422c64418}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:582539c0-37f1-42db-85f2-2655dcef1574,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c64480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c644a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:21 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.3,PodIP:40.0.5.4,StartTime:2019-01-09 22:55:21 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-09 22:55:24 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://c340a62e6056dce866649df2ae089c2ea8bcf1240c1c3107d63fba79577c4487}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan  9 22:55:29.788: INFO: Pod "nginx-deployment-7f9675fb8b-xp49c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xp49c,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-r978s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r978s/pods/nginx-deployment-7f9675fb8b-xp49c,UID:a951c4e1-1461-11e9-9de1-005056902d46,ResourceVersion:15033,Generation:0,CreationTimestamp:2019-01-09 22:55:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b a482088e-1461-11e9-9de1-005056902d46 0xc422c64607 0xc422c64608}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-l6wjb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-l6wjb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-l6wjb true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:362e6945-cc10-4a7c-ad11-8cf4815006e1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422c64670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422c64690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:29 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 22:55:29 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.4,PodIP:,StartTime:2019-01-09 22:55:29 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:55:29.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-r978s" for this suite.
Jan  9 22:55:37.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:55:37.915: INFO: namespace: e2e-tests-deployment-r978s, resource: bindings, ignored listing per whitelist
Jan  9 22:55:37.969: INFO: namespace e2e-tests-deployment-r978s deletion completed in 8.162270719s

• [SLOW TEST:16.607 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:55:37.972: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-r7j7f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-r7j7f
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-r7j7f
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-r7j7f
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-r7j7f
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-r7j7f
Jan  9 22:55:42.223: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-r7j7f, name: ss-0, uid: b0a21130-1461-11e9-9de1-005056902d46, status phase: Pending. Waiting for statefulset controller to delete.
Jan  9 22:55:42.506: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-r7j7f, name: ss-0, uid: b0a21130-1461-11e9-9de1-005056902d46, status phase: Failed. Waiting for statefulset controller to delete.
Jan  9 22:55:42.515: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-r7j7f, name: ss-0, uid: b0a21130-1461-11e9-9de1-005056902d46, status phase: Failed. Waiting for statefulset controller to delete.
Jan  9 22:55:42.540: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-r7j7f
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-r7j7f
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-r7j7f and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan  9 22:55:46.588: INFO: Deleting all statefulset in ns e2e-tests-statefulset-r7j7f
Jan  9 22:55:46.591: INFO: Scaling statefulset ss to 0
Jan  9 22:55:56.621: INFO: Waiting for statefulset status.replicas updated to 0
Jan  9 22:55:56.624: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:55:56.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-r7j7f" for this suite.
Jan  9 22:56:02.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:56:02.686: INFO: namespace: e2e-tests-statefulset-r7j7f, resource: bindings, ignored listing per whitelist
Jan  9 22:56:02.738: INFO: namespace e2e-tests-statefulset-r7j7f deletion completed in 6.08760596s

• [SLOW TEST:24.766 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:56:02.738: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-x95hj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 22:56:02.943: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bd2793b0-1461-11e9-a046-02505600000d" in namespace "e2e-tests-downward-api-x95hj" to be "success or failure"
Jan  9 22:56:02.947: INFO: Pod "downwardapi-volume-bd2793b0-1461-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.877022ms
Jan  9 22:56:04.950: INFO: Pod "downwardapi-volume-bd2793b0-1461-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006967962s
Jan  9 22:56:06.953: INFO: Pod "downwardapi-volume-bd2793b0-1461-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010597962s
STEP: Saw pod success
Jan  9 22:56:06.954: INFO: Pod "downwardapi-volume-bd2793b0-1461-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:56:06.956: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod downwardapi-volume-bd2793b0-1461-11e9-a046-02505600000d container client-container: <nil>
STEP: delete the pod
Jan  9 22:56:06.976: INFO: Waiting for pod downwardapi-volume-bd2793b0-1461-11e9-a046-02505600000d to disappear
Jan  9 22:56:06.979: INFO: Pod downwardapi-volume-bd2793b0-1461-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:56:06.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-x95hj" for this suite.
Jan  9 22:56:12.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:56:13.033: INFO: namespace: e2e-tests-downward-api-x95hj, resource: bindings, ignored listing per whitelist
Jan  9 22:56:13.070: INFO: namespace e2e-tests-downward-api-x95hj deletion completed in 6.087700507s

• [SLOW TEST:10.333 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:56:13.073: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-7sxfs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 22:56:13.261: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c34da0e7-1461-11e9-a046-02505600000d" in namespace "e2e-tests-downward-api-7sxfs" to be "success or failure"
Jan  9 22:56:13.274: INFO: Pod "downwardapi-volume-c34da0e7-1461-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.507195ms
Jan  9 22:56:15.277: INFO: Pod "downwardapi-volume-c34da0e7-1461-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015772231s
Jan  9 22:56:17.281: INFO: Pod "downwardapi-volume-c34da0e7-1461-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019311221s
STEP: Saw pod success
Jan  9 22:56:17.281: INFO: Pod "downwardapi-volume-c34da0e7-1461-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 22:56:17.283: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod downwardapi-volume-c34da0e7-1461-11e9-a046-02505600000d container client-container: <nil>
STEP: delete the pod
Jan  9 22:56:17.306: INFO: Waiting for pod downwardapi-volume-c34da0e7-1461-11e9-a046-02505600000d to disappear
Jan  9 22:56:17.307: INFO: Pod downwardapi-volume-c34da0e7-1461-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 22:56:17.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7sxfs" for this suite.
Jan  9 22:56:23.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 22:56:23.368: INFO: namespace: e2e-tests-downward-api-7sxfs, resource: bindings, ignored listing per whitelist
Jan  9 22:56:23.404: INFO: namespace e2e-tests-downward-api-7sxfs deletion completed in 6.094247354s

• [SLOW TEST:10.331 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 22:56:23.404: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-zzdp5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-zzdp5
Jan  9 22:56:27.613: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-zzdp5
STEP: checking the pod's current state and verifying that restartCount is present
Jan  9 22:56:27.616: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:00:28.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zzdp5" for this suite.
Jan  9 23:00:34.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:00:34.202: INFO: namespace: e2e-tests-container-probe-zzdp5, resource: bindings, ignored listing per whitelist
Jan  9 23:00:34.209: INFO: namespace e2e-tests-container-probe-zzdp5 deletion completed in 6.109465341s

• [SLOW TEST:250.804 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:00:34.211: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-j4jg8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 23:00:34.411: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5ef5f89d-1462-11e9-a046-02505600000d" in namespace "e2e-tests-projected-j4jg8" to be "success or failure"
Jan  9 23:00:34.415: INFO: Pod "downwardapi-volume-5ef5f89d-1462-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.232211ms
Jan  9 23:00:36.419: INFO: Pod "downwardapi-volume-5ef5f89d-1462-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007382487s
Jan  9 23:00:38.422: INFO: Pod "downwardapi-volume-5ef5f89d-1462-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010331568s
STEP: Saw pod success
Jan  9 23:00:38.422: INFO: Pod "downwardapi-volume-5ef5f89d-1462-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:00:38.426: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod downwardapi-volume-5ef5f89d-1462-11e9-a046-02505600000d container client-container: <nil>
STEP: delete the pod
Jan  9 23:00:38.451: INFO: Waiting for pod downwardapi-volume-5ef5f89d-1462-11e9-a046-02505600000d to disappear
Jan  9 23:00:38.455: INFO: Pod downwardapi-volume-5ef5f89d-1462-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:00:38.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j4jg8" for this suite.
Jan  9 23:00:44.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:00:44.571: INFO: namespace: e2e-tests-projected-j4jg8, resource: bindings, ignored listing per whitelist
Jan  9 23:00:44.576: INFO: namespace e2e-tests-projected-j4jg8 deletion completed in 6.118172223s

• [SLOW TEST:10.366 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:00:44.579: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-9rdvg
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-6527756a-1462-11e9-a046-02505600000d
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-6527756a-1462-11e9-a046-02505600000d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:00:48.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9rdvg" for this suite.
Jan  9 23:01:10.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:01:10.918: INFO: namespace: e2e-tests-configmap-9rdvg, resource: bindings, ignored listing per whitelist
Jan  9 23:01:10.959: INFO: namespace e2e-tests-configmap-9rdvg deletion completed in 22.089170694s

• [SLOW TEST:26.381 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:01:10.961: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-q9qct
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan  9 23:01:21.184: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 23:01:21.187: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 23:01:23.187: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 23:01:23.191: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 23:01:25.187: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 23:01:25.191: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 23:01:27.188: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 23:01:27.191: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 23:01:29.187: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 23:01:29.192: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 23:01:31.187: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 23:01:31.191: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 23:01:33.188: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 23:01:33.193: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 23:01:35.188: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 23:01:35.193: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 23:01:37.188: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 23:01:37.191: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 23:01:39.187: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 23:01:39.191: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 23:01:41.188: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 23:01:41.192: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 23:01:43.188: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 23:01:43.192: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 23:01:45.187: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 23:01:45.191: INFO: Pod pod-with-poststart-exec-hook still exists
Jan  9 23:01:47.187: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan  9 23:01:47.191: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:01:47.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-q9qct" for this suite.
Jan  9 23:01:59.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:01:59.228: INFO: namespace: e2e-tests-container-lifecycle-hook-q9qct, resource: bindings, ignored listing per whitelist
Jan  9 23:01:59.292: INFO: namespace e2e-tests-container-lifecycle-hook-q9qct deletion completed in 12.097225735s

• [SLOW TEST:48.332 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:01:59.294: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-rf99s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 23:01:59.481: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jan  9 23:02:04.487: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan  9 23:02:04.487: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan  9 23:02:04.505: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-rf99s,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rf99s/deployments/test-cleanup-deployment,UID:94a8c52d-1462-11e9-9de1-005056902d46,ResourceVersion:16163,Generation:1,CreationTimestamp:2019-01-09 23:02:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jan  9 23:02:04.512: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:02:04.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-rf99s" for this suite.
Jan  9 23:02:10.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:02:10.662: INFO: namespace: e2e-tests-deployment-rf99s, resource: bindings, ignored listing per whitelist
Jan  9 23:02:10.692: INFO: namespace e2e-tests-deployment-rf99s deletion completed in 6.105216796s

• [SLOW TEST:11.399 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:02:10.693: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-hpxjr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 23:02:10.892: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jan  9 23:02:10.904: INFO: Number of nodes with available pods: 0
Jan  9 23:02:10.904: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:02:11.911: INFO: Number of nodes with available pods: 0
Jan  9 23:02:11.911: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:02:12.911: INFO: Number of nodes with available pods: 1
Jan  9 23:02:12.911: INFO: Node 50ed3ea8-4626-444e-b102-822e7e7faeed is running more than one daemon pod
Jan  9 23:02:13.913: INFO: Number of nodes with available pods: 2
Jan  9 23:02:13.913: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:02:14.913: INFO: Number of nodes with available pods: 2
Jan  9 23:02:14.913: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:02:15.916: INFO: Number of nodes with available pods: 2
Jan  9 23:02:15.916: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:02:16.914: INFO: Number of nodes with available pods: 2
Jan  9 23:02:16.914: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:02:17.912: INFO: Number of nodes with available pods: 3
Jan  9 23:02:17.912: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jan  9 23:02:17.945: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:17.946: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:17.946: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:18.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:18.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:18.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:19.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:19.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:19.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:20.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:20.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:20.957: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:21.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:21.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:21.957: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:22.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:22.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:22.957: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:23.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:23.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:23.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:24.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:24.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:24.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:25.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:25.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:25.959: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:26.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:26.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:26.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:27.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:27.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:27.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:28.959: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:28.959: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:28.959: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:29.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:29.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:29.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:30.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:30.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:30.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:31.964: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:31.964: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:31.965: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:32.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:32.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:32.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:33.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:33.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:33.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:34.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:34.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:34.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:35.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:35.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:35.957: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:36.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:36.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:36.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:37.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:37.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:37.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:38.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:38.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:38.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:39.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:39.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:39.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:40.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:40.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:40.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:41.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:41.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:41.957: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:42.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:42.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:42.957: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:43.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:43.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:43.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:44.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:44.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:44.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:45.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:45.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:45.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:46.959: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:46.959: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:46.959: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:47.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:47.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:47.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:48.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:48.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:48.957: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:49.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:49.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:49.957: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:50.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:50.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:50.958: INFO: Wrong image for pod: daemon-set-t8hkk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:50.958: INFO: Pod daemon-set-t8hkk is not available
Jan  9 23:02:51.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:51.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:51.957: INFO: Pod daemon-set-vs5wl is not available
Jan  9 23:02:52.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:52.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:52.957: INFO: Pod daemon-set-vs5wl is not available
Jan  9 23:02:53.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:53.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:53.957: INFO: Pod daemon-set-vs5wl is not available
Jan  9 23:02:54.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:54.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:54.958: INFO: Pod daemon-set-vs5wl is not available
Jan  9 23:02:55.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:55.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:55.958: INFO: Pod daemon-set-vs5wl is not available
Jan  9 23:02:56.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:56.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:56.957: INFO: Pod daemon-set-vs5wl is not available
Jan  9 23:02:57.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:57.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:58.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:58.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:59.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:02:59.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:00.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:00.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:01.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:01.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:02.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:02.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:03.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:03.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:04.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:04.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:05.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:05.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:06.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:06.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:07.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:07.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:08.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:08.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:09.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:09.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:10.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:10.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:11.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:11.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:12.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:12.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:13.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:13.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:14.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:14.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:15.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:15.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:16.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:16.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:17.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:17.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:18.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:18.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:19.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:19.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:20.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:20.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:21.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:21.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:22.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:22.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:23.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:23.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:24.960: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:24.960: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:25.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:25.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:26.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:26.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:27.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:27.957: INFO: Pod daemon-set-p6582 is not available
Jan  9 23:03:27.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:28.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:28.959: INFO: Pod daemon-set-p6582 is not available
Jan  9 23:03:28.959: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:29.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:29.958: INFO: Pod daemon-set-p6582 is not available
Jan  9 23:03:29.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:30.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:30.958: INFO: Pod daemon-set-p6582 is not available
Jan  9 23:03:30.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:31.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:31.958: INFO: Pod daemon-set-p6582 is not available
Jan  9 23:03:31.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:32.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:32.957: INFO: Pod daemon-set-p6582 is not available
Jan  9 23:03:32.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:33.957: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:33.958: INFO: Pod daemon-set-p6582 is not available
Jan  9 23:03:33.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:34.958: INFO: Wrong image for pod: daemon-set-p6582. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:34.958: INFO: Pod daemon-set-p6582 is not available
Jan  9 23:03:34.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:35.957: INFO: Pod daemon-set-8vnz4 is not available
Jan  9 23:03:35.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:36.958: INFO: Pod daemon-set-8vnz4 is not available
Jan  9 23:03:36.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:37.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:38.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:39.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:40.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:41.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:42.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:43.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:44.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:45.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:46.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:47.962: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:48.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:49.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:50.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:51.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:52.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:53.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:54.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:55.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:56.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:57.956: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:58.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:03:59.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:04:00.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:04:01.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:04:02.962: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:04:03.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:04:04.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:04:05.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:04:06.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:04:07.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:04:07.957: INFO: Pod daemon-set-rhzhr is not available
Jan  9 23:04:08.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:04:08.957: INFO: Pod daemon-set-rhzhr is not available
Jan  9 23:04:09.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:04:09.957: INFO: Pod daemon-set-rhzhr is not available
Jan  9 23:04:10.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:04:10.957: INFO: Pod daemon-set-rhzhr is not available
Jan  9 23:04:11.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:04:11.958: INFO: Pod daemon-set-rhzhr is not available
Jan  9 23:04:12.957: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:04:12.957: INFO: Pod daemon-set-rhzhr is not available
Jan  9 23:04:13.977: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:04:13.977: INFO: Pod daemon-set-rhzhr is not available
Jan  9 23:04:14.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:04:14.958: INFO: Pod daemon-set-rhzhr is not available
Jan  9 23:04:15.958: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:04:15.958: INFO: Pod daemon-set-rhzhr is not available
Jan  9 23:04:16.959: INFO: Wrong image for pod: daemon-set-rhzhr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan  9 23:04:16.959: INFO: Pod daemon-set-rhzhr is not available
Jan  9 23:04:17.958: INFO: Pod daemon-set-vqfgx is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Jan  9 23:04:17.970: INFO: Number of nodes with available pods: 2
Jan  9 23:04:17.971: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:04:18.979: INFO: Number of nodes with available pods: 2
Jan  9 23:04:18.980: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:04:19.977: INFO: Number of nodes with available pods: 3
Jan  9 23:04:19.977: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-hpxjr, will wait for the garbage collector to delete the pods
Jan  9 23:04:20.056: INFO: Deleting {extensions DaemonSet} daemon-set took: 11.321452ms
Jan  9 23:04:20.157: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.934646ms
Jan  9 23:04:27.160: INFO: Number of nodes with available pods: 0
Jan  9 23:04:27.160: INFO: Number of running nodes: 0, number of available pods: 0
Jan  9 23:04:27.164: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hpxjr/daemonsets","resourceVersion":"16520"},"items":null}

Jan  9 23:04:27.166: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hpxjr/pods","resourceVersion":"16520"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:04:27.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hpxjr" for this suite.
Jan  9 23:04:33.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:04:33.222: INFO: namespace: e2e-tests-daemonsets-hpxjr, resource: bindings, ignored listing per whitelist
Jan  9 23:04:33.281: INFO: namespace e2e-tests-daemonsets-hpxjr deletion completed in 6.101507468s

• [SLOW TEST:142.588 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:04:33.287: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-dgt8l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-ed76b82a-1462-11e9-a046-02505600000d
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-ed76b82a-1462-11e9-a046-02505600000d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:04:39.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dgt8l" for this suite.
Jan  9 23:05:01.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:05:01.582: INFO: namespace: e2e-tests-projected-dgt8l, resource: bindings, ignored listing per whitelist
Jan  9 23:05:01.657: INFO: namespace e2e-tests-projected-dgt8l deletion completed in 22.104918093s

• [SLOW TEST:28.371 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:05:01.659: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-j2lp7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-j2lp7
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan  9 23:05:01.842: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan  9 23:05:29.944: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://40.0.5.2:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-j2lp7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 23:05:29.944: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 23:05:30.075: INFO: Found all expected endpoints: [netserver-0]
Jan  9 23:05:30.078: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://40.0.5.3:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-j2lp7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 23:05:30.078: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 23:05:30.187: INFO: Found all expected endpoints: [netserver-1]
Jan  9 23:05:30.190: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://40.0.5.4:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-j2lp7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 23:05:30.190: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 23:05:30.294: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:05:30.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-j2lp7" for this suite.
Jan  9 23:05:52.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:05:52.340: INFO: namespace: e2e-tests-pod-network-test-j2lp7, resource: bindings, ignored listing per whitelist
Jan  9 23:05:52.413: INFO: namespace e2e-tests-pod-network-test-j2lp7 deletion completed in 22.114341242s

• [SLOW TEST:50.755 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:05:52.414: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-x489w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan  9 23:05:52.601: INFO: Waiting up to 5m0s for pod "pod-1c9d0048-1463-11e9-a046-02505600000d" in namespace "e2e-tests-emptydir-x489w" to be "success or failure"
Jan  9 23:05:52.615: INFO: Pod "pod-1c9d0048-1463-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.06765ms
Jan  9 23:05:54.619: INFO: Pod "pod-1c9d0048-1463-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017415122s
Jan  9 23:05:56.622: INFO: Pod "pod-1c9d0048-1463-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02113879s
STEP: Saw pod success
Jan  9 23:05:56.623: INFO: Pod "pod-1c9d0048-1463-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:05:56.625: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-1c9d0048-1463-11e9-a046-02505600000d container test-container: <nil>
STEP: delete the pod
Jan  9 23:05:56.648: INFO: Waiting for pod pod-1c9d0048-1463-11e9-a046-02505600000d to disappear
Jan  9 23:05:56.651: INFO: Pod pod-1c9d0048-1463-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:05:56.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-x489w" for this suite.
Jan  9 23:06:02.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:06:02.694: INFO: namespace: e2e-tests-emptydir-x489w, resource: bindings, ignored listing per whitelist
Jan  9 23:06:02.760: INFO: namespace e2e-tests-emptydir-x489w deletion completed in 6.104951466s

• [SLOW TEST:10.346 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:06:02.762: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-kpgcw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-22c9056b-1463-11e9-a046-02505600000d
STEP: Creating a pod to test consume configMaps
Jan  9 23:06:02.963: INFO: Waiting up to 5m0s for pod "pod-configmaps-22ca75d2-1463-11e9-a046-02505600000d" in namespace "e2e-tests-configmap-kpgcw" to be "success or failure"
Jan  9 23:06:02.970: INFO: Pod "pod-configmaps-22ca75d2-1463-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.078498ms
Jan  9 23:06:04.976: INFO: Pod "pod-configmaps-22ca75d2-1463-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013011928s
Jan  9 23:06:06.982: INFO: Pod "pod-configmaps-22ca75d2-1463-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018878165s
STEP: Saw pod success
Jan  9 23:06:06.982: INFO: Pod "pod-configmaps-22ca75d2-1463-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:06:06.986: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-configmaps-22ca75d2-1463-11e9-a046-02505600000d container configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 23:06:07.011: INFO: Waiting for pod pod-configmaps-22ca75d2-1463-11e9-a046-02505600000d to disappear
Jan  9 23:06:07.015: INFO: Pod pod-configmaps-22ca75d2-1463-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:06:07.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kpgcw" for this suite.
Jan  9 23:06:13.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:06:13.066: INFO: namespace: e2e-tests-configmap-kpgcw, resource: bindings, ignored listing per whitelist
Jan  9 23:06:13.109: INFO: namespace e2e-tests-configmap-kpgcw deletion completed in 6.090842073s

• [SLOW TEST:10.348 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:06:13.109: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-xltbw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-28f51c8d-1463-11e9-a046-02505600000d
STEP: Creating a pod to test consume configMaps
Jan  9 23:06:13.314: INFO: Waiting up to 5m0s for pod "pod-configmaps-28f5ee8d-1463-11e9-a046-02505600000d" in namespace "e2e-tests-configmap-xltbw" to be "success or failure"
Jan  9 23:06:13.319: INFO: Pod "pod-configmaps-28f5ee8d-1463-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.674638ms
Jan  9 23:06:15.322: INFO: Pod "pod-configmaps-28f5ee8d-1463-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007793141s
Jan  9 23:06:17.325: INFO: Pod "pod-configmaps-28f5ee8d-1463-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011503437s
STEP: Saw pod success
Jan  9 23:06:17.326: INFO: Pod "pod-configmaps-28f5ee8d-1463-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:06:17.329: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-configmaps-28f5ee8d-1463-11e9-a046-02505600000d container configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 23:06:17.348: INFO: Waiting for pod pod-configmaps-28f5ee8d-1463-11e9-a046-02505600000d to disappear
Jan  9 23:06:17.355: INFO: Pod pod-configmaps-28f5ee8d-1463-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:06:17.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xltbw" for this suite.
Jan  9 23:06:23.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:06:23.392: INFO: namespace: e2e-tests-configmap-xltbw, resource: bindings, ignored listing per whitelist
Jan  9 23:06:23.473: INFO: namespace e2e-tests-configmap-xltbw deletion completed in 6.109411601s

• [SLOW TEST:10.364 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:06:23.474: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-xscll
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Jan  9 23:06:23.704: INFO: Waiting up to 5m0s for pod "client-containers-2f2821da-1463-11e9-a046-02505600000d" in namespace "e2e-tests-containers-xscll" to be "success or failure"
Jan  9 23:06:23.718: INFO: Pod "client-containers-2f2821da-1463-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.432178ms
Jan  9 23:06:25.722: INFO: Pod "client-containers-2f2821da-1463-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018143168s
Jan  9 23:06:27.725: INFO: Pod "client-containers-2f2821da-1463-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021574595s
Jan  9 23:06:29.732: INFO: Pod "client-containers-2f2821da-1463-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.028626881s
STEP: Saw pod success
Jan  9 23:06:29.732: INFO: Pod "client-containers-2f2821da-1463-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:06:29.735: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod client-containers-2f2821da-1463-11e9-a046-02505600000d container test-container: <nil>
STEP: delete the pod
Jan  9 23:06:29.760: INFO: Waiting for pod client-containers-2f2821da-1463-11e9-a046-02505600000d to disappear
Jan  9 23:06:29.763: INFO: Pod client-containers-2f2821da-1463-11e9-a046-02505600000d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:06:29.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-xscll" for this suite.
Jan  9 23:06:35.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:06:35.821: INFO: namespace: e2e-tests-containers-xscll, resource: bindings, ignored listing per whitelist
Jan  9 23:06:35.863: INFO: namespace e2e-tests-containers-xscll deletion completed in 6.095119164s

• [SLOW TEST:12.388 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:06:35.864: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-lcshx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan  9 23:06:36.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 create -f - --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:36.985: INFO: stderr: ""
Jan  9 23:06:36.985: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan  9 23:06:36.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:37.090: INFO: stderr: ""
Jan  9 23:06:37.090: INFO: stdout: "update-demo-nautilus-5mj96 update-demo-nautilus-fj7js "
Jan  9 23:06:37.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-5mj96 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:37.206: INFO: stderr: ""
Jan  9 23:06:37.207: INFO: stdout: ""
Jan  9 23:06:37.207: INFO: update-demo-nautilus-5mj96 is created but not running
Jan  9 23:06:42.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:42.310: INFO: stderr: ""
Jan  9 23:06:42.310: INFO: stdout: "update-demo-nautilus-5mj96 update-demo-nautilus-fj7js "
Jan  9 23:06:42.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-5mj96 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:42.428: INFO: stderr: ""
Jan  9 23:06:42.428: INFO: stdout: ""
Jan  9 23:06:42.428: INFO: update-demo-nautilus-5mj96 is created but not running
Jan  9 23:06:47.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:47.534: INFO: stderr: ""
Jan  9 23:06:47.534: INFO: stdout: "update-demo-nautilus-5mj96 update-demo-nautilus-fj7js "
Jan  9 23:06:47.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-5mj96 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:47.632: INFO: stderr: ""
Jan  9 23:06:47.632: INFO: stdout: "true"
Jan  9 23:06:47.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-5mj96 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:47.732: INFO: stderr: ""
Jan  9 23:06:47.732: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 23:06:47.732: INFO: validating pod update-demo-nautilus-5mj96
Jan  9 23:06:47.738: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 23:06:47.738: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 23:06:47.738: INFO: update-demo-nautilus-5mj96 is verified up and running
Jan  9 23:06:47.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-fj7js -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:47.855: INFO: stderr: ""
Jan  9 23:06:47.855: INFO: stdout: "true"
Jan  9 23:06:47.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-fj7js -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:47.951: INFO: stderr: ""
Jan  9 23:06:47.951: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 23:06:47.951: INFO: validating pod update-demo-nautilus-fj7js
Jan  9 23:06:47.957: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 23:06:47.957: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 23:06:47.957: INFO: update-demo-nautilus-fj7js is verified up and running
STEP: scaling down the replication controller
Jan  9 23:06:47.959: INFO: scanned /root for discovery docs: <nil>
Jan  9 23:06:47.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:49.090: INFO: stderr: ""
Jan  9 23:06:49.090: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan  9 23:06:49.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:49.198: INFO: stderr: ""
Jan  9 23:06:49.198: INFO: stdout: "update-demo-nautilus-5mj96 update-demo-nautilus-fj7js "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan  9 23:06:54.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:54.315: INFO: stderr: ""
Jan  9 23:06:54.315: INFO: stdout: "update-demo-nautilus-fj7js "
Jan  9 23:06:54.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-fj7js -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:54.408: INFO: stderr: ""
Jan  9 23:06:54.408: INFO: stdout: "true"
Jan  9 23:06:54.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-fj7js -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:54.512: INFO: stderr: ""
Jan  9 23:06:54.512: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 23:06:54.512: INFO: validating pod update-demo-nautilus-fj7js
Jan  9 23:06:54.516: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 23:06:54.516: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 23:06:54.516: INFO: update-demo-nautilus-fj7js is verified up and running
STEP: scaling up the replication controller
Jan  9 23:06:54.518: INFO: scanned /root for discovery docs: <nil>
Jan  9 23:06:54.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:55.665: INFO: stderr: ""
Jan  9 23:06:55.665: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan  9 23:06:55.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:55.773: INFO: stderr: ""
Jan  9 23:06:55.773: INFO: stdout: "update-demo-nautilus-fj7js update-demo-nautilus-gk6zv "
Jan  9 23:06:55.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-fj7js -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:55.868: INFO: stderr: ""
Jan  9 23:06:55.868: INFO: stdout: "true"
Jan  9 23:06:55.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-fj7js -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:55.973: INFO: stderr: ""
Jan  9 23:06:55.973: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 23:06:55.973: INFO: validating pod update-demo-nautilus-fj7js
Jan  9 23:06:55.977: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 23:06:55.977: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 23:06:55.977: INFO: update-demo-nautilus-fj7js is verified up and running
Jan  9 23:06:55.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-gk6zv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:56.073: INFO: stderr: ""
Jan  9 23:06:56.073: INFO: stdout: "true"
Jan  9 23:06:56.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-gk6zv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:56.207: INFO: stderr: ""
Jan  9 23:06:56.207: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 23:06:56.207: INFO: validating pod update-demo-nautilus-gk6zv
Jan  9 23:06:56.213: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 23:06:56.213: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 23:06:56.213: INFO: update-demo-nautilus-gk6zv is verified up and running
STEP: using delete to clean up resources
Jan  9 23:06:56.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:56.324: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 23:06:56.324: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan  9 23:06:56.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-lcshx'
Jan  9 23:06:56.424: INFO: stderr: "No resources found.\n"
Jan  9 23:06:56.424: INFO: stdout: ""
Jan  9 23:06:56.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods -l name=update-demo --namespace=e2e-tests-kubectl-lcshx -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan  9 23:06:56.525: INFO: stderr: ""
Jan  9 23:06:56.525: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:06:56.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lcshx" for this suite.
Jan  9 23:07:18.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:07:18.563: INFO: namespace: e2e-tests-kubectl-lcshx, resource: bindings, ignored listing per whitelist
Jan  9 23:07:18.611: INFO: namespace e2e-tests-kubectl-lcshx deletion completed in 22.08173336s

• [SLOW TEST:42.747 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:07:18.612: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-tc75m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Jan  9 23:07:18.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 cluster-info'
Jan  9 23:07:18.906: INFO: stderr: ""
Jan  9 23:07:18.906: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mmonitoring-influxdb\x1b[0m is running at \x1b[0;33mhttps://10.100.200.1:443/api/v1/namespaces/kube-system/services/monitoring-influxdb/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:07:18.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tc75m" for this suite.
Jan  9 23:07:24.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:07:24.964: INFO: namespace: e2e-tests-kubectl-tc75m, resource: bindings, ignored listing per whitelist
Jan  9 23:07:25.003: INFO: namespace e2e-tests-kubectl-tc75m deletion completed in 6.091196515s

• [SLOW TEST:6.392 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:07:25.005: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-t8w4r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Jan  9 23:07:25.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 create -f - --namespace=e2e-tests-kubectl-t8w4r'
Jan  9 23:07:25.472: INFO: stderr: ""
Jan  9 23:07:25.472: INFO: stdout: "pod/pause created\n"
Jan  9 23:07:25.472: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jan  9 23:07:25.472: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-t8w4r" to be "running and ready"
Jan  9 23:07:25.489: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 16.496672ms
Jan  9 23:07:27.492: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.01924976s
Jan  9 23:07:27.492: INFO: Pod "pause" satisfied condition "running and ready"
Jan  9 23:07:27.492: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Jan  9 23:07:27.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-t8w4r'
Jan  9 23:07:27.603: INFO: stderr: ""
Jan  9 23:07:27.603: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jan  9 23:07:27.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pod pause -L testing-label --namespace=e2e-tests-kubectl-t8w4r'
Jan  9 23:07:27.689: INFO: stderr: ""
Jan  9 23:07:27.689: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jan  9 23:07:27.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 label pods pause testing-label- --namespace=e2e-tests-kubectl-t8w4r'
Jan  9 23:07:27.781: INFO: stderr: ""
Jan  9 23:07:27.781: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jan  9 23:07:27.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pod pause -L testing-label --namespace=e2e-tests-kubectl-t8w4r'
Jan  9 23:07:27.896: INFO: stderr: ""
Jan  9 23:07:27.896: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Jan  9 23:07:27.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-t8w4r'
Jan  9 23:07:28.049: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 23:07:28.049: INFO: stdout: "pod \"pause\" force deleted\n"
Jan  9 23:07:28.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-t8w4r'
Jan  9 23:07:28.153: INFO: stderr: "No resources found.\n"
Jan  9 23:07:28.153: INFO: stdout: ""
Jan  9 23:07:28.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods -l name=pause --namespace=e2e-tests-kubectl-t8w4r -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan  9 23:07:28.234: INFO: stderr: ""
Jan  9 23:07:28.234: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:07:28.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-t8w4r" for this suite.
Jan  9 23:07:34.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:07:34.316: INFO: namespace: e2e-tests-kubectl-t8w4r, resource: bindings, ignored listing per whitelist
Jan  9 23:07:34.333: INFO: namespace e2e-tests-kubectl-t8w4r deletion completed in 6.094648546s

• [SLOW TEST:9.328 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:07:34.338: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-vbg6f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-vbg6f
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vbg6f to expose endpoints map[]
Jan  9 23:07:34.533: INFO: Get endpoints failed (3.774104ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jan  9 23:07:35.536: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vbg6f exposes endpoints map[] (1.007394103s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-vbg6f
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vbg6f to expose endpoints map[pod1:[80]]
Jan  9 23:07:37.560: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vbg6f exposes endpoints map[pod1:[80]] (2.018922131s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-vbg6f
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vbg6f to expose endpoints map[pod2:[80] pod1:[80]]
Jan  9 23:07:39.592: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vbg6f exposes endpoints map[pod1:[80] pod2:[80]] (2.028655031s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-vbg6f
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vbg6f to expose endpoints map[pod2:[80]]
Jan  9 23:07:40.615: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vbg6f exposes endpoints map[pod2:[80]] (1.017245592s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-vbg6f
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vbg6f to expose endpoints map[]
Jan  9 23:07:41.637: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vbg6f exposes endpoints map[] (1.017757672s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:07:41.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-vbg6f" for this suite.
Jan  9 23:07:47.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:07:47.708: INFO: namespace: e2e-tests-services-vbg6f, resource: bindings, ignored listing per whitelist
Jan  9 23:07:47.767: INFO: namespace e2e-tests-services-vbg6f deletion completed in 6.108443153s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:13.430 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:07:47.769: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-8nbml
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0109 23:08:27.996939      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan  9 23:08:27.997: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:08:27.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8nbml" for this suite.
Jan  9 23:08:34.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:08:34.048: INFO: namespace: e2e-tests-gc-8nbml, resource: bindings, ignored listing per whitelist
Jan  9 23:08:34.106: INFO: namespace e2e-tests-gc-8nbml deletion completed in 6.105171908s

• [SLOW TEST:46.337 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:08:34.108: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-76cql
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-7cfd8db7-1463-11e9-a046-02505600000d
STEP: Creating a pod to test consume configMaps
Jan  9 23:08:34.298: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7cfe1aee-1463-11e9-a046-02505600000d" in namespace "e2e-tests-projected-76cql" to be "success or failure"
Jan  9 23:08:34.310: INFO: Pod "pod-projected-configmaps-7cfe1aee-1463-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.00211ms
Jan  9 23:08:36.313: INFO: Pod "pod-projected-configmaps-7cfe1aee-1463-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015110475s
STEP: Saw pod success
Jan  9 23:08:36.313: INFO: Pod "pod-projected-configmaps-7cfe1aee-1463-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:08:36.315: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-projected-configmaps-7cfe1aee-1463-11e9-a046-02505600000d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 23:08:36.337: INFO: Waiting for pod pod-projected-configmaps-7cfe1aee-1463-11e9-a046-02505600000d to disappear
Jan  9 23:08:36.339: INFO: Pod pod-projected-configmaps-7cfe1aee-1463-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:08:36.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-76cql" for this suite.
Jan  9 23:08:42.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:08:42.386: INFO: namespace: e2e-tests-projected-76cql, resource: bindings, ignored listing per whitelist
Jan  9 23:08:42.470: INFO: namespace e2e-tests-projected-76cql deletion completed in 6.126238892s

• [SLOW TEST:8.362 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:08:42.471: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-jqgz2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-g6kx6
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-qfxh9
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:08:48.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-jqgz2" for this suite.
Jan  9 23:08:54.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:08:55.061: INFO: namespace: e2e-tests-namespaces-jqgz2, resource: bindings, ignored listing per whitelist
Jan  9 23:08:55.063: INFO: namespace e2e-tests-namespaces-jqgz2 deletion completed in 6.094534268s
STEP: Destroying namespace "e2e-tests-nsdeletetest-g6kx6" for this suite.
Jan  9 23:08:55.065: INFO: Namespace e2e-tests-nsdeletetest-g6kx6 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-qfxh9" for this suite.
Jan  9 23:09:01.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:09:01.085: INFO: namespace: e2e-tests-nsdeletetest-qfxh9, resource: bindings, ignored listing per whitelist
Jan  9 23:09:01.155: INFO: namespace e2e-tests-nsdeletetest-qfxh9 deletion completed in 6.090128712s

• [SLOW TEST:18.685 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:09:01.158: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-vw2p2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Jan  9 23:09:01.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 create -f - --namespace=e2e-tests-kubectl-vw2p2'
Jan  9 23:09:01.580: INFO: stderr: ""
Jan  9 23:09:01.580: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Jan  9 23:09:02.583: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 23:09:02.583: INFO: Found 0 / 1
Jan  9 23:09:03.584: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 23:09:03.584: INFO: Found 1 / 1
Jan  9 23:09:03.584: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan  9 23:09:03.586: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 23:09:03.586: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jan  9 23:09:03.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 logs redis-master-mzpw6 redis-master --namespace=e2e-tests-kubectl-vw2p2'
Jan  9 23:09:03.702: INFO: stderr: ""
Jan  9 23:09:03.702: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Jan 23:09:02.969 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Jan 23:09:02.969 # Server started, Redis version 3.2.12\n1:M 09 Jan 23:09:02.969 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Jan 23:09:02.969 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jan  9 23:09:03.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 log redis-master-mzpw6 redis-master --namespace=e2e-tests-kubectl-vw2p2 --tail=1'
Jan  9 23:09:03.803: INFO: stderr: ""
Jan  9 23:09:03.804: INFO: stdout: "1:M 09 Jan 23:09:02.969 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jan  9 23:09:03.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 log redis-master-mzpw6 redis-master --namespace=e2e-tests-kubectl-vw2p2 --limit-bytes=1'
Jan  9 23:09:03.916: INFO: stderr: ""
Jan  9 23:09:03.916: INFO: stdout: " "
STEP: exposing timestamps
Jan  9 23:09:03.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 log redis-master-mzpw6 redis-master --namespace=e2e-tests-kubectl-vw2p2 --tail=1 --timestamps'
Jan  9 23:09:04.030: INFO: stderr: ""
Jan  9 23:09:04.030: INFO: stdout: "2019-01-09T23:09:02.96965526Z 1:M 09 Jan 23:09:02.969 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jan  9 23:09:06.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 log redis-master-mzpw6 redis-master --namespace=e2e-tests-kubectl-vw2p2 --since=1s'
Jan  9 23:09:06.670: INFO: stderr: ""
Jan  9 23:09:06.670: INFO: stdout: ""
Jan  9 23:09:06.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 log redis-master-mzpw6 redis-master --namespace=e2e-tests-kubectl-vw2p2 --since=24h'
Jan  9 23:09:06.787: INFO: stderr: ""
Jan  9 23:09:06.787: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Jan 23:09:02.969 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Jan 23:09:02.969 # Server started, Redis version 3.2.12\n1:M 09 Jan 23:09:02.969 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Jan 23:09:02.969 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Jan  9 23:09:06.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-vw2p2'
Jan  9 23:09:06.878: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 23:09:06.878: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jan  9 23:09:06.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-vw2p2'
Jan  9 23:09:06.985: INFO: stderr: "No resources found.\n"
Jan  9 23:09:06.985: INFO: stdout: ""
Jan  9 23:09:06.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods -l name=nginx --namespace=e2e-tests-kubectl-vw2p2 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan  9 23:09:07.090: INFO: stderr: ""
Jan  9 23:09:07.090: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:09:07.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vw2p2" for this suite.
Jan  9 23:09:29.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:09:29.199: INFO: namespace: e2e-tests-kubectl-vw2p2, resource: bindings, ignored listing per whitelist
Jan  9 23:09:29.245: INFO: namespace e2e-tests-kubectl-vw2p2 deletion completed in 22.150321244s

• [SLOW TEST:28.087 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:09:29.246: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-hgvz4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan  9 23:09:37.533: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan  9 23:09:37.542: INFO: Pod pod-with-prestop-http-hook still exists
Jan  9 23:09:39.542: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan  9 23:09:39.546: INFO: Pod pod-with-prestop-http-hook still exists
Jan  9 23:09:41.542: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan  9 23:09:41.546: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:09:41.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-hgvz4" for this suite.
Jan  9 23:10:03.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:10:03.623: INFO: namespace: e2e-tests-container-lifecycle-hook-hgvz4, resource: bindings, ignored listing per whitelist
Jan  9 23:10:03.660: INFO: namespace e2e-tests-container-lifecycle-hook-hgvz4 deletion completed in 22.101151771s

• [SLOW TEST:34.414 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:10:03.663: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-c4wjg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  9 23:10:03.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-c4wjg'
Jan  9 23:10:03.987: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan  9 23:10:03.987: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Jan  9 23:10:06.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-c4wjg'
Jan  9 23:10:06.095: INFO: stderr: ""
Jan  9 23:10:06.095: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:10:06.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c4wjg" for this suite.
Jan  9 23:11:28.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:11:28.181: INFO: namespace: e2e-tests-kubectl-c4wjg, resource: bindings, ignored listing per whitelist
Jan  9 23:11:28.207: INFO: namespace e2e-tests-kubectl-c4wjg deletion completed in 1m22.106127255s

• [SLOW TEST:84.544 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:11:28.208: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-z5tc9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-e4c4c592-1463-11e9-a046-02505600000d
STEP: Creating configMap with name cm-test-opt-upd-e4c4c9c3-1463-11e9-a046-02505600000d
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-e4c4c592-1463-11e9-a046-02505600000d
STEP: Updating configmap cm-test-opt-upd-e4c4c9c3-1463-11e9-a046-02505600000d
STEP: Creating configMap with name cm-test-opt-create-e4c4c9e0-1463-11e9-a046-02505600000d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:11:36.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z5tc9" for this suite.
Jan  9 23:11:58.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:11:58.586: INFO: namespace: e2e-tests-projected-z5tc9, resource: bindings, ignored listing per whitelist
Jan  9 23:11:58.607: INFO: namespace e2e-tests-projected-z5tc9 deletion completed in 22.094719931s

• [SLOW TEST:30.399 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:11:58.607: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-xw75x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-glvfj in namespace e2e-tests-proxy-xw75x
I0109 23:11:58.815806      16 runners.go:180] Created replication controller with name: proxy-service-glvfj, namespace: e2e-tests-proxy-xw75x, replica count: 1
I0109 23:11:59.866715      16 runners.go:180] proxy-service-glvfj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0109 23:12:00.866987      16 runners.go:180] proxy-service-glvfj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0109 23:12:01.867276      16 runners.go:180] proxy-service-glvfj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0109 23:12:02.867532      16 runners.go:180] proxy-service-glvfj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0109 23:12:03.867856      16 runners.go:180] proxy-service-glvfj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0109 23:12:04.868137      16 runners.go:180] proxy-service-glvfj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0109 23:12:05.868408      16 runners.go:180] proxy-service-glvfj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0109 23:12:06.868751      16 runners.go:180] proxy-service-glvfj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0109 23:12:07.869092      16 runners.go:180] proxy-service-glvfj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0109 23:12:08.869480      16 runners.go:180] proxy-service-glvfj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0109 23:12:09.869804      16 runners.go:180] proxy-service-glvfj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0109 23:12:10.870271      16 runners.go:180] proxy-service-glvfj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0109 23:12:11.870719      16 runners.go:180] proxy-service-glvfj Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan  9 23:12:11.874: INFO: setup took 13.087406847s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jan  9 23:12:11.889: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 14.25398ms)
Jan  9 23:12:11.889: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 15.188455ms)
Jan  9 23:12:11.893: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 18.544555ms)
Jan  9 23:12:11.894: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 19.114721ms)
Jan  9 23:12:11.895: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 20.679177ms)
Jan  9 23:12:11.896: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 21.951645ms)
Jan  9 23:12:11.896: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 21.730616ms)
Jan  9 23:12:11.897: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 22.367902ms)
Jan  9 23:12:11.898: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 24.073976ms)
Jan  9 23:12:11.898: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 24.052024ms)
Jan  9 23:12:11.902: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 27.940805ms)
Jan  9 23:12:11.902: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 28.067525ms)
Jan  9 23:12:11.904: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 29.794672ms)
Jan  9 23:12:11.904: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 29.634372ms)
Jan  9 23:12:11.904: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 29.825001ms)
Jan  9 23:12:11.904: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 29.746672ms)
Jan  9 23:12:11.915: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 9.559079ms)
Jan  9 23:12:11.915: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 10.026897ms)
Jan  9 23:12:11.915: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 10.519051ms)
Jan  9 23:12:11.915: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 10.177973ms)
Jan  9 23:12:11.916: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 10.377021ms)
Jan  9 23:12:11.916: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 10.897793ms)
Jan  9 23:12:11.916: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 10.315021ms)
Jan  9 23:12:11.916: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 11.296114ms)
Jan  9 23:12:11.917: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 11.714019ms)
Jan  9 23:12:11.917: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 11.724199ms)
Jan  9 23:12:11.918: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 12.230191ms)
Jan  9 23:12:11.918: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 13.425582ms)
Jan  9 23:12:11.918: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 13.080515ms)
Jan  9 23:12:11.919: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 13.64504ms)
Jan  9 23:12:11.919: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 13.986669ms)
Jan  9 23:12:11.919: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 13.729397ms)
Jan  9 23:12:11.930: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 9.032686ms)
Jan  9 23:12:11.933: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 12.110823ms)
Jan  9 23:12:11.933: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 14.07561ms)
Jan  9 23:12:11.934: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 12.819255ms)
Jan  9 23:12:11.934: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 14.069202ms)
Jan  9 23:12:11.936: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 15.797528ms)
Jan  9 23:12:11.936: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 15.967773ms)
Jan  9 23:12:11.937: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 16.291478ms)
Jan  9 23:12:11.937: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 17.26849ms)
Jan  9 23:12:11.937: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 17.577582ms)
Jan  9 23:12:11.937: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 16.832645ms)
Jan  9 23:12:11.938: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 17.481912ms)
Jan  9 23:12:11.938: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 16.838544ms)
Jan  9 23:12:11.948: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 28.144474ms)
Jan  9 23:12:11.949: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 28.368501ms)
Jan  9 23:12:11.949: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 28.940584ms)
Jan  9 23:12:11.955: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 5.191208ms)
Jan  9 23:12:11.955: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 5.416795ms)
Jan  9 23:12:11.955: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 5.954607ms)
Jan  9 23:12:11.956: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 6.545657ms)
Jan  9 23:12:11.957: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 7.444202ms)
Jan  9 23:12:11.959: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 9.157996ms)
Jan  9 23:12:11.960: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 10.09135ms)
Jan  9 23:12:11.960: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 10.149211ms)
Jan  9 23:12:11.960: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 10.511758ms)
Jan  9 23:12:11.960: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 10.48724ms)
Jan  9 23:12:11.961: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 11.127475ms)
Jan  9 23:12:11.961: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 11.164377ms)
Jan  9 23:12:11.961: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 11.081619ms)
Jan  9 23:12:11.963: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 12.922004ms)
Jan  9 23:12:11.963: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 13.631769ms)
Jan  9 23:12:11.964: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 14.402437ms)
Jan  9 23:12:11.974: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 9.442115ms)
Jan  9 23:12:11.975: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 10.055428ms)
Jan  9 23:12:11.975: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 10.805645ms)
Jan  9 23:12:11.976: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 11.472381ms)
Jan  9 23:12:11.976: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 12.135101ms)
Jan  9 23:12:11.977: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 12.065548ms)
Jan  9 23:12:11.977: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 11.98754ms)
Jan  9 23:12:11.977: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 12.163767ms)
Jan  9 23:12:11.977: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 12.259352ms)
Jan  9 23:12:11.977: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 12.159631ms)
Jan  9 23:12:11.977: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 13.392161ms)
Jan  9 23:12:11.978: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 12.826857ms)
Jan  9 23:12:11.979: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 13.761908ms)
Jan  9 23:12:11.979: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 13.88654ms)
Jan  9 23:12:11.979: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 14.719622ms)
Jan  9 23:12:11.979: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 14.545448ms)
Jan  9 23:12:11.985: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 5.712544ms)
Jan  9 23:12:11.989: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 9.959737ms)
Jan  9 23:12:11.990: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 9.019293ms)
Jan  9 23:12:11.990: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 9.989208ms)
Jan  9 23:12:11.990: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 10.299544ms)
Jan  9 23:12:11.993: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 12.87079ms)
Jan  9 23:12:11.993: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 12.335838ms)
Jan  9 23:12:11.993: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 12.317958ms)
Jan  9 23:12:11.993: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 13.343092ms)
Jan  9 23:12:11.997: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 16.596405ms)
Jan  9 23:12:11.997: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 17.548405ms)
Jan  9 23:12:11.998: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 17.862036ms)
Jan  9 23:12:11.998: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 18.114305ms)
Jan  9 23:12:11.998: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 18.192113ms)
Jan  9 23:12:12.001: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 20.971627ms)
Jan  9 23:12:12.001: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 21.131549ms)
Jan  9 23:12:12.009: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 7.607931ms)
Jan  9 23:12:12.009: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 7.468377ms)
Jan  9 23:12:12.010: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 8.412806ms)
Jan  9 23:12:12.011: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 8.982921ms)
Jan  9 23:12:12.012: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 9.976392ms)
Jan  9 23:12:12.012: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 9.944856ms)
Jan  9 23:12:12.016: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 13.359254ms)
Jan  9 23:12:12.016: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 14.075748ms)
Jan  9 23:12:12.016: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 13.874387ms)
Jan  9 23:12:12.016: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 13.971567ms)
Jan  9 23:12:12.016: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 14.372732ms)
Jan  9 23:12:12.016: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 14.094163ms)
Jan  9 23:12:12.017: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 14.941231ms)
Jan  9 23:12:12.019: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 16.756632ms)
Jan  9 23:12:12.020: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 17.964568ms)
Jan  9 23:12:12.020: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 17.689776ms)
Jan  9 23:12:12.028: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 8.507454ms)
Jan  9 23:12:12.031: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 10.954245ms)
Jan  9 23:12:12.034: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 13.829637ms)
Jan  9 23:12:12.035: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 14.875063ms)
Jan  9 23:12:12.036: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 14.315999ms)
Jan  9 23:12:12.036: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 15.105838ms)
Jan  9 23:12:12.036: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 15.385767ms)
Jan  9 23:12:12.037: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 16.780544ms)
Jan  9 23:12:12.037: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 15.841107ms)
Jan  9 23:12:12.038: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 16.765423ms)
Jan  9 23:12:12.038: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 16.840129ms)
Jan  9 23:12:12.038: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 17.70037ms)
Jan  9 23:12:12.038: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 16.907991ms)
Jan  9 23:12:12.038: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 17.307932ms)
Jan  9 23:12:12.038: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 17.657135ms)
Jan  9 23:12:12.038: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 17.266129ms)
Jan  9 23:12:12.045: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 5.906107ms)
Jan  9 23:12:12.047: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 7.575275ms)
Jan  9 23:12:12.048: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 8.452174ms)
Jan  9 23:12:12.049: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 9.091859ms)
Jan  9 23:12:12.050: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 10.657252ms)
Jan  9 23:12:12.050: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 11.191803ms)
Jan  9 23:12:12.050: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 11.447793ms)
Jan  9 23:12:12.052: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 12.02244ms)
Jan  9 23:12:12.054: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 13.771326ms)
Jan  9 23:12:12.054: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 13.914745ms)
Jan  9 23:12:12.054: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 14.018085ms)
Jan  9 23:12:12.057: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 18.485268ms)
Jan  9 23:12:12.061: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 21.300114ms)
Jan  9 23:12:12.061: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 21.904494ms)
Jan  9 23:12:12.061: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 21.450561ms)
Jan  9 23:12:12.061: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 21.610733ms)
Jan  9 23:12:12.068: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 6.217303ms)
Jan  9 23:12:12.069: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 6.111358ms)
Jan  9 23:12:12.069: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 6.965101ms)
Jan  9 23:12:12.070: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 6.974877ms)
Jan  9 23:12:12.070: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 8.024518ms)
Jan  9 23:12:12.070: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 7.979016ms)
Jan  9 23:12:12.073: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 9.783072ms)
Jan  9 23:12:12.077: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 14.744786ms)
Jan  9 23:12:12.078: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 15.210154ms)
Jan  9 23:12:12.079: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 15.818819ms)
Jan  9 23:12:12.079: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 16.403167ms)
Jan  9 23:12:12.080: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 16.662393ms)
Jan  9 23:12:12.085: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 21.652438ms)
Jan  9 23:12:12.085: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 22.635063ms)
Jan  9 23:12:12.086: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 23.134083ms)
Jan  9 23:12:12.086: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 23.046021ms)
Jan  9 23:12:12.091: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 4.410517ms)
Jan  9 23:12:12.091: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 4.766949ms)
Jan  9 23:12:12.096: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 8.321703ms)
Jan  9 23:12:12.097: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 8.819645ms)
Jan  9 23:12:12.097: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 10.068732ms)
Jan  9 23:12:12.098: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 10.90795ms)
Jan  9 23:12:12.099: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 10.473431ms)
Jan  9 23:12:12.099: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 11.449143ms)
Jan  9 23:12:12.099: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 11.583834ms)
Jan  9 23:12:12.100: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 11.701994ms)
Jan  9 23:12:12.100: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 13.009208ms)
Jan  9 23:12:12.101: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 13.786286ms)
Jan  9 23:12:12.101: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 12.115734ms)
Jan  9 23:12:12.101: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 13.717193ms)
Jan  9 23:12:12.101: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 12.874018ms)
Jan  9 23:12:12.102: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 13.202072ms)
Jan  9 23:12:12.112: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 9.626569ms)
Jan  9 23:12:12.114: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 12.51838ms)
Jan  9 23:12:12.115: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 12.795612ms)
Jan  9 23:12:12.115: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 12.688547ms)
Jan  9 23:12:12.115: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 12.663006ms)
Jan  9 23:12:12.115: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 12.658197ms)
Jan  9 23:12:12.117: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 14.463867ms)
Jan  9 23:12:12.117: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 14.251326ms)
Jan  9 23:12:12.117: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 14.825266ms)
Jan  9 23:12:12.117: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 15.011163ms)
Jan  9 23:12:12.117: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 15.411084ms)
Jan  9 23:12:12.117: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 15.199115ms)
Jan  9 23:12:12.118: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 16.020244ms)
Jan  9 23:12:12.118: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 15.524923ms)
Jan  9 23:12:12.120: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 17.887417ms)
Jan  9 23:12:12.120: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 17.95369ms)
Jan  9 23:12:12.123: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 2.522722ms)
Jan  9 23:12:12.126: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 4.818887ms)
Jan  9 23:12:12.127: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 5.738119ms)
Jan  9 23:12:12.127: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 6.665686ms)
Jan  9 23:12:12.128: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 7.630127ms)
Jan  9 23:12:12.129: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 8.3908ms)
Jan  9 23:12:12.135: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 13.90599ms)
Jan  9 23:12:12.135: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 13.444358ms)
Jan  9 23:12:12.135: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 13.17153ms)
Jan  9 23:12:12.135: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 14.920682ms)
Jan  9 23:12:12.135: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 14.099337ms)
Jan  9 23:12:12.136: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 14.804859ms)
Jan  9 23:12:12.136: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 14.247642ms)
Jan  9 23:12:12.136: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 14.562547ms)
Jan  9 23:12:12.136: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 14.734342ms)
Jan  9 23:12:12.136: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 14.738669ms)
Jan  9 23:12:12.142: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 5.272736ms)
Jan  9 23:12:12.144: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 7.082793ms)
Jan  9 23:12:12.144: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 7.654197ms)
Jan  9 23:12:12.145: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 8.403554ms)
Jan  9 23:12:12.145: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 8.817666ms)
Jan  9 23:12:12.146: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 8.74117ms)
Jan  9 23:12:12.147: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 10.40602ms)
Jan  9 23:12:12.148: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 11.730729ms)
Jan  9 23:12:12.149: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 12.866082ms)
Jan  9 23:12:12.150: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 13.137313ms)
Jan  9 23:12:12.151: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 13.165496ms)
Jan  9 23:12:12.151: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 14.252538ms)
Jan  9 23:12:12.152: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 14.728293ms)
Jan  9 23:12:12.152: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 15.390565ms)
Jan  9 23:12:12.153: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 15.311159ms)
Jan  9 23:12:12.153: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 16.056911ms)
Jan  9 23:12:12.161: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 7.893825ms)
Jan  9 23:12:12.162: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 7.765791ms)
Jan  9 23:12:12.162: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 8.606159ms)
Jan  9 23:12:12.165: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 10.596861ms)
Jan  9 23:12:12.166: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 11.533137ms)
Jan  9 23:12:12.166: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 12.182619ms)
Jan  9 23:12:12.167: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 11.812148ms)
Jan  9 23:12:12.167: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 11.296196ms)
Jan  9 23:12:12.167: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 11.392827ms)
Jan  9 23:12:12.168: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 13.209619ms)
Jan  9 23:12:12.168: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 14.228565ms)
Jan  9 23:12:12.168: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 13.467739ms)
Jan  9 23:12:12.168: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 13.187831ms)
Jan  9 23:12:12.170: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 14.187691ms)
Jan  9 23:12:12.170: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 15.076269ms)
Jan  9 23:12:12.170: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 15.225516ms)
Jan  9 23:12:12.177: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 7.261339ms)
Jan  9 23:12:12.178: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 7.052478ms)
Jan  9 23:12:12.178: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 7.687954ms)
Jan  9 23:12:12.179: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 7.778196ms)
Jan  9 23:12:12.180: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 7.927063ms)
Jan  9 23:12:12.181: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 8.731393ms)
Jan  9 23:12:12.181: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 9.505842ms)
Jan  9 23:12:12.182: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 10.145912ms)
Jan  9 23:12:12.182: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 10.810096ms)
Jan  9 23:12:12.182: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 11.5273ms)
Jan  9 23:12:12.183: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 11.788135ms)
Jan  9 23:12:12.183: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 10.679622ms)
Jan  9 23:12:12.183: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 10.603411ms)
Jan  9 23:12:12.183: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 11.65551ms)
Jan  9 23:12:12.183: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 12.200132ms)
Jan  9 23:12:12.183: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 12.135332ms)
Jan  9 23:12:12.187: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 4.101451ms)
Jan  9 23:12:12.190: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 5.694902ms)
Jan  9 23:12:12.190: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 6.04356ms)
Jan  9 23:12:12.190: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 6.317526ms)
Jan  9 23:12:12.190: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 5.882828ms)
Jan  9 23:12:12.192: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 6.759558ms)
Jan  9 23:12:12.193: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 7.679985ms)
Jan  9 23:12:12.193: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 8.830211ms)
Jan  9 23:12:12.193: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 8.253233ms)
Jan  9 23:12:12.194: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 8.237883ms)
Jan  9 23:12:12.194: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 10.106149ms)
Jan  9 23:12:12.195: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 9.646803ms)
Jan  9 23:12:12.195: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 9.4237ms)
Jan  9 23:12:12.196: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 10.314092ms)
Jan  9 23:12:12.197: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 10.664621ms)
Jan  9 23:12:12.197: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 11.164081ms)
Jan  9 23:12:12.204: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 6.541659ms)
Jan  9 23:12:12.205: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 6.681575ms)
Jan  9 23:12:12.205: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 7.849309ms)
Jan  9 23:12:12.206: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 7.929911ms)
Jan  9 23:12:12.206: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 8.566215ms)
Jan  9 23:12:12.206: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 7.608052ms)
Jan  9 23:12:12.206: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 8.991958ms)
Jan  9 23:12:12.207: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 9.27532ms)
Jan  9 23:12:12.207: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 8.161076ms)
Jan  9 23:12:12.207: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 8.342238ms)
Jan  9 23:12:12.207: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 8.93026ms)
Jan  9 23:12:12.207: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 8.312366ms)
Jan  9 23:12:12.209: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 10.516973ms)
Jan  9 23:12:12.209: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 11.207838ms)
Jan  9 23:12:12.210: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 11.318684ms)
Jan  9 23:12:12.210: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 11.549007ms)
Jan  9 23:12:12.219: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 7.472961ms)
Jan  9 23:12:12.219: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 7.788802ms)
Jan  9 23:12:12.219: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 8.433833ms)
Jan  9 23:12:12.219: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 8.257375ms)
Jan  9 23:12:12.219: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 9.379864ms)
Jan  9 23:12:12.220: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 9.663485ms)
Jan  9 23:12:12.220: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 9.37735ms)
Jan  9 23:12:12.220: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 9.411076ms)
Jan  9 23:12:12.221: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 9.027299ms)
Jan  9 23:12:12.221: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 8.95742ms)
Jan  9 23:12:12.221: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 9.910518ms)
Jan  9 23:12:12.221: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 9.546462ms)
Jan  9 23:12:12.222: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 11.857209ms)
Jan  9 23:12:12.223: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 10.720682ms)
Jan  9 23:12:12.223: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 12.630996ms)
Jan  9 23:12:12.223: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 11.41326ms)
Jan  9 23:12:12.228: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:460/proxy/: tls baz (200; 4.85118ms)
Jan  9 23:12:12.229: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:462/proxy/: tls qux (200; 5.681931ms)
Jan  9 23:12:12.230: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname2/proxy/: tls qux (200; 6.38174ms)
Jan  9 23:12:12.230: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname2/proxy/: bar (200; 6.607578ms)
Jan  9 23:12:12.234: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 9.71494ms)
Jan  9 23:12:12.237: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:162/proxy/: bar (200; 12.192184ms)
Jan  9 23:12:12.237: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:1080/proxy/... (200; 13.271035ms)
Jan  9 23:12:12.238: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:1080/proxy/rewri... (200; 13.464983ms)
Jan  9 23:12:12.238: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/http:proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 13.296133ms)
Jan  9 23:12:12.238: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd/proxy/rewriteme"... (200; 14.485349ms)
Jan  9 23:12:12.239: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-xw75x/pods/https:proxy-service-glvfj-4xmbd:443/proxy/... (200; 14.795582ms)
Jan  9 23:12:12.239: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/https:proxy-service-glvfj:tlsportname1/proxy/: tls baz (200; 15.791177ms)
Jan  9 23:12:12.240: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xw75x/pods/proxy-service-glvfj-4xmbd:160/proxy/: foo (200; 15.712993ms)
Jan  9 23:12:12.240: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname2/proxy/: bar (200; 15.5646ms)
Jan  9 23:12:12.241: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/http:proxy-service-glvfj:portname1/proxy/: foo (200; 17.527831ms)
Jan  9 23:12:12.241: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-xw75x/services/proxy-service-glvfj:portname1/proxy/: foo (200; 16.941643ms)
STEP: deleting { ReplicationController} proxy-service-glvfj in namespace e2e-tests-proxy-xw75x, will wait for the garbage collector to delete the pods
Jan  9 23:12:12.301: INFO: Deleting { ReplicationController} proxy-service-glvfj took: 6.915319ms
Jan  9 23:12:12.401: INFO: Terminating { ReplicationController} proxy-service-glvfj pods took: 100.289023ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:12:25.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-xw75x" for this suite.
Jan  9 23:12:31.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:12:31.143: INFO: namespace: e2e-tests-proxy-xw75x, resource: bindings, ignored listing per whitelist
Jan  9 23:12:31.225: INFO: namespace e2e-tests-proxy-xw75x deletion completed in 6.119082974s

• [SLOW TEST:32.618 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:12:31.226: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-s5m4r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-s5m4r
Jan  9 23:12:33.468: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-s5m4r
STEP: checking the pod's current state and verifying that restartCount is present
Jan  9 23:12:33.471: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:16:33.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-s5m4r" for this suite.
Jan  9 23:16:39.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:16:39.988: INFO: namespace: e2e-tests-container-probe-s5m4r, resource: bindings, ignored listing per whitelist
Jan  9 23:16:40.049: INFO: namespace e2e-tests-container-probe-s5m4r deletion completed in 6.11609281s

• [SLOW TEST:248.823 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:16:40.050: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fcmtt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 23:16:40.256: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9ea6124a-1464-11e9-a046-02505600000d" in namespace "e2e-tests-projected-fcmtt" to be "success or failure"
Jan  9 23:16:40.275: INFO: Pod "downwardapi-volume-9ea6124a-1464-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 18.459194ms
Jan  9 23:16:42.278: INFO: Pod "downwardapi-volume-9ea6124a-1464-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021521754s
Jan  9 23:16:44.281: INFO: Pod "downwardapi-volume-9ea6124a-1464-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02418212s
STEP: Saw pod success
Jan  9 23:16:44.281: INFO: Pod "downwardapi-volume-9ea6124a-1464-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:16:44.282: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod downwardapi-volume-9ea6124a-1464-11e9-a046-02505600000d container client-container: <nil>
STEP: delete the pod
Jan  9 23:16:44.314: INFO: Waiting for pod downwardapi-volume-9ea6124a-1464-11e9-a046-02505600000d to disappear
Jan  9 23:16:44.329: INFO: Pod downwardapi-volume-9ea6124a-1464-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:16:44.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fcmtt" for this suite.
Jan  9 23:16:50.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:16:50.386: INFO: namespace: e2e-tests-projected-fcmtt, resource: bindings, ignored listing per whitelist
Jan  9 23:16:50.442: INFO: namespace e2e-tests-projected-fcmtt deletion completed in 6.100729984s

• [SLOW TEST:10.393 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:16:50.443: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-gwxvn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan  9 23:16:50.657: INFO: Waiting up to 5m0s for pod "pod-a4d93038-1464-11e9-a046-02505600000d" in namespace "e2e-tests-emptydir-gwxvn" to be "success or failure"
Jan  9 23:16:50.671: INFO: Pod "pod-a4d93038-1464-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.558561ms
Jan  9 23:16:52.675: INFO: Pod "pod-a4d93038-1464-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018091575s
STEP: Saw pod success
Jan  9 23:16:52.675: INFO: Pod "pod-a4d93038-1464-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:16:52.677: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-a4d93038-1464-11e9-a046-02505600000d container test-container: <nil>
STEP: delete the pod
Jan  9 23:16:52.699: INFO: Waiting for pod pod-a4d93038-1464-11e9-a046-02505600000d to disappear
Jan  9 23:16:52.704: INFO: Pod pod-a4d93038-1464-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:16:52.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gwxvn" for this suite.
Jan  9 23:16:58.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:16:58.810: INFO: namespace: e2e-tests-emptydir-gwxvn, resource: bindings, ignored listing per whitelist
Jan  9 23:16:58.829: INFO: namespace e2e-tests-emptydir-gwxvn deletion completed in 6.117515368s

• [SLOW TEST:8.386 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:16:58.835: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-knn2m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:17:59.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-knn2m" for this suite.
Jan  9 23:18:21.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:18:21.178: INFO: namespace: e2e-tests-container-probe-knn2m, resource: bindings, ignored listing per whitelist
Jan  9 23:18:21.208: INFO: namespace e2e-tests-container-probe-knn2m deletion completed in 22.120998852s

• [SLOW TEST:82.374 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:18:21.209: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-d8f9v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-d8f9v
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan  9 23:18:21.422: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan  9 23:18:45.551: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://40.0.6.5:8080/dial?request=hostName&protocol=udp&host=40.0.6.2&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-d8f9v PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 23:18:45.552: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 23:18:45.671: INFO: Waiting for endpoints: map[]
Jan  9 23:18:45.675: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://40.0.6.5:8080/dial?request=hostName&protocol=udp&host=40.0.6.3&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-d8f9v PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 23:18:45.675: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 23:18:45.779: INFO: Waiting for endpoints: map[]
Jan  9 23:18:45.784: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://40.0.6.5:8080/dial?request=hostName&protocol=udp&host=40.0.6.4&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-d8f9v PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 23:18:45.784: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 23:18:45.885: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:18:45.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-d8f9v" for this suite.
Jan  9 23:19:07.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:19:07.941: INFO: namespace: e2e-tests-pod-network-test-d8f9v, resource: bindings, ignored listing per whitelist
Jan  9 23:19:08.007: INFO: namespace e2e-tests-pod-network-test-d8f9v deletion completed in 22.114973273s

• [SLOW TEST:46.799 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:19:08.010: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-hthdq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 23:19:08.223: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jan  9 23:19:08.236: INFO: Number of nodes with available pods: 0
Jan  9 23:19:08.236: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jan  9 23:19:08.267: INFO: Number of nodes with available pods: 0
Jan  9 23:19:08.267: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:09.272: INFO: Number of nodes with available pods: 0
Jan  9 23:19:09.272: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:10.272: INFO: Number of nodes with available pods: 0
Jan  9 23:19:10.272: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:11.271: INFO: Number of nodes with available pods: 1
Jan  9 23:19:11.272: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jan  9 23:19:11.305: INFO: Number of nodes with available pods: 0
Jan  9 23:19:11.306: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jan  9 23:19:11.334: INFO: Number of nodes with available pods: 0
Jan  9 23:19:11.334: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:12.338: INFO: Number of nodes with available pods: 0
Jan  9 23:19:12.338: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:13.340: INFO: Number of nodes with available pods: 0
Jan  9 23:19:13.340: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:14.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:14.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:15.340: INFO: Number of nodes with available pods: 0
Jan  9 23:19:15.340: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:16.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:16.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:17.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:17.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:18.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:18.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:19.340: INFO: Number of nodes with available pods: 0
Jan  9 23:19:19.340: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:20.341: INFO: Number of nodes with available pods: 0
Jan  9 23:19:20.341: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:21.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:21.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:22.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:22.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:23.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:23.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:24.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:24.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:25.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:25.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:26.338: INFO: Number of nodes with available pods: 0
Jan  9 23:19:26.338: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:27.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:27.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:28.338: INFO: Number of nodes with available pods: 0
Jan  9 23:19:28.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:29.340: INFO: Number of nodes with available pods: 0
Jan  9 23:19:29.340: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:30.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:30.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:31.340: INFO: Number of nodes with available pods: 0
Jan  9 23:19:31.340: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:32.338: INFO: Number of nodes with available pods: 0
Jan  9 23:19:32.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:33.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:33.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:34.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:34.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:35.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:35.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:36.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:36.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:37.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:37.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:38.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:38.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:39.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:39.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:40.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:40.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:41.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:41.340: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:42.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:42.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:43.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:43.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:44.341: INFO: Number of nodes with available pods: 0
Jan  9 23:19:44.341: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:45.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:45.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:46.341: INFO: Number of nodes with available pods: 0
Jan  9 23:19:46.341: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:47.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:47.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:48.339: INFO: Number of nodes with available pods: 0
Jan  9 23:19:48.339: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:19:49.340: INFO: Number of nodes with available pods: 1
Jan  9 23:19:49.340: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-hthdq, will wait for the garbage collector to delete the pods
Jan  9 23:19:49.408: INFO: Deleting {extensions DaemonSet} daemon-set took: 7.197594ms
Jan  9 23:19:49.508: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.297155ms
Jan  9 23:20:27.211: INFO: Number of nodes with available pods: 0
Jan  9 23:20:27.211: INFO: Number of running nodes: 0, number of available pods: 0
Jan  9 23:20:27.214: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hthdq/daemonsets","resourceVersion":"19054"},"items":null}

Jan  9 23:20:27.217: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hthdq/pods","resourceVersion":"19054"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:20:27.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hthdq" for this suite.
Jan  9 23:20:33.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:20:33.320: INFO: namespace: e2e-tests-daemonsets-hthdq, resource: bindings, ignored listing per whitelist
Jan  9 23:20:33.367: INFO: namespace e2e-tests-daemonsets-hthdq deletion completed in 6.122339896s

• [SLOW TEST:85.358 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:20:33.371: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-6msnw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan  9 23:20:33.592: INFO: Waiting up to 5m0s for pod "pod-29b9f7a5-1465-11e9-a046-02505600000d" in namespace "e2e-tests-emptydir-6msnw" to be "success or failure"
Jan  9 23:20:33.599: INFO: Pod "pod-29b9f7a5-1465-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.657588ms
Jan  9 23:20:35.603: INFO: Pod "pod-29b9f7a5-1465-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011182463s
Jan  9 23:20:37.607: INFO: Pod "pod-29b9f7a5-1465-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015157348s
STEP: Saw pod success
Jan  9 23:20:37.607: INFO: Pod "pod-29b9f7a5-1465-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:20:37.610: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-29b9f7a5-1465-11e9-a046-02505600000d container test-container: <nil>
STEP: delete the pod
Jan  9 23:20:37.625: INFO: Waiting for pod pod-29b9f7a5-1465-11e9-a046-02505600000d to disappear
Jan  9 23:20:37.639: INFO: Pod pod-29b9f7a5-1465-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:20:37.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6msnw" for this suite.
Jan  9 23:20:43.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:20:43.721: INFO: namespace: e2e-tests-emptydir-6msnw, resource: bindings, ignored listing per whitelist
Jan  9 23:20:43.754: INFO: namespace e2e-tests-emptydir-6msnw deletion completed in 6.110642444s

• [SLOW TEST:10.383 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:20:43.756: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9nt8j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-2feb74f4-1465-11e9-a046-02505600000d
STEP: Creating a pod to test consume secrets
Jan  9 23:20:43.986: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2fec149d-1465-11e9-a046-02505600000d" in namespace "e2e-tests-projected-9nt8j" to be "success or failure"
Jan  9 23:20:43.990: INFO: Pod "pod-projected-secrets-2fec149d-1465-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.11982ms
Jan  9 23:20:45.994: INFO: Pod "pod-projected-secrets-2fec149d-1465-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008123134s
Jan  9 23:20:47.998: INFO: Pod "pod-projected-secrets-2fec149d-1465-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01233991s
STEP: Saw pod success
Jan  9 23:20:47.998: INFO: Pod "pod-projected-secrets-2fec149d-1465-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:20:48.002: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-projected-secrets-2fec149d-1465-11e9-a046-02505600000d container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan  9 23:20:48.026: INFO: Waiting for pod pod-projected-secrets-2fec149d-1465-11e9-a046-02505600000d to disappear
Jan  9 23:20:48.030: INFO: Pod pod-projected-secrets-2fec149d-1465-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:20:48.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9nt8j" for this suite.
Jan  9 23:20:54.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:20:54.127: INFO: namespace: e2e-tests-projected-9nt8j, resource: bindings, ignored listing per whitelist
Jan  9 23:20:54.180: INFO: namespace e2e-tests-projected-9nt8j deletion completed in 6.146502936s

• [SLOW TEST:10.424 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:20:54.182: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-7h79h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan  9 23:21:02.489: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  9 23:21:02.493: INFO: Pod pod-with-poststart-http-hook still exists
Jan  9 23:21:04.493: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  9 23:21:04.498: INFO: Pod pod-with-poststart-http-hook still exists
Jan  9 23:21:06.495: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  9 23:21:06.513: INFO: Pod pod-with-poststart-http-hook still exists
Jan  9 23:21:08.493: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  9 23:21:08.499: INFO: Pod pod-with-poststart-http-hook still exists
Jan  9 23:21:10.494: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  9 23:21:10.497: INFO: Pod pod-with-poststart-http-hook still exists
Jan  9 23:21:12.493: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  9 23:21:12.498: INFO: Pod pod-with-poststart-http-hook still exists
Jan  9 23:21:14.493: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  9 23:21:14.498: INFO: Pod pod-with-poststart-http-hook still exists
Jan  9 23:21:16.493: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan  9 23:21:16.498: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:21:16.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-7h79h" for this suite.
Jan  9 23:21:38.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:21:38.569: INFO: namespace: e2e-tests-container-lifecycle-hook-7h79h, resource: bindings, ignored listing per whitelist
Jan  9 23:21:38.615: INFO: namespace e2e-tests-container-lifecycle-hook-7h79h deletion completed in 22.112227906s

• [SLOW TEST:44.434 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:21:38.615: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-6rhjt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jan  9 23:21:38.836: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6rhjt,SelfLink:/api/v1/namespaces/e2e-tests-watch-6rhjt/configmaps/e2e-watch-test-watch-closed,UID:509e0782-1465-11e9-9de1-005056902d46,ResourceVersion:19285,Generation:0,CreationTimestamp:2019-01-09 23:21:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan  9 23:21:38.837: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6rhjt,SelfLink:/api/v1/namespaces/e2e-tests-watch-6rhjt/configmaps/e2e-watch-test-watch-closed,UID:509e0782-1465-11e9-9de1-005056902d46,ResourceVersion:19286,Generation:0,CreationTimestamp:2019-01-09 23:21:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jan  9 23:21:38.857: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6rhjt,SelfLink:/api/v1/namespaces/e2e-tests-watch-6rhjt/configmaps/e2e-watch-test-watch-closed,UID:509e0782-1465-11e9-9de1-005056902d46,ResourceVersion:19287,Generation:0,CreationTimestamp:2019-01-09 23:21:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan  9 23:21:38.857: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6rhjt,SelfLink:/api/v1/namespaces/e2e-tests-watch-6rhjt/configmaps/e2e-watch-test-watch-closed,UID:509e0782-1465-11e9-9de1-005056902d46,ResourceVersion:19288,Generation:0,CreationTimestamp:2019-01-09 23:21:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:21:38.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-6rhjt" for this suite.
Jan  9 23:21:44.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:21:44.941: INFO: namespace: e2e-tests-watch-6rhjt, resource: bindings, ignored listing per whitelist
Jan  9 23:21:44.967: INFO: namespace e2e-tests-watch-6rhjt deletion completed in 6.102943977s

• [SLOW TEST:6.352 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:21:44.970: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ghdbl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan  9 23:21:45.323: INFO: namespace e2e-tests-kubectl-ghdbl
Jan  9 23:21:45.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 create -f - --namespace=e2e-tests-kubectl-ghdbl'
Jan  9 23:21:46.403: INFO: stderr: ""
Jan  9 23:21:46.403: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan  9 23:21:47.408: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 23:21:47.408: INFO: Found 0 / 1
Jan  9 23:21:48.407: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 23:21:48.407: INFO: Found 0 / 1
Jan  9 23:21:49.407: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 23:21:49.407: INFO: Found 0 / 1
Jan  9 23:21:50.408: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 23:21:50.408: INFO: Found 1 / 1
Jan  9 23:21:50.408: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan  9 23:21:50.412: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 23:21:50.412: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan  9 23:21:50.412: INFO: wait on redis-master startup in e2e-tests-kubectl-ghdbl 
Jan  9 23:21:50.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 logs redis-master-9l6k4 redis-master --namespace=e2e-tests-kubectl-ghdbl'
Jan  9 23:21:50.536: INFO: stderr: ""
Jan  9 23:21:50.536: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Jan 23:21:48.708 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Jan 23:21:48.708 # Server started, Redis version 3.2.12\n1:M 09 Jan 23:21:48.708 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Jan 23:21:48.708 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jan  9 23:21:50.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-ghdbl'
Jan  9 23:21:50.672: INFO: stderr: ""
Jan  9 23:21:50.672: INFO: stdout: "service/rm2 exposed\n"
Jan  9 23:21:50.681: INFO: Service rm2 in namespace e2e-tests-kubectl-ghdbl found.
STEP: exposing service
Jan  9 23:21:52.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-ghdbl'
Jan  9 23:21:52.844: INFO: stderr: ""
Jan  9 23:21:52.844: INFO: stdout: "service/rm3 exposed\n"
Jan  9 23:21:52.852: INFO: Service rm3 in namespace e2e-tests-kubectl-ghdbl found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:21:54.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ghdbl" for this suite.
Jan  9 23:22:16.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:22:16.961: INFO: namespace: e2e-tests-kubectl-ghdbl, resource: bindings, ignored listing per whitelist
Jan  9 23:22:17.000: INFO: namespace e2e-tests-kubectl-ghdbl deletion completed in 22.123168392s

• [SLOW TEST:32.031 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:22:17.000: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-kw6nj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Jan  9 23:22:17.204: INFO: Waiting up to 5m0s for pod "var-expansion-677cab1e-1465-11e9-a046-02505600000d" in namespace "e2e-tests-var-expansion-kw6nj" to be "success or failure"
Jan  9 23:22:17.213: INFO: Pod "var-expansion-677cab1e-1465-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.907157ms
Jan  9 23:22:19.218: INFO: Pod "var-expansion-677cab1e-1465-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013554048s
Jan  9 23:22:21.222: INFO: Pod "var-expansion-677cab1e-1465-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017738901s
STEP: Saw pod success
Jan  9 23:22:21.222: INFO: Pod "var-expansion-677cab1e-1465-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:22:21.225: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod var-expansion-677cab1e-1465-11e9-a046-02505600000d container dapi-container: <nil>
STEP: delete the pod
Jan  9 23:22:21.252: INFO: Waiting for pod var-expansion-677cab1e-1465-11e9-a046-02505600000d to disappear
Jan  9 23:22:21.257: INFO: Pod var-expansion-677cab1e-1465-11e9-a046-02505600000d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:22:21.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-kw6nj" for this suite.
Jan  9 23:22:27.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:22:27.366: INFO: namespace: e2e-tests-var-expansion-kw6nj, resource: bindings, ignored listing per whitelist
Jan  9 23:22:27.368: INFO: namespace e2e-tests-var-expansion-kw6nj deletion completed in 6.106458538s

• [SLOW TEST:10.368 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:22:27.371: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-jrjp7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan  9 23:22:27.596: INFO: Waiting up to 5m0s for pod "pod-6dad2df1-1465-11e9-a046-02505600000d" in namespace "e2e-tests-emptydir-jrjp7" to be "success or failure"
Jan  9 23:22:27.610: INFO: Pod "pod-6dad2df1-1465-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.518736ms
Jan  9 23:22:29.615: INFO: Pod "pod-6dad2df1-1465-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018053201s
Jan  9 23:22:31.620: INFO: Pod "pod-6dad2df1-1465-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023131036s
STEP: Saw pod success
Jan  9 23:22:31.620: INFO: Pod "pod-6dad2df1-1465-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:22:31.624: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-6dad2df1-1465-11e9-a046-02505600000d container test-container: <nil>
STEP: delete the pod
Jan  9 23:22:31.648: INFO: Waiting for pod pod-6dad2df1-1465-11e9-a046-02505600000d to disappear
Jan  9 23:22:31.660: INFO: Pod pod-6dad2df1-1465-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:22:31.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jrjp7" for this suite.
Jan  9 23:22:37.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:22:37.706: INFO: namespace: e2e-tests-emptydir-jrjp7, resource: bindings, ignored listing per whitelist
Jan  9 23:22:37.758: INFO: namespace e2e-tests-emptydir-jrjp7 deletion completed in 6.092402538s

• [SLOW TEST:10.387 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:22:37.762: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-8vwht
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 23:22:37.967: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jan  9 23:22:42.972: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan  9 23:22:42.972: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jan  9 23:22:44.976: INFO: Creating deployment "test-rollover-deployment"
Jan  9 23:22:44.990: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jan  9 23:22:46.999: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jan  9 23:22:47.005: INFO: Ensure that both replica sets have 1 created replica
Jan  9 23:22:47.011: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jan  9 23:22:47.021: INFO: Updating deployment test-rollover-deployment
Jan  9 23:22:47.021: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jan  9 23:22:49.035: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jan  9 23:22:49.042: INFO: Make sure deployment "test-rollover-deployment" is complete
Jan  9 23:22:49.049: INFO: all replica sets need to contain the pod-template-hash label
Jan  9 23:22:49.049: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672965, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672965, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672968, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672965, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  9 23:22:51.058: INFO: all replica sets need to contain the pod-template-hash label
Jan  9 23:22:51.058: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672965, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672965, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672968, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672965, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  9 23:22:53.057: INFO: all replica sets need to contain the pod-template-hash label
Jan  9 23:22:53.057: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672965, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672965, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672968, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672965, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  9 23:22:55.057: INFO: all replica sets need to contain the pod-template-hash label
Jan  9 23:22:55.058: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672965, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672965, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672968, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672965, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  9 23:22:57.058: INFO: all replica sets need to contain the pod-template-hash label
Jan  9 23:22:57.058: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672965, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672965, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672968, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672965, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  9 23:22:59.065: INFO: 
Jan  9 23:22:59.065: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672965, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672965, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672979, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682672965, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan  9 23:23:01.058: INFO: 
Jan  9 23:23:01.058: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan  9 23:23:01.067: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-8vwht,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8vwht/deployments/test-rollover-deployment,UID:780ba56e-1465-11e9-9de1-005056902d46,ResourceVersion:19583,Generation:2,CreationTimestamp:2019-01-09 23:22:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-09 23:22:45 +0000 UTC 2019-01-09 23:22:45 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-09 23:22:59 +0000 UTC 2019-01-09 23:22:45 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan  9 23:23:01.071: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-8vwht,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8vwht/replicasets/test-rollover-deployment-5b76ff8c4,UID:7943bea5-1465-11e9-9de1-005056902d46,ResourceVersion:19573,Generation:2,CreationTimestamp:2019-01-09 23:22:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 780ba56e-1465-11e9-9de1-005056902d46 0xc42269ba07 0xc42269ba08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan  9 23:23:01.071: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jan  9 23:23:01.072: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-8vwht,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8vwht/replicasets/test-rollover-controller,UID:73dbe51f-1465-11e9-9de1-005056902d46,ResourceVersion:19582,Generation:2,CreationTimestamp:2019-01-09 23:22:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 780ba56e-1465-11e9-9de1-005056902d46 0xc42269b93e 0xc42269b93f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan  9 23:23:01.072: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-8vwht,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8vwht/replicasets/test-rollover-deployment-6975f4fb87,UID:780f8bca-1465-11e9-9de1-005056902d46,ResourceVersion:19546,Generation:2,CreationTimestamp:2019-01-09 23:22:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 780ba56e-1465-11e9-9de1-005056902d46 0xc42269bac7 0xc42269bac8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan  9 23:23:01.077: INFO: Pod "test-rollover-deployment-5b76ff8c4-ggr8w" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-ggr8w,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-8vwht,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8vwht/pods/test-rollover-deployment-5b76ff8c4-ggr8w,UID:794b86f5-1465-11e9-9de1-005056902d46,ResourceVersion:19556,Generation:0,CreationTimestamp:2019-01-09 23:22:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 7943bea5-1465-11e9-9de1-005056902d46 0xc421f825c0 0xc421f825c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sqshv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sqshv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-sqshv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:50ed3ea8-4626-444e-b102-822e7e7faeed,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f82620} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f82640}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:22:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:22:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:22:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:22:47 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.5,PodIP:40.0.5.4,StartTime:2019-01-09 23:22:47 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-09 23:22:48 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://9f858789ff0e6964dcf8482795e32a06d6bfb80c24c963a12b957bcaeb3f91a5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:23:01.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-8vwht" for this suite.
Jan  9 23:23:07.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:23:07.127: INFO: namespace: e2e-tests-deployment-8vwht, resource: bindings, ignored listing per whitelist
Jan  9 23:23:07.196: INFO: namespace e2e-tests-deployment-8vwht deletion completed in 6.114011663s

• [SLOW TEST:29.434 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:23:07.197: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-bkwbs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 23:23:07.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 version --client'
Jan  9 23:23:07.488: INFO: stderr: ""
Jan  9 23:23:07.488: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jan  9 23:23:07.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 create -f - --namespace=e2e-tests-kubectl-bkwbs'
Jan  9 23:23:07.772: INFO: stderr: ""
Jan  9 23:23:07.772: INFO: stdout: "replicationcontroller/redis-master created\n"
Jan  9 23:23:07.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 create -f - --namespace=e2e-tests-kubectl-bkwbs'
Jan  9 23:23:08.011: INFO: stderr: ""
Jan  9 23:23:08.011: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan  9 23:23:09.016: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 23:23:09.017: INFO: Found 0 / 1
Jan  9 23:23:10.017: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 23:23:10.017: INFO: Found 0 / 1
Jan  9 23:23:11.018: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 23:23:11.018: INFO: Found 1 / 1
Jan  9 23:23:11.018: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan  9 23:23:11.020: INFO: Selector matched 1 pods for map[app:redis]
Jan  9 23:23:11.020: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan  9 23:23:11.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 describe pod redis-master-cc6w4 --namespace=e2e-tests-kubectl-bkwbs'
Jan  9 23:23:11.143: INFO: stderr: ""
Jan  9 23:23:11.143: INFO: stdout: "Name:               redis-master-cc6w4\nNamespace:          e2e-tests-kubectl-bkwbs\nPriority:           0\nPriorityClassName:  <none>\nNode:               362e6945-cc10-4a7c-ad11-8cf4815006e1/30.0.3.4\nStart Time:         Wed, 09 Jan 2019 23:23:07 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 40.0.6.2\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://6767cf7223a21aa189289c5823a5cf5a77ebc93350f3100955a3f6a6b0a1e6a0\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 09 Jan 2019 23:23:09 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-gw8vw (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-gw8vw:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-gw8vw\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                           Message\n  ----    ------     ----  ----                                           -------\n  Normal  Scheduled  4s    default-scheduler                              Successfully assigned e2e-tests-kubectl-bkwbs/redis-master-cc6w4 to 362e6945-cc10-4a7c-ad11-8cf4815006e1\n  Normal  Pulled     2s    kubelet, 362e6945-cc10-4a7c-ad11-8cf4815006e1  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, 362e6945-cc10-4a7c-ad11-8cf4815006e1  Created container\n  Normal  Started    2s    kubelet, 362e6945-cc10-4a7c-ad11-8cf4815006e1  Started container\n"
Jan  9 23:23:11.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 describe rc redis-master --namespace=e2e-tests-kubectl-bkwbs'
Jan  9 23:23:11.290: INFO: stderr: ""
Jan  9 23:23:11.290: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-bkwbs\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-cc6w4\n"
Jan  9 23:23:11.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 describe service redis-master --namespace=e2e-tests-kubectl-bkwbs'
Jan  9 23:23:11.423: INFO: stderr: ""
Jan  9 23:23:11.423: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-bkwbs\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.100.200.84\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         40.0.6.2:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jan  9 23:23:11.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 describe node 362e6945-cc10-4a7c-ad11-8cf4815006e1'
Jan  9 23:23:11.572: INFO: stderr: ""
Jan  9 23:23:11.572: INFO: stdout: "Name:               362e6945-cc10-4a7c-ad11-8cf4815006e1\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    bosh.id=2d6a9297-da8f-427f-9bf3-375c22d3bc23\n                    bosh.zone=az-2\n                    failure-domain.beta.kubernetes.io/zone=az-2\n                    kubernetes.io/hostname=30.0.3.4\n                    spec.ip=30.0.3.4\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 09 Jan 2019 20:51:47 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Wed, 09 Jan 2019 23:23:10 +0000   Wed, 09 Jan 2019 20:51:47 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Wed, 09 Jan 2019 23:23:10 +0000   Wed, 09 Jan 2019 20:51:47 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 09 Jan 2019 23:23:10 +0000   Wed, 09 Jan 2019 20:51:47 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 09 Jan 2019 23:23:10 +0000   Wed, 09 Jan 2019 20:51:47 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 09 Jan 2019 23:23:10 +0000   Wed, 09 Jan 2019 20:51:47 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  ExternalIP:  30.0.3.4\n  InternalIP:  30.0.3.4\n  Hostname:    30.0.3.4\nCapacity:\n cpu:                2\n ephemeral-storage:  3030944Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8168828Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  2793317986\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8066428Ki\n pods:               110\nSystem Info:\n Machine ID:                 6db40ea29d4363ade6a737337df95111\n System UUID:                42102A28-0BC1-D681-03A1-4F6F3E7E4FCE\n Boot ID:                    1575ae6b-66b1-42fe-ae92-7c2c62902700\n Kernel Version:             4.15.0-42-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.12.4\n Kube-Proxy Version:         v1.12.4\nProviderID:                  vsphere://42102a28-0bc1-d681-03a1-4f6f3e7e4fce\nNon-terminated Pods:         (8 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  e2e-tests-kubectl-bkwbs    redis-master-cc6w4                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-6feb07c93b6e401e-cnswx    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                heapster-85647cf566-dbhkz                                  0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kubernetes-dashboard-5f4b59b97f-jtrxq                      50m (2%)      100m (5%)   100Mi (1%)       300Mi (3%)\n  pks-system                 event-controller-6c77ddd949-gfsgs                          0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  pks-system                 fluent-bit-v8nfk                                           0 (0%)        0 (0%)      100Mi (1%)       100Mi (1%)\n  pks-system                 sink-controller-65595c498b-m5gzm                           0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  pks-system                 telemetry-agent-559f9c8855-t6jq6                           0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests    Limits\n  --------  --------    ------\n  cpu       50m (2%)    100m (5%)\n  memory    200Mi (2%)  400Mi (5%)\nEvents:     <none>\n"
Jan  9 23:23:11.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 describe namespace e2e-tests-kubectl-bkwbs'
Jan  9 23:23:11.703: INFO: stderr: ""
Jan  9 23:23:11.703: INFO: stdout: "Name:         e2e-tests-kubectl-bkwbs\nLabels:       e2e-framework=kubectl\n              e2e-run=3653f488-145f-11e9-a046-02505600000d\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:23:11.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bkwbs" for this suite.
Jan  9 23:23:33.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:23:33.783: INFO: namespace: e2e-tests-kubectl-bkwbs, resource: bindings, ignored listing per whitelist
Jan  9 23:23:33.813: INFO: namespace e2e-tests-kubectl-bkwbs deletion completed in 22.105347192s

• [SLOW TEST:26.617 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:23:33.814: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-l4x5q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan  9 23:23:34.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 create -f - --namespace=e2e-tests-kubectl-l4x5q'
Jan  9 23:23:34.300: INFO: stderr: ""
Jan  9 23:23:34.300: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan  9 23:23:34.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-l4x5q'
Jan  9 23:23:34.423: INFO: stderr: ""
Jan  9 23:23:34.423: INFO: stdout: "update-demo-nautilus-6llrx update-demo-nautilus-blmcr "
Jan  9 23:23:34.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-6llrx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-l4x5q'
Jan  9 23:23:34.548: INFO: stderr: ""
Jan  9 23:23:34.548: INFO: stdout: ""
Jan  9 23:23:34.548: INFO: update-demo-nautilus-6llrx is created but not running
Jan  9 23:23:39.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-l4x5q'
Jan  9 23:23:39.638: INFO: stderr: ""
Jan  9 23:23:39.638: INFO: stdout: "update-demo-nautilus-6llrx update-demo-nautilus-blmcr "
Jan  9 23:23:39.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-6llrx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-l4x5q'
Jan  9 23:23:39.743: INFO: stderr: ""
Jan  9 23:23:39.743: INFO: stdout: "true"
Jan  9 23:23:39.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-6llrx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-l4x5q'
Jan  9 23:23:39.854: INFO: stderr: ""
Jan  9 23:23:39.854: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 23:23:39.854: INFO: validating pod update-demo-nautilus-6llrx
Jan  9 23:23:39.861: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 23:23:39.861: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 23:23:39.861: INFO: update-demo-nautilus-6llrx is verified up and running
Jan  9 23:23:39.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-blmcr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-l4x5q'
Jan  9 23:23:39.962: INFO: stderr: ""
Jan  9 23:23:39.962: INFO: stdout: "true"
Jan  9 23:23:39.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-blmcr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-l4x5q'
Jan  9 23:23:40.070: INFO: stderr: ""
Jan  9 23:23:40.070: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 23:23:40.070: INFO: validating pod update-demo-nautilus-blmcr
Jan  9 23:23:40.079: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 23:23:40.079: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 23:23:40.079: INFO: update-demo-nautilus-blmcr is verified up and running
STEP: using delete to clean up resources
Jan  9 23:23:40.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-l4x5q'
Jan  9 23:23:40.204: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 23:23:40.204: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan  9 23:23:40.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-l4x5q'
Jan  9 23:23:40.314: INFO: stderr: "No resources found.\n"
Jan  9 23:23:40.314: INFO: stdout: ""
Jan  9 23:23:40.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods -l name=update-demo --namespace=e2e-tests-kubectl-l4x5q -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan  9 23:23:40.434: INFO: stderr: ""
Jan  9 23:23:40.434: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:23:40.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l4x5q" for this suite.
Jan  9 23:24:02.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:24:02.536: INFO: namespace: e2e-tests-kubectl-l4x5q, resource: bindings, ignored listing per whitelist
Jan  9 23:24:02.550: INFO: namespace e2e-tests-kubectl-l4x5q deletion completed in 22.110472097s

• [SLOW TEST:28.736 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:24:02.550: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-qknkp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-qknkp
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-qknkp
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-qknkp
Jan  9 23:24:02.771: INFO: Found 0 stateful pods, waiting for 1
Jan  9 23:24:12.775: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jan  9 23:24:12.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 23:24:12.989: INFO: stderr: ""
Jan  9 23:24:12.989: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 23:24:12.989: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  9 23:24:12.993: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan  9 23:24:22.997: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan  9 23:24:22.997: INFO: Waiting for statefulset status.replicas updated to 0
Jan  9 23:24:23.018: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan  9 23:24:23.019: INFO: ss-0  50ed3ea8-4626-444e-b102-822e7e7faeed  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:13 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:02 +0000 UTC  }]
Jan  9 23:24:23.019: INFO: ss-1                                        Pending         []
Jan  9 23:24:23.019: INFO: 
Jan  9 23:24:23.020: INFO: StatefulSet ss has not reached scale 3, at 2
Jan  9 23:24:24.025: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.987373196s
Jan  9 23:24:25.030: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.982814048s
Jan  9 23:24:26.037: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.977215842s
Jan  9 23:24:27.042: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.970525002s
Jan  9 23:24:28.047: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.965804446s
Jan  9 23:24:29.052: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.960629702s
Jan  9 23:24:30.055: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.95582658s
Jan  9 23:24:31.064: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.952141825s
Jan  9 23:24:32.070: INFO: Verifying statefulset ss doesn't scale past 3 for another 942.884698ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-qknkp
Jan  9 23:24:33.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:24:33.290: INFO: stderr: ""
Jan  9 23:24:33.290: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  9 23:24:33.290: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  9 23:24:33.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:24:33.505: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan  9 23:24:33.505: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  9 23:24:33.505: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  9 23:24:33.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:24:33.770: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan  9 23:24:33.770: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  9 23:24:33.770: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  9 23:24:33.774: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan  9 23:24:33.774: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan  9 23:24:33.774: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jan  9 23:24:33.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 23:24:33.967: INFO: stderr: ""
Jan  9 23:24:33.967: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 23:24:33.967: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  9 23:24:33.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 23:24:34.179: INFO: stderr: ""
Jan  9 23:24:34.179: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 23:24:34.179: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  9 23:24:34.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 23:24:34.398: INFO: stderr: ""
Jan  9 23:24:34.398: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 23:24:34.398: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  9 23:24:34.398: INFO: Waiting for statefulset status.replicas updated to 0
Jan  9 23:24:34.402: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jan  9 23:24:44.409: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan  9 23:24:44.409: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan  9 23:24:44.409: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan  9 23:24:44.424: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan  9 23:24:44.424: INFO: ss-0  50ed3ea8-4626-444e-b102-822e7e7faeed  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:02 +0000 UTC  }]
Jan  9 23:24:44.424: INFO: ss-1  362e6945-cc10-4a7c-ad11-8cf4815006e1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:44.425: INFO: ss-2  582539c0-37f1-42db-85f2-2655dcef1574  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:44.425: INFO: 
Jan  9 23:24:44.425: INFO: StatefulSet ss has not reached scale 0, at 3
Jan  9 23:24:45.429: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan  9 23:24:45.429: INFO: ss-0  50ed3ea8-4626-444e-b102-822e7e7faeed  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:02 +0000 UTC  }]
Jan  9 23:24:45.429: INFO: ss-1  362e6945-cc10-4a7c-ad11-8cf4815006e1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:45.429: INFO: ss-2  582539c0-37f1-42db-85f2-2655dcef1574  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:45.429: INFO: 
Jan  9 23:24:45.429: INFO: StatefulSet ss has not reached scale 0, at 3
Jan  9 23:24:46.434: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan  9 23:24:46.434: INFO: ss-1  362e6945-cc10-4a7c-ad11-8cf4815006e1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:46.434: INFO: ss-2  582539c0-37f1-42db-85f2-2655dcef1574  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:46.434: INFO: 
Jan  9 23:24:46.434: INFO: StatefulSet ss has not reached scale 0, at 2
Jan  9 23:24:47.445: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan  9 23:24:47.445: INFO: ss-1  362e6945-cc10-4a7c-ad11-8cf4815006e1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:47.445: INFO: ss-2  582539c0-37f1-42db-85f2-2655dcef1574  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:47.445: INFO: 
Jan  9 23:24:47.445: INFO: StatefulSet ss has not reached scale 0, at 2
Jan  9 23:24:48.451: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan  9 23:24:48.451: INFO: ss-1  362e6945-cc10-4a7c-ad11-8cf4815006e1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:48.451: INFO: ss-2  582539c0-37f1-42db-85f2-2655dcef1574  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:48.452: INFO: 
Jan  9 23:24:48.452: INFO: StatefulSet ss has not reached scale 0, at 2
Jan  9 23:24:49.456: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan  9 23:24:49.456: INFO: ss-1  362e6945-cc10-4a7c-ad11-8cf4815006e1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:49.456: INFO: ss-2  582539c0-37f1-42db-85f2-2655dcef1574  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:49.456: INFO: 
Jan  9 23:24:49.456: INFO: StatefulSet ss has not reached scale 0, at 2
Jan  9 23:24:50.461: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan  9 23:24:50.462: INFO: ss-1  362e6945-cc10-4a7c-ad11-8cf4815006e1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:50.462: INFO: ss-2  582539c0-37f1-42db-85f2-2655dcef1574  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:50.463: INFO: 
Jan  9 23:24:50.463: INFO: StatefulSet ss has not reached scale 0, at 2
Jan  9 23:24:51.468: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan  9 23:24:51.468: INFO: ss-1  362e6945-cc10-4a7c-ad11-8cf4815006e1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:51.469: INFO: ss-2  582539c0-37f1-42db-85f2-2655dcef1574  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:51.469: INFO: 
Jan  9 23:24:51.469: INFO: StatefulSet ss has not reached scale 0, at 2
Jan  9 23:24:52.474: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan  9 23:24:52.474: INFO: ss-1  362e6945-cc10-4a7c-ad11-8cf4815006e1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:52.474: INFO: ss-2  582539c0-37f1-42db-85f2-2655dcef1574  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:52.474: INFO: 
Jan  9 23:24:52.474: INFO: StatefulSet ss has not reached scale 0, at 2
Jan  9 23:24:53.478: INFO: POD   NODE                                  PHASE    GRACE  CONDITIONS
Jan  9 23:24:53.479: INFO: ss-1  362e6945-cc10-4a7c-ad11-8cf4815006e1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:53.479: INFO: ss-2  582539c0-37f1-42db-85f2-2655dcef1574  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:24:23 +0000 UTC  }]
Jan  9 23:24:53.479: INFO: 
Jan  9 23:24:53.479: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-qknkp
Jan  9 23:24:54.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:24:54.633: INFO: rc: 1
Jan  9 23:24:54.634: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc42184c3c0 exit status 1 <nil> <nil> true [0xc42218b9e8 0xc42218ba00 0xc42218ba18] [0xc42218b9e8 0xc42218ba00 0xc42218ba18] [0xc42218b9f8 0xc42218ba10] [0x8fd520 0x8fd520] 0xc4216a27e0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Jan  9 23:25:04.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:25:04.731: INFO: rc: 1
Jan  9 23:25:04.731: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421fd5d40 exit status 1 <nil> <nil> true [0xc421a5fd70 0xc421a5fdb0 0xc421a5fdc8] [0xc421a5fd70 0xc421a5fdb0 0xc421a5fdc8] [0xc421a5fda8 0xc421a5fdc0] [0x8fd520 0x8fd520] 0xc421d8ea80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:25:14.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:25:14.837: INFO: rc: 1
Jan  9 23:25:14.837: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42216a420 exit status 1 <nil> <nil> true [0xc4212900e0 0xc4212901c8 0xc421290238] [0xc4212900e0 0xc4212901c8 0xc421290238] [0xc421290138 0xc421290230] [0x8fd520 0x8fd520] 0xc42148a060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:25:24.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:25:24.940: INFO: rc: 1
Jan  9 23:25:24.940: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422020390 exit status 1 <nil> <nil> true [0xc42000e120 0xc42000e2f8 0xc42000e4e0] [0xc42000e120 0xc42000e2f8 0xc42000e4e0] [0xc42000e280 0xc42000e400] [0x8fd520 0x8fd520] 0xc4217ce060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:25:34.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:25:35.057: INFO: rc: 1
Jan  9 23:25:35.057: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42216a7b0 exit status 1 <nil> <nil> true [0xc421290278 0xc421290358 0xc4212903c0] [0xc421290278 0xc421290358 0xc4212903c0] [0xc4212902f0 0xc4212903b8] [0x8fd520 0x8fd520] 0xc42148a180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:25:45.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:25:45.161: INFO: rc: 1
Jan  9 23:25:45.162: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42216ae70 exit status 1 <nil> <nil> true [0xc421290400 0xc421290500 0xc421290650] [0xc421290400 0xc421290500 0xc421290650] [0xc421290480 0xc421290550] [0x8fd520 0x8fd520] 0xc42148a360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:25:55.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:25:55.275: INFO: rc: 1
Jan  9 23:25:55.275: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4220208a0 exit status 1 <nil> <nil> true [0xc42000e500 0xc4200ca200 0xc4200cbc98] [0xc42000e500 0xc4200ca200 0xc4200cbc98] [0xc4200ca1d0 0xc4200ca2d0] [0x8fd520 0x8fd520] 0xc4217ce480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:26:05.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:26:05.395: INFO: rc: 1
Jan  9 23:26:05.395: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422020d80 exit status 1 <nil> <nil> true [0xc4200cbd18 0xc4200cbd88 0xc4200cbe00] [0xc4200cbd18 0xc4200cbd88 0xc4200cbe00] [0xc4200cbd70 0xc4200cbdc8] [0x8fd520 0x8fd520] 0xc4217ceba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:26:15.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:26:15.487: INFO: rc: 1
Jan  9 23:26:15.487: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42216b3e0 exit status 1 <nil> <nil> true [0xc4212906e0 0xc4212907b8 0xc421290808] [0xc4212906e0 0xc4212907b8 0xc421290808] [0xc421290798 0xc4212907e8] [0x8fd520 0x8fd520] 0xc42148a480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:26:25.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:26:25.599: INFO: rc: 1
Jan  9 23:26:25.599: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422021200 exit status 1 <nil> <nil> true [0xc4200cbe18 0xc4200cbea0 0xc4200cbef8] [0xc4200cbe18 0xc4200cbea0 0xc4200cbef8] [0xc4200cbe48 0xc4200cbee0] [0x8fd520 0x8fd520] 0xc4217cecc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:26:35.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:26:35.715: INFO: rc: 1
Jan  9 23:26:35.715: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422021740 exit status 1 <nil> <nil> true [0xc4200cbf28 0xc421bc0050 0xc421bc00b0] [0xc4200cbf28 0xc421bc0050 0xc421bc00b0] [0xc421bc0038 0xc421bc0090] [0x8fd520 0x8fd520] 0xc4217cede0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:26:45.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:26:45.815: INFO: rc: 1
Jan  9 23:26:45.815: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42216b830 exit status 1 <nil> <nil> true [0xc421290830 0xc4212908e0 0xc421290a10] [0xc421290830 0xc4212908e0 0xc421290a10] [0xc4212908a0 0xc421290960] [0x8fd520 0x8fd520] 0xc42148a5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:26:55.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:26:55.911: INFO: rc: 1
Jan  9 23:26:55.911: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422021b60 exit status 1 <nil> <nil> true [0xc421bc00d0 0xc421bc0118 0xc421bc0150] [0xc421bc00d0 0xc421bc0118 0xc421bc0150] [0xc421bc0100 0xc421bc0140] [0x8fd520 0x8fd520] 0xc4217cef00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:27:05.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:27:06.030: INFO: rc: 1
Jan  9 23:27:06.030: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42216bf80 exit status 1 <nil> <nil> true [0xc421290ae8 0xc421290ba8 0xc421290d18] [0xc421290ae8 0xc421290ba8 0xc421290d18] [0xc421290b68 0xc421290cf0] [0x8fd520 0x8fd520] 0xc42148a6c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:27:16.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:27:16.122: INFO: rc: 1
Jan  9 23:27:16.122: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42216a450 exit status 1 <nil> <nil> true [0xc4200ca1d0 0xc4200ca2d0 0xc4200cbd48] [0xc4200ca1d0 0xc4200ca2d0 0xc4200cbd48] [0xc4200ca230 0xc4200cbd18] [0x8fd520 0x8fd520] 0xc4217ce060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:27:26.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:27:26.214: INFO: rc: 1
Jan  9 23:27:26.215: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42216a840 exit status 1 <nil> <nil> true [0xc4200cbd70 0xc4200cbdc8 0xc4200cbe38] [0xc4200cbd70 0xc4200cbdc8 0xc4200cbe38] [0xc4200cbda8 0xc4200cbe18] [0x8fd520 0x8fd520] 0xc4217ce480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:27:36.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:27:36.335: INFO: rc: 1
Jan  9 23:27:36.335: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4220203c0 exit status 1 <nil> <nil> true [0xc42000e120 0xc42000e2f8 0xc42000e4e0] [0xc42000e120 0xc42000e2f8 0xc42000e4e0] [0xc42000e280 0xc42000e400] [0x8fd520 0x8fd520] 0xc42148a060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:27:46.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:27:46.422: INFO: rc: 1
Jan  9 23:27:46.423: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42216aff0 exit status 1 <nil> <nil> true [0xc4200cbe48 0xc4200cbee0 0xc421bc0010] [0xc4200cbe48 0xc4200cbee0 0xc421bc0010] [0xc4200cbec8 0xc4200cbf28] [0x8fd520 0x8fd520] 0xc4217ceba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:27:56.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:27:56.518: INFO: rc: 1
Jan  9 23:27:56.518: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42216b4a0 exit status 1 <nil> <nil> true [0xc421bc0038 0xc421bc0090 0xc421bc00f0] [0xc421bc0038 0xc421bc0090 0xc421bc00f0] [0xc421bc0060 0xc421bc00d0] [0x8fd520 0x8fd520] 0xc4217cecc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:28:06.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:28:06.619: INFO: rc: 1
Jan  9 23:28:06.620: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422020930 exit status 1 <nil> <nil> true [0xc42000e500 0xc421290110 0xc421290200] [0xc42000e500 0xc421290110 0xc421290200] [0xc4212900e0 0xc4212901c8] [0x8fd520 0x8fd520] 0xc42148a180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:28:16.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:28:16.702: INFO: rc: 1
Jan  9 23:28:16.702: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422020db0 exit status 1 <nil> <nil> true [0xc421290230 0xc4212902c8 0xc421290398] [0xc421290230 0xc4212902c8 0xc421290398] [0xc421290278 0xc421290358] [0x8fd520 0x8fd520] 0xc42148a360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:28:26.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:28:26.799: INFO: rc: 1
Jan  9 23:28:26.799: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42216bb00 exit status 1 <nil> <nil> true [0xc421bc0100 0xc421bc0140 0xc421bc0178] [0xc421bc0100 0xc421bc0140 0xc421bc0178] [0xc421bc0128 0xc421bc0168] [0x8fd520 0x8fd520] 0xc4217cede0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:28:36.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:28:36.894: INFO: rc: 1
Jan  9 23:28:36.894: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421faa0f0 exit status 1 <nil> <nil> true [0xc421bc0190 0xc421bc01c8 0xc421bc0208] [0xc421bc0190 0xc421bc01c8 0xc421bc0208] [0xc421bc01b8 0xc421bc01f0] [0x8fd520 0x8fd520] 0xc4217cef00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:28:46.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:28:46.981: INFO: rc: 1
Jan  9 23:28:46.981: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421faa570 exit status 1 <nil> <nil> true [0xc421bc0218 0xc421bc0248 0xc421bc0280] [0xc421bc0218 0xc421bc0248 0xc421bc0280] [0xc421bc0238 0xc421bc0270] [0x8fd520 0x8fd520] 0xc4217cf020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:28:56.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:28:57.082: INFO: rc: 1
Jan  9 23:28:57.082: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422021380 exit status 1 <nil> <nil> true [0xc4212903b8 0xc421290418 0xc421290510] [0xc4212903b8 0xc421290418 0xc421290510] [0xc421290400 0xc421290500] [0x8fd520 0x8fd520] 0xc42148a480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:29:07.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:29:07.177: INFO: rc: 1
Jan  9 23:29:07.177: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc4220218f0 exit status 1 <nil> <nil> true [0xc421290550 0xc421290740 0xc4212907c0] [0xc421290550 0xc421290740 0xc4212907c0] [0xc4212906e0 0xc4212907b8] [0x8fd520 0x8fd520] 0xc42148a5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:29:17.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:29:17.319: INFO: rc: 1
Jan  9 23:29:17.319: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc422021d40 exit status 1 <nil> <nil> true [0xc421290808 0xc4212908a0 0xc421290960] [0xc421290808 0xc4212908a0 0xc421290960] [0xc421290888 0xc421290948] [0x8fd520 0x8fd520] 0xc42148a6c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:29:27.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:29:27.412: INFO: rc: 1
Jan  9 23:29:27.412: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc42216a420 exit status 1 <nil> <nil> true [0xc42000e120 0xc42000e2f8 0xc42000e4e0] [0xc42000e120 0xc42000e2f8 0xc42000e4e0] [0xc42000e280 0xc42000e400] [0x8fd520 0x8fd520] 0xc4217ce060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:29:37.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:29:37.545: INFO: rc: 1
Jan  9 23:29:37.545: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421faa510 exit status 1 <nil> <nil> true [0xc4200ca150 0xc4200ca230 0xc4200cbd18] [0xc4200ca150 0xc4200ca230 0xc4200cbd18] [0xc4200ca200 0xc4200cbc98] [0x8fd520 0x8fd520] 0xc42148a060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:29:47.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:29:47.664: INFO: rc: 1
Jan  9 23:29:47.665: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc421faa990 exit status 1 <nil> <nil> true [0xc4200cbd48 0xc4200cbda8 0xc4200cbe18] [0xc4200cbd48 0xc4200cbda8 0xc4200cbe18] [0xc4200cbd88 0xc4200cbe00] [0x8fd520 0x8fd520] 0xc42148a180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1

Jan  9 23:29:57.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-qknkp ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:29:57.758: INFO: rc: 1
Jan  9 23:29:57.758: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Jan  9 23:29:57.758: INFO: Scaling statefulset ss to 0
Jan  9 23:29:57.771: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan  9 23:29:57.774: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qknkp
Jan  9 23:29:57.777: INFO: Scaling statefulset ss to 0
Jan  9 23:29:57.784: INFO: Waiting for statefulset status.replicas updated to 0
Jan  9 23:29:57.786: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:29:57.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qknkp" for this suite.
Jan  9 23:30:03.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:30:03.924: INFO: namespace: e2e-tests-statefulset-qknkp, resource: bindings, ignored listing per whitelist
Jan  9 23:30:03.927: INFO: namespace e2e-tests-statefulset-qknkp deletion completed in 6.116620598s

• [SLOW TEST:361.378 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:30:03.929: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rlqbh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-7dcb147c-1466-11e9-a046-02505600000d
STEP: Creating a pod to test consume configMaps
Jan  9 23:30:04.134: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7dcc2d5f-1466-11e9-a046-02505600000d" in namespace "e2e-tests-projected-rlqbh" to be "success or failure"
Jan  9 23:30:04.141: INFO: Pod "pod-projected-configmaps-7dcc2d5f-1466-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.592371ms
Jan  9 23:30:06.146: INFO: Pod "pod-projected-configmaps-7dcc2d5f-1466-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011837059s
Jan  9 23:30:08.150: INFO: Pod "pod-projected-configmaps-7dcc2d5f-1466-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016029211s
STEP: Saw pod success
Jan  9 23:30:08.150: INFO: Pod "pod-projected-configmaps-7dcc2d5f-1466-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:30:08.154: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-projected-configmaps-7dcc2d5f-1466-11e9-a046-02505600000d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 23:30:08.183: INFO: Waiting for pod pod-projected-configmaps-7dcc2d5f-1466-11e9-a046-02505600000d to disappear
Jan  9 23:30:08.185: INFO: Pod pod-projected-configmaps-7dcc2d5f-1466-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:30:08.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rlqbh" for this suite.
Jan  9 23:30:14.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:30:14.224: INFO: namespace: e2e-tests-projected-rlqbh, resource: bindings, ignored listing per whitelist
Jan  9 23:30:14.303: INFO: namespace e2e-tests-projected-rlqbh deletion completed in 6.112715252s

• [SLOW TEST:10.374 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:30:14.307: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-nr6bg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-83fc7026-1466-11e9-a046-02505600000d
STEP: Creating a pod to test consume secrets
Jan  9 23:30:14.528: INFO: Waiting up to 5m0s for pod "pod-secrets-83fcfe23-1466-11e9-a046-02505600000d" in namespace "e2e-tests-secrets-nr6bg" to be "success or failure"
Jan  9 23:30:14.555: INFO: Pod "pod-secrets-83fcfe23-1466-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 27.000215ms
Jan  9 23:30:16.560: INFO: Pod "pod-secrets-83fcfe23-1466-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031851145s
STEP: Saw pod success
Jan  9 23:30:16.560: INFO: Pod "pod-secrets-83fcfe23-1466-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:30:16.563: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-secrets-83fcfe23-1466-11e9-a046-02505600000d container secret-volume-test: <nil>
STEP: delete the pod
Jan  9 23:30:16.600: INFO: Waiting for pod pod-secrets-83fcfe23-1466-11e9-a046-02505600000d to disappear
Jan  9 23:30:16.604: INFO: Pod pod-secrets-83fcfe23-1466-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:30:16.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nr6bg" for this suite.
Jan  9 23:30:22.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:30:22.640: INFO: namespace: e2e-tests-secrets-nr6bg, resource: bindings, ignored listing per whitelist
Jan  9 23:30:22.729: INFO: namespace e2e-tests-secrets-nr6bg deletion completed in 6.12045296s

• [SLOW TEST:8.422 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:30:22.729: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-7gg5m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-8901df93-1466-11e9-a046-02505600000d
STEP: Creating a pod to test consume secrets
Jan  9 23:30:22.945: INFO: Waiting up to 5m0s for pod "pod-secrets-89026305-1466-11e9-a046-02505600000d" in namespace "e2e-tests-secrets-7gg5m" to be "success or failure"
Jan  9 23:30:22.948: INFO: Pod "pod-secrets-89026305-1466-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.393366ms
Jan  9 23:30:24.953: INFO: Pod "pod-secrets-89026305-1466-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007668946s
Jan  9 23:30:26.956: INFO: Pod "pod-secrets-89026305-1466-11e9-a046-02505600000d": Phase="Running", Reason="", readiness=true. Elapsed: 4.011554115s
Jan  9 23:30:28.961: INFO: Pod "pod-secrets-89026305-1466-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01599002s
STEP: Saw pod success
Jan  9 23:30:28.961: INFO: Pod "pod-secrets-89026305-1466-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:30:28.965: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-secrets-89026305-1466-11e9-a046-02505600000d container secret-volume-test: <nil>
STEP: delete the pod
Jan  9 23:30:28.984: INFO: Waiting for pod pod-secrets-89026305-1466-11e9-a046-02505600000d to disappear
Jan  9 23:30:28.989: INFO: Pod pod-secrets-89026305-1466-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:30:28.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7gg5m" for this suite.
Jan  9 23:30:35.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:30:35.245: INFO: namespace: e2e-tests-secrets-7gg5m, resource: bindings, ignored listing per whitelist
Jan  9 23:30:35.265: INFO: namespace e2e-tests-secrets-7gg5m deletion completed in 6.272061159s

• [SLOW TEST:12.536 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:30:35.265: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9gkw5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 23:30:35.479: INFO: Waiting up to 5m0s for pod "downwardapi-volume-907ac637-1466-11e9-a046-02505600000d" in namespace "e2e-tests-projected-9gkw5" to be "success or failure"
Jan  9 23:30:35.493: INFO: Pod "downwardapi-volume-907ac637-1466-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.886216ms
Jan  9 23:30:37.498: INFO: Pod "downwardapi-volume-907ac637-1466-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018439348s
Jan  9 23:30:39.501: INFO: Pod "downwardapi-volume-907ac637-1466-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022224468s
STEP: Saw pod success
Jan  9 23:30:39.502: INFO: Pod "downwardapi-volume-907ac637-1466-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:30:39.504: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod downwardapi-volume-907ac637-1466-11e9-a046-02505600000d container client-container: <nil>
STEP: delete the pod
Jan  9 23:30:39.529: INFO: Waiting for pod downwardapi-volume-907ac637-1466-11e9-a046-02505600000d to disappear
Jan  9 23:30:39.537: INFO: Pod downwardapi-volume-907ac637-1466-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:30:39.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9gkw5" for this suite.
Jan  9 23:30:45.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:30:45.584: INFO: namespace: e2e-tests-projected-9gkw5, resource: bindings, ignored listing per whitelist
Jan  9 23:30:45.642: INFO: namespace e2e-tests-projected-9gkw5 deletion completed in 6.101804069s

• [SLOW TEST:10.377 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:30:45.648: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-6g495
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 23:30:45.852: INFO: Waiting up to 5m0s for pod "downwardapi-volume-96aa27f8-1466-11e9-a046-02505600000d" in namespace "e2e-tests-downward-api-6g495" to be "success or failure"
Jan  9 23:30:45.858: INFO: Pod "downwardapi-volume-96aa27f8-1466-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.04234ms
Jan  9 23:30:47.863: INFO: Pod "downwardapi-volume-96aa27f8-1466-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011046876s
Jan  9 23:30:49.866: INFO: Pod "downwardapi-volume-96aa27f8-1466-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014566102s
STEP: Saw pod success
Jan  9 23:30:49.866: INFO: Pod "downwardapi-volume-96aa27f8-1466-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:30:49.869: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod downwardapi-volume-96aa27f8-1466-11e9-a046-02505600000d container client-container: <nil>
STEP: delete the pod
Jan  9 23:30:49.898: INFO: Waiting for pod downwardapi-volume-96aa27f8-1466-11e9-a046-02505600000d to disappear
Jan  9 23:30:49.903: INFO: Pod downwardapi-volume-96aa27f8-1466-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:30:49.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6g495" for this suite.
Jan  9 23:30:55.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:30:55.996: INFO: namespace: e2e-tests-downward-api-6g495, resource: bindings, ignored listing per whitelist
Jan  9 23:30:56.015: INFO: namespace e2e-tests-downward-api-6g495 deletion completed in 6.107659366s

• [SLOW TEST:10.368 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:30:56.017: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-ggl5p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan  9 23:30:56.249: INFO: Waiting up to 5m0s for pod "pod-9cdbe983-1466-11e9-a046-02505600000d" in namespace "e2e-tests-emptydir-ggl5p" to be "success or failure"
Jan  9 23:30:56.253: INFO: Pod "pod-9cdbe983-1466-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.270604ms
Jan  9 23:30:58.258: INFO: Pod "pod-9cdbe983-1466-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008139614s
Jan  9 23:31:00.262: INFO: Pod "pod-9cdbe983-1466-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012846609s
STEP: Saw pod success
Jan  9 23:31:00.262: INFO: Pod "pod-9cdbe983-1466-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:31:00.266: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-9cdbe983-1466-11e9-a046-02505600000d container test-container: <nil>
STEP: delete the pod
Jan  9 23:31:00.287: INFO: Waiting for pod pod-9cdbe983-1466-11e9-a046-02505600000d to disappear
Jan  9 23:31:00.296: INFO: Pod pod-9cdbe983-1466-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:31:00.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ggl5p" for this suite.
Jan  9 23:31:06.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:31:06.393: INFO: namespace: e2e-tests-emptydir-ggl5p, resource: bindings, ignored listing per whitelist
Jan  9 23:31:06.404: INFO: namespace e2e-tests-emptydir-ggl5p deletion completed in 6.104204987s

• [SLOW TEST:10.387 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:31:06.405: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-f58x4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0109 23:31:07.670921      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan  9 23:31:07.671: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:31:07.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-f58x4" for this suite.
Jan  9 23:31:13.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:31:13.727: INFO: namespace: e2e-tests-gc-f58x4, resource: bindings, ignored listing per whitelist
Jan  9 23:31:13.778: INFO: namespace e2e-tests-gc-f58x4 deletion completed in 6.103393916s

• [SLOW TEST:7.373 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:31:13.779: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-vzdxq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0109 23:31:24.048400      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan  9 23:31:24.048: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:31:24.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vzdxq" for this suite.
Jan  9 23:31:30.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:31:30.118: INFO: namespace: e2e-tests-gc-vzdxq, resource: bindings, ignored listing per whitelist
Jan  9 23:31:30.164: INFO: namespace e2e-tests-gc-vzdxq deletion completed in 6.1065719s

• [SLOW TEST:16.384 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:31:30.167: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-d86dj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 23:31:30.370: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b1311a22-1466-11e9-a046-02505600000d" in namespace "e2e-tests-projected-d86dj" to be "success or failure"
Jan  9 23:31:30.378: INFO: Pod "downwardapi-volume-b1311a22-1466-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.172972ms
Jan  9 23:31:32.382: INFO: Pod "downwardapi-volume-b1311a22-1466-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011481553s
Jan  9 23:31:34.388: INFO: Pod "downwardapi-volume-b1311a22-1466-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017528466s
STEP: Saw pod success
Jan  9 23:31:34.388: INFO: Pod "downwardapi-volume-b1311a22-1466-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:31:34.394: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod downwardapi-volume-b1311a22-1466-11e9-a046-02505600000d container client-container: <nil>
STEP: delete the pod
Jan  9 23:31:34.425: INFO: Waiting for pod downwardapi-volume-b1311a22-1466-11e9-a046-02505600000d to disappear
Jan  9 23:31:34.430: INFO: Pod downwardapi-volume-b1311a22-1466-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:31:34.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d86dj" for this suite.
Jan  9 23:31:40.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:31:40.537: INFO: namespace: e2e-tests-projected-d86dj, resource: bindings, ignored listing per whitelist
Jan  9 23:31:40.563: INFO: namespace e2e-tests-projected-d86dj deletion completed in 6.119577796s

• [SLOW TEST:10.396 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:31:40.567: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-dzr5j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Jan  9 23:31:40.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 api-versions'
Jan  9 23:31:40.925: INFO: stderr: ""
Jan  9 23:31:40.925: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps.pivotal.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:31:40.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dzr5j" for this suite.
Jan  9 23:31:46.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:31:46.991: INFO: namespace: e2e-tests-kubectl-dzr5j, resource: bindings, ignored listing per whitelist
Jan  9 23:31:47.028: INFO: namespace e2e-tests-kubectl-dzr5j deletion completed in 6.095014792s

• [SLOW TEST:6.461 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:31:47.030: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-777h5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 23:31:47.245: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bb3f055a-1466-11e9-a046-02505600000d" in namespace "e2e-tests-projected-777h5" to be "success or failure"
Jan  9 23:31:47.253: INFO: Pod "downwardapi-volume-bb3f055a-1466-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.575735ms
Jan  9 23:31:49.257: INFO: Pod "downwardapi-volume-bb3f055a-1466-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011608913s
Jan  9 23:31:51.261: INFO: Pod "downwardapi-volume-bb3f055a-1466-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016488694s
STEP: Saw pod success
Jan  9 23:31:51.261: INFO: Pod "downwardapi-volume-bb3f055a-1466-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:31:51.265: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod downwardapi-volume-bb3f055a-1466-11e9-a046-02505600000d container client-container: <nil>
STEP: delete the pod
Jan  9 23:31:51.289: INFO: Waiting for pod downwardapi-volume-bb3f055a-1466-11e9-a046-02505600000d to disappear
Jan  9 23:31:51.291: INFO: Pod downwardapi-volume-bb3f055a-1466-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:31:51.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-777h5" for this suite.
Jan  9 23:31:57.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:31:57.391: INFO: namespace: e2e-tests-projected-777h5, resource: bindings, ignored listing per whitelist
Jan  9 23:31:57.398: INFO: namespace e2e-tests-projected-777h5 deletion completed in 6.103653721s

• [SLOW TEST:10.369 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:31:57.399: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-98jn4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Jan  9 23:31:57.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 create -f - --namespace=e2e-tests-kubectl-98jn4'
Jan  9 23:31:58.552: INFO: stderr: ""
Jan  9 23:31:58.552: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan  9 23:31:58.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-98jn4'
Jan  9 23:31:58.751: INFO: stderr: ""
Jan  9 23:31:58.751: INFO: stdout: "update-demo-nautilus-k8dls update-demo-nautilus-t8df4 "
Jan  9 23:31:58.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-k8dls -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-98jn4'
Jan  9 23:31:58.873: INFO: stderr: ""
Jan  9 23:31:58.873: INFO: stdout: ""
Jan  9 23:31:58.873: INFO: update-demo-nautilus-k8dls is created but not running
Jan  9 23:32:03.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-98jn4'
Jan  9 23:32:04.006: INFO: stderr: ""
Jan  9 23:32:04.006: INFO: stdout: "update-demo-nautilus-k8dls update-demo-nautilus-t8df4 "
Jan  9 23:32:04.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-k8dls -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-98jn4'
Jan  9 23:32:04.123: INFO: stderr: ""
Jan  9 23:32:04.123: INFO: stdout: "true"
Jan  9 23:32:04.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-k8dls -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-98jn4'
Jan  9 23:32:04.236: INFO: stderr: ""
Jan  9 23:32:04.236: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 23:32:04.236: INFO: validating pod update-demo-nautilus-k8dls
Jan  9 23:32:04.243: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 23:32:04.243: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 23:32:04.243: INFO: update-demo-nautilus-k8dls is verified up and running
Jan  9 23:32:04.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-t8df4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-98jn4'
Jan  9 23:32:04.373: INFO: stderr: ""
Jan  9 23:32:04.373: INFO: stdout: "true"
Jan  9 23:32:04.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-nautilus-t8df4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-98jn4'
Jan  9 23:32:04.479: INFO: stderr: ""
Jan  9 23:32:04.479: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan  9 23:32:04.479: INFO: validating pod update-demo-nautilus-t8df4
Jan  9 23:32:04.486: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan  9 23:32:04.486: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan  9 23:32:04.486: INFO: update-demo-nautilus-t8df4 is verified up and running
STEP: rolling-update to new replication controller
Jan  9 23:32:04.488: INFO: scanned /root for discovery docs: <nil>
Jan  9 23:32:04.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-98jn4'
Jan  9 23:32:30.090: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan  9 23:32:30.090: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan  9 23:32:30.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-98jn4'
Jan  9 23:32:30.203: INFO: stderr: ""
Jan  9 23:32:30.203: INFO: stdout: "update-demo-kitten-dk77m update-demo-kitten-px97q "
Jan  9 23:32:30.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-kitten-dk77m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-98jn4'
Jan  9 23:32:30.305: INFO: stderr: ""
Jan  9 23:32:30.305: INFO: stdout: "true"
Jan  9 23:32:30.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-kitten-dk77m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-98jn4'
Jan  9 23:32:30.411: INFO: stderr: ""
Jan  9 23:32:30.411: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan  9 23:32:30.411: INFO: validating pod update-demo-kitten-dk77m
Jan  9 23:32:30.420: INFO: got data: {
  "image": "kitten.jpg"
}

Jan  9 23:32:30.420: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan  9 23:32:30.420: INFO: update-demo-kitten-dk77m is verified up and running
Jan  9 23:32:30.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-kitten-px97q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-98jn4'
Jan  9 23:32:30.517: INFO: stderr: ""
Jan  9 23:32:30.517: INFO: stdout: "true"
Jan  9 23:32:30.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods update-demo-kitten-px97q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-98jn4'
Jan  9 23:32:30.617: INFO: stderr: ""
Jan  9 23:32:30.617: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan  9 23:32:30.617: INFO: validating pod update-demo-kitten-px97q
Jan  9 23:32:30.624: INFO: got data: {
  "image": "kitten.jpg"
}

Jan  9 23:32:30.625: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan  9 23:32:30.625: INFO: update-demo-kitten-px97q is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:32:30.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-98jn4" for this suite.
Jan  9 23:32:52.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:32:52.703: INFO: namespace: e2e-tests-kubectl-98jn4, resource: bindings, ignored listing per whitelist
Jan  9 23:32:52.739: INFO: namespace e2e-tests-kubectl-98jn4 deletion completed in 22.11167534s

• [SLOW TEST:55.341 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:32:52.742: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qwln7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-e26e14a5-1466-11e9-a046-02505600000d
STEP: Creating a pod to test consume configMaps
Jan  9 23:32:52.985: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e26ecd13-1466-11e9-a046-02505600000d" in namespace "e2e-tests-projected-qwln7" to be "success or failure"
Jan  9 23:32:52.996: INFO: Pod "pod-projected-configmaps-e26ecd13-1466-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.182519ms
Jan  9 23:32:55.000: INFO: Pod "pod-projected-configmaps-e26ecd13-1466-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015165785s
Jan  9 23:32:57.005: INFO: Pod "pod-projected-configmaps-e26ecd13-1466-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019966174s
STEP: Saw pod success
Jan  9 23:32:57.005: INFO: Pod "pod-projected-configmaps-e26ecd13-1466-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:32:57.007: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-projected-configmaps-e26ecd13-1466-11e9-a046-02505600000d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 23:32:57.028: INFO: Waiting for pod pod-projected-configmaps-e26ecd13-1466-11e9-a046-02505600000d to disappear
Jan  9 23:32:57.031: INFO: Pod pod-projected-configmaps-e26ecd13-1466-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:32:57.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qwln7" for this suite.
Jan  9 23:33:03.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:33:03.082: INFO: namespace: e2e-tests-projected-qwln7, resource: bindings, ignored listing per whitelist
Jan  9 23:33:03.138: INFO: namespace e2e-tests-projected-qwln7 deletion completed in 6.103868878s

• [SLOW TEST:10.397 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:33:03.140: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-88v8n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 23:33:21.385: INFO: Container started at 2019-01-09 23:33:05 +0000 UTC, pod became ready at 2019-01-09 23:33:20 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:33:21.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-88v8n" for this suite.
Jan  9 23:33:43.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:33:43.449: INFO: namespace: e2e-tests-container-probe-88v8n, resource: bindings, ignored listing per whitelist
Jan  9 23:33:43.572: INFO: namespace e2e-tests-container-probe-88v8n deletion completed in 22.182864179s

• [SLOW TEST:40.434 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:33:43.579: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-g29bv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Jan  9 23:33:43.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 --namespace=e2e-tests-kubectl-g29bv run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jan  9 23:33:46.124: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jan  9 23:33:46.124: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:33:48.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g29bv" for this suite.
Jan  9 23:33:54.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:33:54.202: INFO: namespace: e2e-tests-kubectl-g29bv, resource: bindings, ignored listing per whitelist
Jan  9 23:33:54.242: INFO: namespace e2e-tests-kubectl-g29bv deletion completed in 6.106733904s

• [SLOW TEST:10.664 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:33:54.246: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-hswmb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan  9 23:33:58.996: INFO: Successfully updated pod "pod-update-0713aaba-1467-11e9-a046-02505600000d"
STEP: verifying the updated pod is in kubernetes
Jan  9 23:33:59.017: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:33:59.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hswmb" for this suite.
Jan  9 23:34:21.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:34:21.064: INFO: namespace: e2e-tests-pods-hswmb, resource: bindings, ignored listing per whitelist
Jan  9 23:34:21.118: INFO: namespace e2e-tests-pods-hswmb deletion completed in 22.094791764s

• [SLOW TEST:26.872 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:34:21.121: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-d7hh5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Jan  9 23:34:21.309: INFO: Waiting up to 5m0s for pod "var-expansion-17161c9e-1467-11e9-a046-02505600000d" in namespace "e2e-tests-var-expansion-d7hh5" to be "success or failure"
Jan  9 23:34:21.312: INFO: Pod "var-expansion-17161c9e-1467-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.68984ms
Jan  9 23:34:23.316: INFO: Pod "var-expansion-17161c9e-1467-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006477508s
Jan  9 23:34:25.322: INFO: Pod "var-expansion-17161c9e-1467-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011851372s
STEP: Saw pod success
Jan  9 23:34:25.322: INFO: Pod "var-expansion-17161c9e-1467-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:34:25.325: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod var-expansion-17161c9e-1467-11e9-a046-02505600000d container dapi-container: <nil>
STEP: delete the pod
Jan  9 23:34:25.349: INFO: Waiting for pod var-expansion-17161c9e-1467-11e9-a046-02505600000d to disappear
Jan  9 23:34:25.355: INFO: Pod var-expansion-17161c9e-1467-11e9-a046-02505600000d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:34:25.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-d7hh5" for this suite.
Jan  9 23:34:31.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:34:31.418: INFO: namespace: e2e-tests-var-expansion-d7hh5, resource: bindings, ignored listing per whitelist
Jan  9 23:34:31.479: INFO: namespace e2e-tests-var-expansion-d7hh5 deletion completed in 6.120628665s

• [SLOW TEST:10.360 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:34:31.483: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-pxb82
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 23:34:31.698: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1d471e24-1467-11e9-a046-02505600000d" in namespace "e2e-tests-downward-api-pxb82" to be "success or failure"
Jan  9 23:34:31.703: INFO: Pod "downwardapi-volume-1d471e24-1467-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.295825ms
Jan  9 23:34:33.708: INFO: Pod "downwardapi-volume-1d471e24-1467-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009764226s
STEP: Saw pod success
Jan  9 23:34:33.708: INFO: Pod "downwardapi-volume-1d471e24-1467-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:34:33.711: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod downwardapi-volume-1d471e24-1467-11e9-a046-02505600000d container client-container: <nil>
STEP: delete the pod
Jan  9 23:34:33.730: INFO: Waiting for pod downwardapi-volume-1d471e24-1467-11e9-a046-02505600000d to disappear
Jan  9 23:34:33.735: INFO: Pod downwardapi-volume-1d471e24-1467-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:34:33.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pxb82" for this suite.
Jan  9 23:34:39.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:34:39.791: INFO: namespace: e2e-tests-downward-api-pxb82, resource: bindings, ignored listing per whitelist
Jan  9 23:34:39.857: INFO: namespace e2e-tests-downward-api-pxb82 deletion completed in 6.116834223s

• [SLOW TEST:8.374 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:34:39.860: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-blzhz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 23:34:40.060: INFO: Waiting up to 5m0s for pod "downwardapi-volume-22433e80-1467-11e9-a046-02505600000d" in namespace "e2e-tests-downward-api-blzhz" to be "success or failure"
Jan  9 23:34:40.063: INFO: Pod "downwardapi-volume-22433e80-1467-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.579961ms
Jan  9 23:34:42.068: INFO: Pod "downwardapi-volume-22433e80-1467-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008648461s
STEP: Saw pod success
Jan  9 23:34:42.069: INFO: Pod "downwardapi-volume-22433e80-1467-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:34:42.073: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod downwardapi-volume-22433e80-1467-11e9-a046-02505600000d container client-container: <nil>
STEP: delete the pod
Jan  9 23:34:42.102: INFO: Waiting for pod downwardapi-volume-22433e80-1467-11e9-a046-02505600000d to disappear
Jan  9 23:34:42.105: INFO: Pod downwardapi-volume-22433e80-1467-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:34:42.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-blzhz" for this suite.
Jan  9 23:34:48.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:34:48.213: INFO: namespace: e2e-tests-downward-api-blzhz, resource: bindings, ignored listing per whitelist
Jan  9 23:34:48.222: INFO: namespace e2e-tests-downward-api-blzhz deletion completed in 6.113544201s

• [SLOW TEST:8.362 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:34:48.227: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-57fqf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan  9 23:34:48.445: INFO: Number of nodes with available pods: 0
Jan  9 23:34:48.445: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:34:49.455: INFO: Number of nodes with available pods: 0
Jan  9 23:34:49.455: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:34:50.455: INFO: Number of nodes with available pods: 0
Jan  9 23:34:50.455: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:34:51.454: INFO: Number of nodes with available pods: 1
Jan  9 23:34:51.454: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:34:52.452: INFO: Number of nodes with available pods: 3
Jan  9 23:34:52.452: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jan  9 23:34:52.480: INFO: Number of nodes with available pods: 2
Jan  9 23:34:52.480: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:34:53.489: INFO: Number of nodes with available pods: 2
Jan  9 23:34:53.489: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:34:54.490: INFO: Number of nodes with available pods: 2
Jan  9 23:34:54.490: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:34:55.488: INFO: Number of nodes with available pods: 2
Jan  9 23:34:55.488: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:34:56.490: INFO: Number of nodes with available pods: 2
Jan  9 23:34:56.490: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:34:57.498: INFO: Number of nodes with available pods: 2
Jan  9 23:34:57.498: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:34:58.489: INFO: Number of nodes with available pods: 2
Jan  9 23:34:58.490: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:34:59.489: INFO: Number of nodes with available pods: 2
Jan  9 23:34:59.489: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:00.490: INFO: Number of nodes with available pods: 2
Jan  9 23:35:00.490: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:01.490: INFO: Number of nodes with available pods: 2
Jan  9 23:35:01.490: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:02.492: INFO: Number of nodes with available pods: 2
Jan  9 23:35:02.492: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:03.490: INFO: Number of nodes with available pods: 2
Jan  9 23:35:03.490: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:04.490: INFO: Number of nodes with available pods: 2
Jan  9 23:35:04.491: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:05.490: INFO: Number of nodes with available pods: 2
Jan  9 23:35:05.491: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:06.490: INFO: Number of nodes with available pods: 2
Jan  9 23:35:06.490: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:07.489: INFO: Number of nodes with available pods: 2
Jan  9 23:35:07.489: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:08.490: INFO: Number of nodes with available pods: 2
Jan  9 23:35:08.490: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:09.489: INFO: Number of nodes with available pods: 2
Jan  9 23:35:09.489: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:10.490: INFO: Number of nodes with available pods: 2
Jan  9 23:35:10.490: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:11.488: INFO: Number of nodes with available pods: 2
Jan  9 23:35:11.488: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:12.489: INFO: Number of nodes with available pods: 2
Jan  9 23:35:12.489: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:13.489: INFO: Number of nodes with available pods: 2
Jan  9 23:35:13.489: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:14.488: INFO: Number of nodes with available pods: 2
Jan  9 23:35:14.488: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:15.490: INFO: Number of nodes with available pods: 2
Jan  9 23:35:15.490: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:16.489: INFO: Number of nodes with available pods: 2
Jan  9 23:35:16.489: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:17.489: INFO: Number of nodes with available pods: 2
Jan  9 23:35:17.489: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:18.488: INFO: Number of nodes with available pods: 2
Jan  9 23:35:18.488: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:19.489: INFO: Number of nodes with available pods: 2
Jan  9 23:35:19.489: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:20.487: INFO: Number of nodes with available pods: 2
Jan  9 23:35:20.487: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:21.488: INFO: Number of nodes with available pods: 2
Jan  9 23:35:21.488: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:22.492: INFO: Number of nodes with available pods: 2
Jan  9 23:35:22.492: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:23.489: INFO: Number of nodes with available pods: 2
Jan  9 23:35:23.489: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:24.493: INFO: Number of nodes with available pods: 2
Jan  9 23:35:24.493: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:25.488: INFO: Number of nodes with available pods: 2
Jan  9 23:35:25.488: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:26.488: INFO: Number of nodes with available pods: 2
Jan  9 23:35:26.488: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:27.488: INFO: Number of nodes with available pods: 2
Jan  9 23:35:27.489: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:28.490: INFO: Number of nodes with available pods: 2
Jan  9 23:35:28.490: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:29.489: INFO: Number of nodes with available pods: 2
Jan  9 23:35:29.489: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:30.489: INFO: Number of nodes with available pods: 2
Jan  9 23:35:30.490: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:31.489: INFO: Number of nodes with available pods: 2
Jan  9 23:35:31.490: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:32.491: INFO: Number of nodes with available pods: 2
Jan  9 23:35:32.491: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:33.490: INFO: Number of nodes with available pods: 2
Jan  9 23:35:33.490: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:34.489: INFO: Number of nodes with available pods: 2
Jan  9 23:35:34.489: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:35.490: INFO: Number of nodes with available pods: 2
Jan  9 23:35:35.490: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:36.497: INFO: Number of nodes with available pods: 2
Jan  9 23:35:36.497: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:37.492: INFO: Number of nodes with available pods: 2
Jan  9 23:35:37.493: INFO: Node 582539c0-37f1-42db-85f2-2655dcef1574 is running more than one daemon pod
Jan  9 23:35:38.489: INFO: Number of nodes with available pods: 3
Jan  9 23:35:38.489: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-57fqf, will wait for the garbage collector to delete the pods
Jan  9 23:35:38.558: INFO: Deleting {extensions DaemonSet} daemon-set took: 12.921156ms
Jan  9 23:35:38.658: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.25866ms
Jan  9 23:36:17.162: INFO: Number of nodes with available pods: 0
Jan  9 23:36:17.162: INFO: Number of running nodes: 0, number of available pods: 0
Jan  9 23:36:17.165: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-57fqf/daemonsets","resourceVersion":"21738"},"items":null}

Jan  9 23:36:17.167: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-57fqf/pods","resourceVersion":"21738"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:36:17.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-57fqf" for this suite.
Jan  9 23:36:23.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:36:23.263: INFO: namespace: e2e-tests-daemonsets-57fqf, resource: bindings, ignored listing per whitelist
Jan  9 23:36:23.291: INFO: namespace e2e-tests-daemonsets-57fqf deletion completed in 6.107255711s

• [SLOW TEST:95.064 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:36:23.292: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-tfbrp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan  9 23:36:23.486: INFO: Waiting up to 5m0s for pod "pod-5fe8679c-1467-11e9-a046-02505600000d" in namespace "e2e-tests-emptydir-tfbrp" to be "success or failure"
Jan  9 23:36:23.499: INFO: Pod "pod-5fe8679c-1467-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.088835ms
Jan  9 23:36:25.507: INFO: Pod "pod-5fe8679c-1467-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020825579s
Jan  9 23:36:27.511: INFO: Pod "pod-5fe8679c-1467-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024673179s
STEP: Saw pod success
Jan  9 23:36:27.511: INFO: Pod "pod-5fe8679c-1467-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:36:27.515: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-5fe8679c-1467-11e9-a046-02505600000d container test-container: <nil>
STEP: delete the pod
Jan  9 23:36:27.538: INFO: Waiting for pod pod-5fe8679c-1467-11e9-a046-02505600000d to disappear
Jan  9 23:36:27.544: INFO: Pod pod-5fe8679c-1467-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:36:27.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tfbrp" for this suite.
Jan  9 23:36:33.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:36:33.662: INFO: namespace: e2e-tests-emptydir-tfbrp, resource: bindings, ignored listing per whitelist
Jan  9 23:36:33.685: INFO: namespace e2e-tests-emptydir-tfbrp deletion completed in 6.137732656s

• [SLOW TEST:10.394 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:36:33.687: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-vjd48
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0109 23:37:03.932634      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan  9 23:37:03.933: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:37:03.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vjd48" for this suite.
Jan  9 23:37:09.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:37:10.029: INFO: namespace: e2e-tests-gc-vjd48, resource: bindings, ignored listing per whitelist
Jan  9 23:37:10.057: INFO: namespace e2e-tests-gc-vjd48 deletion completed in 6.120162384s

• [SLOW TEST:36.371 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:37:10.061: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-jcp52
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  9 23:37:10.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-jcp52'
Jan  9 23:37:10.424: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan  9 23:37:10.424: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jan  9 23:37:12.442: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-h2cp9]
Jan  9 23:37:12.442: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-h2cp9" in namespace "e2e-tests-kubectl-jcp52" to be "running and ready"
Jan  9 23:37:12.445: INFO: Pod "e2e-test-nginx-rc-h2cp9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.359898ms
Jan  9 23:37:14.449: INFO: Pod "e2e-test-nginx-rc-h2cp9": Phase="Running", Reason="", readiness=true. Elapsed: 2.006865651s
Jan  9 23:37:14.450: INFO: Pod "e2e-test-nginx-rc-h2cp9" satisfied condition "running and ready"
Jan  9 23:37:14.450: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-h2cp9]
Jan  9 23:37:14.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-jcp52'
Jan  9 23:37:14.596: INFO: stderr: ""
Jan  9 23:37:14.596: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Jan  9 23:37:14.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-jcp52'
Jan  9 23:37:14.724: INFO: stderr: ""
Jan  9 23:37:14.724: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:37:14.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jcp52" for this suite.
Jan  9 23:37:36.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:37:36.819: INFO: namespace: e2e-tests-kubectl-jcp52, resource: bindings, ignored listing per whitelist
Jan  9 23:37:36.842: INFO: namespace e2e-tests-kubectl-jcp52 deletion completed in 22.106913198s

• [SLOW TEST:26.782 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:37:36.845: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-pb7sd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  9 23:37:37.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-pb7sd'
Jan  9 23:37:37.178: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan  9 23:37:37.178: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Jan  9 23:37:37.197: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Jan  9 23:37:37.216: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Jan  9 23:37:37.227: INFO: scanned /root for discovery docs: <nil>
Jan  9 23:37:37.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-pb7sd'
Jan  9 23:37:53.053: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan  9 23:37:53.053: INFO: stdout: "Created e2e-test-nginx-rc-1a3de2e74d4320e2cdbb055efacdd7da\nScaling up e2e-test-nginx-rc-1a3de2e74d4320e2cdbb055efacdd7da from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-1a3de2e74d4320e2cdbb055efacdd7da up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-1a3de2e74d4320e2cdbb055efacdd7da to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jan  9 23:37:53.053: INFO: stdout: "Created e2e-test-nginx-rc-1a3de2e74d4320e2cdbb055efacdd7da\nScaling up e2e-test-nginx-rc-1a3de2e74d4320e2cdbb055efacdd7da from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-1a3de2e74d4320e2cdbb055efacdd7da up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-1a3de2e74d4320e2cdbb055efacdd7da to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jan  9 23:37:53.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-pb7sd'
Jan  9 23:37:53.285: INFO: stderr: ""
Jan  9 23:37:53.285: INFO: stdout: "e2e-test-nginx-rc-1a3de2e74d4320e2cdbb055efacdd7da-rdvs7 e2e-test-nginx-rc-hf68w "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Jan  9 23:37:58.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-pb7sd'
Jan  9 23:37:58.391: INFO: stderr: ""
Jan  9 23:37:58.391: INFO: stdout: "e2e-test-nginx-rc-1a3de2e74d4320e2cdbb055efacdd7da-rdvs7 "
Jan  9 23:37:58.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods e2e-test-nginx-rc-1a3de2e74d4320e2cdbb055efacdd7da-rdvs7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pb7sd'
Jan  9 23:37:58.480: INFO: stderr: ""
Jan  9 23:37:58.480: INFO: stdout: "true"
Jan  9 23:37:58.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pods e2e-test-nginx-rc-1a3de2e74d4320e2cdbb055efacdd7da-rdvs7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pb7sd'
Jan  9 23:37:58.588: INFO: stderr: ""
Jan  9 23:37:58.588: INFO: stdout: "nginx:1.14-alpine"
Jan  9 23:37:58.588: INFO: e2e-test-nginx-rc-1a3de2e74d4320e2cdbb055efacdd7da-rdvs7 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Jan  9 23:37:58.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-pb7sd'
Jan  9 23:37:58.682: INFO: stderr: ""
Jan  9 23:37:58.682: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:37:58.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pb7sd" for this suite.
Jan  9 23:38:20.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:38:20.766: INFO: namespace: e2e-tests-kubectl-pb7sd, resource: bindings, ignored listing per whitelist
Jan  9 23:38:20.783: INFO: namespace e2e-tests-kubectl-pb7sd deletion completed in 22.094758287s

• [SLOW TEST:43.938 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:38:20.785: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-g2rkz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-a5f152c6-1467-11e9-a046-02505600000d
Jan  9 23:38:20.986: INFO: Pod name my-hostname-basic-a5f152c6-1467-11e9-a046-02505600000d: Found 0 pods out of 1
Jan  9 23:38:25.991: INFO: Pod name my-hostname-basic-a5f152c6-1467-11e9-a046-02505600000d: Found 1 pods out of 1
Jan  9 23:38:25.991: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-a5f152c6-1467-11e9-a046-02505600000d" are running
Jan  9 23:38:25.994: INFO: Pod "my-hostname-basic-a5f152c6-1467-11e9-a046-02505600000d-95jxf" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-09 23:38:21 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-09 23:38:22 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-09 23:38:22 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-09 23:38:21 +0000 UTC Reason: Message:}])
Jan  9 23:38:25.994: INFO: Trying to dial the pod
Jan  9 23:38:31.007: INFO: Controller my-hostname-basic-a5f152c6-1467-11e9-a046-02505600000d: Got expected result from replica 1 [my-hostname-basic-a5f152c6-1467-11e9-a046-02505600000d-95jxf]: "my-hostname-basic-a5f152c6-1467-11e9-a046-02505600000d-95jxf", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:38:31.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-g2rkz" for this suite.
Jan  9 23:38:37.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:38:37.064: INFO: namespace: e2e-tests-replication-controller-g2rkz, resource: bindings, ignored listing per whitelist
Jan  9 23:38:37.111: INFO: namespace e2e-tests-replication-controller-g2rkz deletion completed in 6.10062959s

• [SLOW TEST:16.326 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:38:37.112: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-94bb6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Jan  9 23:38:37.831: INFO: created pod pod-service-account-defaultsa
Jan  9 23:38:37.831: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jan  9 23:38:37.835: INFO: created pod pod-service-account-mountsa
Jan  9 23:38:37.835: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jan  9 23:38:37.841: INFO: created pod pod-service-account-nomountsa
Jan  9 23:38:37.841: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jan  9 23:38:37.863: INFO: created pod pod-service-account-defaultsa-mountspec
Jan  9 23:38:37.864: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jan  9 23:38:37.872: INFO: created pod pod-service-account-mountsa-mountspec
Jan  9 23:38:37.872: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jan  9 23:38:37.883: INFO: created pod pod-service-account-nomountsa-mountspec
Jan  9 23:38:37.883: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jan  9 23:38:37.889: INFO: created pod pod-service-account-defaultsa-nomountspec
Jan  9 23:38:37.889: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jan  9 23:38:37.896: INFO: created pod pod-service-account-mountsa-nomountspec
Jan  9 23:38:37.896: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jan  9 23:38:37.918: INFO: created pod pod-service-account-nomountsa-nomountspec
Jan  9 23:38:37.919: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:38:37.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-94bb6" for this suite.
Jan  9 23:38:44.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:38:44.139: INFO: namespace: e2e-tests-svcaccounts-94bb6, resource: bindings, ignored listing per whitelist
Jan  9 23:38:44.225: INFO: namespace e2e-tests-svcaccounts-94bb6 deletion completed in 6.253621676s

• [SLOW TEST:7.114 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:38:44.228: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-r5tgh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-b3f7a541-1467-11e9-a046-02505600000d
STEP: Creating a pod to test consume secrets
Jan  9 23:38:44.527: INFO: Waiting up to 5m0s for pod "pod-secrets-b3f888c4-1467-11e9-a046-02505600000d" in namespace "e2e-tests-secrets-r5tgh" to be "success or failure"
Jan  9 23:38:44.537: INFO: Pod "pod-secrets-b3f888c4-1467-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.968728ms
Jan  9 23:38:46.541: INFO: Pod "pod-secrets-b3f888c4-1467-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013617244s
Jan  9 23:38:48.547: INFO: Pod "pod-secrets-b3f888c4-1467-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019379788s
STEP: Saw pod success
Jan  9 23:38:48.547: INFO: Pod "pod-secrets-b3f888c4-1467-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:38:48.550: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-secrets-b3f888c4-1467-11e9-a046-02505600000d container secret-env-test: <nil>
STEP: delete the pod
Jan  9 23:38:48.587: INFO: Waiting for pod pod-secrets-b3f888c4-1467-11e9-a046-02505600000d to disappear
Jan  9 23:38:48.591: INFO: Pod pod-secrets-b3f888c4-1467-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:38:48.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-r5tgh" for this suite.
Jan  9 23:38:54.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:38:54.656: INFO: namespace: e2e-tests-secrets-r5tgh, resource: bindings, ignored listing per whitelist
Jan  9 23:38:54.695: INFO: namespace e2e-tests-secrets-r5tgh deletion completed in 6.087974963s

• [SLOW TEST:10.468 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:38:54.697: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-dfpgv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jan  9 23:38:58.915: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-ba27e267-1467-11e9-a046-02505600000d,GenerateName:,Namespace:e2e-tests-events-dfpgv,SelfLink:/api/v1/namespaces/e2e-tests-events-dfpgv/pods/send-events-ba27e267-1467-11e9-a046-02505600000d,UID:ba289865-1467-11e9-9de1-005056902d46,ResourceVersion:22404,Generation:0,CreationTimestamp:2019-01-09 23:38:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 887387910,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5xr2r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5xr2r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-5xr2r true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:362e6945-cc10-4a7c-ad11-8cf4815006e1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4222984b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4222984d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:38:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:38:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:38:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-09 23:38:54 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.4,PodIP:40.0.6.2,StartTime:2019-01-09 23:38:54 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-01-09 23:38:56 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://cb3ee92041f6773fbef5ac2e445c6d05047f85aeca64cf9a99e4a55d2c5fe501}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jan  9 23:39:00.920: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jan  9 23:39:02.924: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:39:02.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-dfpgv" for this suite.
Jan  9 23:39:40.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:39:40.986: INFO: namespace: e2e-tests-events-dfpgv, resource: bindings, ignored listing per whitelist
Jan  9 23:39:41.055: INFO: namespace e2e-tests-events-dfpgv deletion completed in 38.111167492s

• [SLOW TEST:46.358 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:39:41.055: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-67847
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-d5cb1c7e-1467-11e9-a046-02505600000d
STEP: Creating configMap with name cm-test-opt-upd-d5cb1cbe-1467-11e9-a046-02505600000d
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d5cb1c7e-1467-11e9-a046-02505600000d
STEP: Updating configmap cm-test-opt-upd-d5cb1cbe-1467-11e9-a046-02505600000d
STEP: Creating configMap with name cm-test-opt-create-d5cb1cd3-1467-11e9-a046-02505600000d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:39:45.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-67847" for this suite.
Jan  9 23:40:07.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:40:07.490: INFO: namespace: e2e-tests-configmap-67847, resource: bindings, ignored listing per whitelist
Jan  9 23:40:07.537: INFO: namespace e2e-tests-configmap-67847 deletion completed in 22.129300472s

• [SLOW TEST:26.482 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:40:07.537: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-sxv9q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-sxv9q
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-sxv9q
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-sxv9q
Jan  9 23:40:07.797: INFO: Found 0 stateful pods, waiting for 1
Jan  9 23:40:17.802: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jan  9 23:40:17.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-sxv9q ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 23:40:18.023: INFO: stderr: ""
Jan  9 23:40:18.023: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 23:40:18.023: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  9 23:40:18.027: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan  9 23:40:28.031: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan  9 23:40:28.031: INFO: Waiting for statefulset status.replicas updated to 0
Jan  9 23:40:28.043: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999631s
Jan  9 23:40:29.048: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995679967s
Jan  9 23:40:30.051: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.99099173s
Jan  9 23:40:31.055: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.98760922s
Jan  9 23:40:32.060: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.983608087s
Jan  9 23:40:33.064: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.978491269s
Jan  9 23:40:34.068: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.974074773s
Jan  9 23:40:35.075: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.970629045s
Jan  9 23:40:36.079: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.964017049s
Jan  9 23:40:37.084: INFO: Verifying statefulset ss doesn't scale past 1 for another 959.196482ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-sxv9q
Jan  9 23:40:38.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-sxv9q ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:40:38.283: INFO: stderr: ""
Jan  9 23:40:38.283: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  9 23:40:38.283: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  9 23:40:38.288: INFO: Found 1 stateful pods, waiting for 3
Jan  9 23:40:48.293: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan  9 23:40:48.293: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan  9 23:40:48.293: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jan  9 23:40:48.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-sxv9q ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 23:40:48.514: INFO: stderr: ""
Jan  9 23:40:48.514: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 23:40:48.514: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  9 23:40:48.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-sxv9q ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 23:40:48.770: INFO: stderr: ""
Jan  9 23:40:48.770: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 23:40:48.770: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  9 23:40:48.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-sxv9q ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan  9 23:40:48.977: INFO: stderr: ""
Jan  9 23:40:48.977: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan  9 23:40:48.977: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan  9 23:40:48.977: INFO: Waiting for statefulset status.replicas updated to 0
Jan  9 23:40:48.981: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jan  9 23:40:58.989: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan  9 23:40:58.989: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan  9 23:40:58.989: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan  9 23:40:59.007: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999571s
Jan  9 23:41:00.014: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992503706s
Jan  9 23:41:01.018: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985506935s
Jan  9 23:41:02.023: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981000415s
Jan  9 23:41:03.030: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.97650344s
Jan  9 23:41:04.033: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.96990116s
Jan  9 23:41:05.038: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.965869739s
Jan  9 23:41:06.043: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.961277293s
Jan  9 23:41:07.047: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.956574641s
Jan  9 23:41:08.052: INFO: Verifying statefulset ss doesn't scale past 3 for another 951.994743ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-sxv9q
Jan  9 23:41:09.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-sxv9q ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:41:09.277: INFO: stderr: ""
Jan  9 23:41:09.277: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  9 23:41:09.277: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  9 23:41:09.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-sxv9q ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:41:09.476: INFO: stderr: ""
Jan  9 23:41:09.476: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  9 23:41:09.476: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  9 23:41:09.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 exec --namespace=e2e-tests-statefulset-sxv9q ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan  9 23:41:09.730: INFO: stderr: ""
Jan  9 23:41:09.730: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan  9 23:41:09.730: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan  9 23:41:09.730: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan  9 23:41:39.748: INFO: Deleting all statefulset in ns e2e-tests-statefulset-sxv9q
Jan  9 23:41:39.751: INFO: Scaling statefulset ss to 0
Jan  9 23:41:39.759: INFO: Waiting for statefulset status.replicas updated to 0
Jan  9 23:41:39.762: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:41:39.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-sxv9q" for this suite.
Jan  9 23:41:45.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:41:45.834: INFO: namespace: e2e-tests-statefulset-sxv9q, resource: bindings, ignored listing per whitelist
Jan  9 23:41:46.005: INFO: namespace e2e-tests-statefulset-sxv9q deletion completed in 6.21419533s

• [SLOW TEST:98.468 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:41:46.009: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qxfh8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-204ce81d-1468-11e9-a046-02505600000d
STEP: Creating a pod to test consume configMaps
Jan  9 23:41:46.269: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-204dafb0-1468-11e9-a046-02505600000d" in namespace "e2e-tests-projected-qxfh8" to be "success or failure"
Jan  9 23:41:46.282: INFO: Pod "pod-projected-configmaps-204dafb0-1468-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.072036ms
Jan  9 23:41:48.286: INFO: Pod "pod-projected-configmaps-204dafb0-1468-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016959021s
Jan  9 23:41:50.290: INFO: Pod "pod-projected-configmaps-204dafb0-1468-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021134902s
STEP: Saw pod success
Jan  9 23:41:50.290: INFO: Pod "pod-projected-configmaps-204dafb0-1468-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:41:50.293: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-projected-configmaps-204dafb0-1468-11e9-a046-02505600000d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 23:41:50.324: INFO: Waiting for pod pod-projected-configmaps-204dafb0-1468-11e9-a046-02505600000d to disappear
Jan  9 23:41:50.326: INFO: Pod pod-projected-configmaps-204dafb0-1468-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:41:50.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qxfh8" for this suite.
Jan  9 23:41:56.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:41:56.430: INFO: namespace: e2e-tests-projected-qxfh8, resource: bindings, ignored listing per whitelist
Jan  9 23:41:56.450: INFO: namespace e2e-tests-projected-qxfh8 deletion completed in 6.119363769s

• [SLOW TEST:10.441 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:41:56.451: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-px52z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan  9 23:41:56.642: INFO: Waiting up to 5m0s for pod "downward-api-267c1695-1468-11e9-a046-02505600000d" in namespace "e2e-tests-downward-api-px52z" to be "success or failure"
Jan  9 23:41:56.676: INFO: Pod "downward-api-267c1695-1468-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 34.231227ms
Jan  9 23:41:58.680: INFO: Pod "downward-api-267c1695-1468-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03806873s
Jan  9 23:42:00.683: INFO: Pod "downward-api-267c1695-1468-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041481106s
STEP: Saw pod success
Jan  9 23:42:00.683: INFO: Pod "downward-api-267c1695-1468-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:42:00.686: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod downward-api-267c1695-1468-11e9-a046-02505600000d container dapi-container: <nil>
STEP: delete the pod
Jan  9 23:42:00.714: INFO: Waiting for pod downward-api-267c1695-1468-11e9-a046-02505600000d to disappear
Jan  9 23:42:00.716: INFO: Pod downward-api-267c1695-1468-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:42:00.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-px52z" for this suite.
Jan  9 23:42:06.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:42:06.779: INFO: namespace: e2e-tests-downward-api-px52z, resource: bindings, ignored listing per whitelist
Jan  9 23:42:06.821: INFO: namespace e2e-tests-downward-api-px52z deletion completed in 6.10212741s

• [SLOW TEST:10.370 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:42:06.824: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-lnfqw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0109 23:42:17.148765      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan  9 23:42:17.148: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:42:17.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-lnfqw" for this suite.
Jan  9 23:42:23.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:42:23.181: INFO: namespace: e2e-tests-gc-lnfqw, resource: bindings, ignored listing per whitelist
Jan  9 23:42:23.272: INFO: namespace e2e-tests-gc-lnfqw deletion completed in 6.119921981s

• [SLOW TEST:16.449 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:42:23.274: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-bnd64
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-bnd64
Jan  9 23:42:29.482: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-bnd64
STEP: checking the pod's current state and verifying that restartCount is present
Jan  9 23:42:29.486: INFO: Initial restart count of pod liveness-http is 0
Jan  9 23:42:41.512: INFO: Restart count of pod e2e-tests-container-probe-bnd64/liveness-http is now 1 (12.025908779s elapsed)
Jan  9 23:43:01.561: INFO: Restart count of pod e2e-tests-container-probe-bnd64/liveness-http is now 2 (32.074772783s elapsed)
Jan  9 23:43:21.598: INFO: Restart count of pod e2e-tests-container-probe-bnd64/liveness-http is now 3 (52.11199242s elapsed)
Jan  9 23:43:41.642: INFO: Restart count of pod e2e-tests-container-probe-bnd64/liveness-http is now 4 (1m12.155497539s elapsed)
Jan  9 23:44:51.784: INFO: Restart count of pod e2e-tests-container-probe-bnd64/liveness-http is now 5 (2m22.298162692s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:44:51.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-bnd64" for this suite.
Jan  9 23:44:57.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:44:57.902: INFO: namespace: e2e-tests-container-probe-bnd64, resource: bindings, ignored listing per whitelist
Jan  9 23:44:57.927: INFO: namespace e2e-tests-container-probe-bnd64 deletion completed in 6.110527005s

• [SLOW TEST:154.653 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:44:57.928: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-4x57v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Jan  9 23:44:58.130: INFO: Waiting up to 5m0s for pod "client-containers-92a908cc-1468-11e9-a046-02505600000d" in namespace "e2e-tests-containers-4x57v" to be "success or failure"
Jan  9 23:44:58.135: INFO: Pod "client-containers-92a908cc-1468-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.911094ms
Jan  9 23:45:00.140: INFO: Pod "client-containers-92a908cc-1468-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009535251s
Jan  9 23:45:02.144: INFO: Pod "client-containers-92a908cc-1468-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0139302s
STEP: Saw pod success
Jan  9 23:45:02.145: INFO: Pod "client-containers-92a908cc-1468-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:45:02.149: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod client-containers-92a908cc-1468-11e9-a046-02505600000d container test-container: <nil>
STEP: delete the pod
Jan  9 23:45:02.180: INFO: Waiting for pod client-containers-92a908cc-1468-11e9-a046-02505600000d to disappear
Jan  9 23:45:02.183: INFO: Pod client-containers-92a908cc-1468-11e9-a046-02505600000d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:45:02.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-4x57v" for this suite.
Jan  9 23:45:08.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:45:08.377: INFO: namespace: e2e-tests-containers-4x57v, resource: bindings, ignored listing per whitelist
Jan  9 23:45:08.386: INFO: namespace e2e-tests-containers-4x57v deletion completed in 6.200163902s

• [SLOW TEST:10.459 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:45:08.387: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-8smxs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 23:45:08.618: INFO: (0) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.83429ms)
Jan  9 23:45:08.623: INFO: (1) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.540435ms)
Jan  9 23:45:08.627: INFO: (2) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.494655ms)
Jan  9 23:45:08.631: INFO: (3) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.405292ms)
Jan  9 23:45:08.635: INFO: (4) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.979515ms)
Jan  9 23:45:08.638: INFO: (5) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.230149ms)
Jan  9 23:45:08.642: INFO: (6) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.417941ms)
Jan  9 23:45:08.645: INFO: (7) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.120956ms)
Jan  9 23:45:08.648: INFO: (8) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.280969ms)
Jan  9 23:45:08.654: INFO: (9) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.37297ms)
Jan  9 23:45:08.659: INFO: (10) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.115611ms)
Jan  9 23:45:08.663: INFO: (11) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.08386ms)
Jan  9 23:45:08.667: INFO: (12) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.470754ms)
Jan  9 23:45:08.670: INFO: (13) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.573534ms)
Jan  9 23:45:08.674: INFO: (14) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.316042ms)
Jan  9 23:45:08.677: INFO: (15) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.253452ms)
Jan  9 23:45:08.680: INFO: (16) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.838571ms)
Jan  9 23:45:08.683: INFO: (17) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.216869ms)
Jan  9 23:45:08.688: INFO: (18) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.698051ms)
Jan  9 23:45:08.692: INFO: (19) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.618325ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:45:08.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-8smxs" for this suite.
Jan  9 23:45:14.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:45:14.779: INFO: namespace: e2e-tests-proxy-8smxs, resource: bindings, ignored listing per whitelist
Jan  9 23:45:14.798: INFO: namespace e2e-tests-proxy-8smxs deletion completed in 6.096169665s

• [SLOW TEST:6.411 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:45:14.800: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-w6t89
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jan  9 23:45:15.019: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-w6t89,SelfLink:/api/v1/namespaces/e2e-tests-watch-w6t89/configmaps/e2e-watch-test-label-changed,UID:9cb87f34-1468-11e9-9de1-005056902d46,ResourceVersion:23567,Generation:0,CreationTimestamp:2019-01-09 23:45:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan  9 23:45:15.020: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-w6t89,SelfLink:/api/v1/namespaces/e2e-tests-watch-w6t89/configmaps/e2e-watch-test-label-changed,UID:9cb87f34-1468-11e9-9de1-005056902d46,ResourceVersion:23568,Generation:0,CreationTimestamp:2019-01-09 23:45:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan  9 23:45:15.020: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-w6t89,SelfLink:/api/v1/namespaces/e2e-tests-watch-w6t89/configmaps/e2e-watch-test-label-changed,UID:9cb87f34-1468-11e9-9de1-005056902d46,ResourceVersion:23569,Generation:0,CreationTimestamp:2019-01-09 23:45:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jan  9 23:45:25.044: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-w6t89,SelfLink:/api/v1/namespaces/e2e-tests-watch-w6t89/configmaps/e2e-watch-test-label-changed,UID:9cb87f34-1468-11e9-9de1-005056902d46,ResourceVersion:23585,Generation:0,CreationTimestamp:2019-01-09 23:45:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan  9 23:45:25.045: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-w6t89,SelfLink:/api/v1/namespaces/e2e-tests-watch-w6t89/configmaps/e2e-watch-test-label-changed,UID:9cb87f34-1468-11e9-9de1-005056902d46,ResourceVersion:23586,Generation:0,CreationTimestamp:2019-01-09 23:45:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jan  9 23:45:25.045: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-w6t89,SelfLink:/api/v1/namespaces/e2e-tests-watch-w6t89/configmaps/e2e-watch-test-label-changed,UID:9cb87f34-1468-11e9-9de1-005056902d46,ResourceVersion:23587,Generation:0,CreationTimestamp:2019-01-09 23:45:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:45:25.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-w6t89" for this suite.
Jan  9 23:45:31.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:45:31.086: INFO: namespace: e2e-tests-watch-w6t89, resource: bindings, ignored listing per whitelist
Jan  9 23:45:31.176: INFO: namespace e2e-tests-watch-w6t89 deletion completed in 6.126684107s

• [SLOW TEST:16.377 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:45:31.177: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-2l55s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-r92c
STEP: Creating a pod to test atomic-volume-subpath
Jan  9 23:45:31.392: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-r92c" in namespace "e2e-tests-subpath-2l55s" to be "success or failure"
Jan  9 23:45:31.407: INFO: Pod "pod-subpath-test-configmap-r92c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.639707ms
Jan  9 23:45:33.411: INFO: Pod "pod-subpath-test-configmap-r92c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018622815s
Jan  9 23:45:35.415: INFO: Pod "pod-subpath-test-configmap-r92c": Phase="Running", Reason="", readiness=false. Elapsed: 4.022317444s
Jan  9 23:45:37.421: INFO: Pod "pod-subpath-test-configmap-r92c": Phase="Running", Reason="", readiness=false. Elapsed: 6.028165441s
Jan  9 23:45:39.425: INFO: Pod "pod-subpath-test-configmap-r92c": Phase="Running", Reason="", readiness=false. Elapsed: 8.032239604s
Jan  9 23:45:41.431: INFO: Pod "pod-subpath-test-configmap-r92c": Phase="Running", Reason="", readiness=false. Elapsed: 10.038700359s
Jan  9 23:45:43.436: INFO: Pod "pod-subpath-test-configmap-r92c": Phase="Running", Reason="", readiness=false. Elapsed: 12.04401627s
Jan  9 23:45:45.443: INFO: Pod "pod-subpath-test-configmap-r92c": Phase="Running", Reason="", readiness=false. Elapsed: 14.050349043s
Jan  9 23:45:47.447: INFO: Pod "pod-subpath-test-configmap-r92c": Phase="Running", Reason="", readiness=false. Elapsed: 16.054606172s
Jan  9 23:45:49.451: INFO: Pod "pod-subpath-test-configmap-r92c": Phase="Running", Reason="", readiness=false. Elapsed: 18.058877279s
Jan  9 23:45:51.456: INFO: Pod "pod-subpath-test-configmap-r92c": Phase="Running", Reason="", readiness=false. Elapsed: 20.063692225s
Jan  9 23:45:53.461: INFO: Pod "pod-subpath-test-configmap-r92c": Phase="Running", Reason="", readiness=false. Elapsed: 22.068801749s
Jan  9 23:45:55.466: INFO: Pod "pod-subpath-test-configmap-r92c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.073025544s
STEP: Saw pod success
Jan  9 23:45:55.466: INFO: Pod "pod-subpath-test-configmap-r92c" satisfied condition "success or failure"
Jan  9 23:45:55.469: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-subpath-test-configmap-r92c container test-container-subpath-configmap-r92c: <nil>
STEP: delete the pod
Jan  9 23:45:55.493: INFO: Waiting for pod pod-subpath-test-configmap-r92c to disappear
Jan  9 23:45:55.495: INFO: Pod pod-subpath-test-configmap-r92c no longer exists
STEP: Deleting pod pod-subpath-test-configmap-r92c
Jan  9 23:45:55.495: INFO: Deleting pod "pod-subpath-test-configmap-r92c" in namespace "e2e-tests-subpath-2l55s"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:45:55.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-2l55s" for this suite.
Jan  9 23:46:01.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:46:01.555: INFO: namespace: e2e-tests-subpath-2l55s, resource: bindings, ignored listing per whitelist
Jan  9 23:46:01.613: INFO: namespace e2e-tests-subpath-2l55s deletion completed in 6.110941705s

• [SLOW TEST:30.437 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:46:01.618: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-hgmhm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 23:46:01.824: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Jan  9 23:46:01.830: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hgmhm/daemonsets","resourceVersion":"23692"},"items":null}

Jan  9 23:46:01.837: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hgmhm/pods","resourceVersion":"23692"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:46:01.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hgmhm" for this suite.
Jan  9 23:46:07.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:46:07.906: INFO: namespace: e2e-tests-daemonsets-hgmhm, resource: bindings, ignored listing per whitelist
Jan  9 23:46:07.948: INFO: namespace e2e-tests-daemonsets-hgmhm deletion completed in 6.093550318s

S [SKIPPING] [6.330 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Jan  9 23:46:01.824: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:46:07.949: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-2zz2h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan  9 23:46:12.688: INFO: Successfully updated pod "annotationupdatebc644756-1468-11e9-a046-02505600000d"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:46:14.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2zz2h" for this suite.
Jan  9 23:46:36.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:46:36.880: INFO: namespace: e2e-tests-downward-api-2zz2h, resource: bindings, ignored listing per whitelist
Jan  9 23:46:36.900: INFO: namespace e2e-tests-downward-api-2zz2h deletion completed in 22.12017072s

• [SLOW TEST:28.950 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:46:36.902: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-tcslh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-cda6fb68-1468-11e9-a046-02505600000d
STEP: Creating a pod to test consume configMaps
Jan  9 23:46:37.124: INFO: Waiting up to 5m0s for pod "pod-configmaps-cda78c07-1468-11e9-a046-02505600000d" in namespace "e2e-tests-configmap-tcslh" to be "success or failure"
Jan  9 23:46:37.146: INFO: Pod "pod-configmaps-cda78c07-1468-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 21.706101ms
Jan  9 23:46:39.150: INFO: Pod "pod-configmaps-cda78c07-1468-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025347249s
Jan  9 23:46:41.154: INFO: Pod "pod-configmaps-cda78c07-1468-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029746394s
STEP: Saw pod success
Jan  9 23:46:41.154: INFO: Pod "pod-configmaps-cda78c07-1468-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:46:41.157: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-configmaps-cda78c07-1468-11e9-a046-02505600000d container configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 23:46:41.184: INFO: Waiting for pod pod-configmaps-cda78c07-1468-11e9-a046-02505600000d to disappear
Jan  9 23:46:41.191: INFO: Pod pod-configmaps-cda78c07-1468-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:46:41.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tcslh" for this suite.
Jan  9 23:46:47.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:46:47.264: INFO: namespace: e2e-tests-configmap-tcslh, resource: bindings, ignored listing per whitelist
Jan  9 23:46:47.335: INFO: namespace e2e-tests-configmap-tcslh deletion completed in 6.139093102s

• [SLOW TEST:10.433 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:46:47.335: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-k98sq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-k98sq
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-k98sq
STEP: Deleting pre-stop pod
Jan  9 23:47:04.592: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:47:04.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-k98sq" for this suite.
Jan  9 23:47:42.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:47:42.700: INFO: namespace: e2e-tests-prestop-k98sq, resource: bindings, ignored listing per whitelist
Jan  9 23:47:42.711: INFO: namespace e2e-tests-prestop-k98sq deletion completed in 38.098881313s

• [SLOW TEST:55.376 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:47:42.712: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-dh82l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-f4e0da98-1468-11e9-a046-02505600000d
STEP: Creating secret with name s-test-opt-upd-f4e0dc22-1468-11e9-a046-02505600000d
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-f4e0da98-1468-11e9-a046-02505600000d
STEP: Updating secret s-test-opt-upd-f4e0dc22-1468-11e9-a046-02505600000d
STEP: Creating secret with name s-test-opt-create-f4e0dc3c-1468-11e9-a046-02505600000d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:47:51.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dh82l" for this suite.
Jan  9 23:48:13.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:48:13.072: INFO: namespace: e2e-tests-projected-dh82l, resource: bindings, ignored listing per whitelist
Jan  9 23:48:13.121: INFO: namespace e2e-tests-projected-dh82l deletion completed in 22.086984308s

• [SLOW TEST:30.410 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:48:13.124: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-vtdfw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jan  9 23:48:13.820: INFO: Waiting up to 5m0s for pod "pod-service-account-074c96e4-1469-11e9-a046-02505600000d-flc6v" in namespace "e2e-tests-svcaccounts-vtdfw" to be "success or failure"
Jan  9 23:48:13.827: INFO: Pod "pod-service-account-074c96e4-1469-11e9-a046-02505600000d-flc6v": Phase="Pending", Reason="", readiness=false. Elapsed: 6.962015ms
Jan  9 23:48:15.844: INFO: Pod "pod-service-account-074c96e4-1469-11e9-a046-02505600000d-flc6v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023488336s
Jan  9 23:48:17.847: INFO: Pod "pod-service-account-074c96e4-1469-11e9-a046-02505600000d-flc6v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02672917s
STEP: Saw pod success
Jan  9 23:48:17.847: INFO: Pod "pod-service-account-074c96e4-1469-11e9-a046-02505600000d-flc6v" satisfied condition "success or failure"
Jan  9 23:48:17.849: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-service-account-074c96e4-1469-11e9-a046-02505600000d-flc6v container token-test: <nil>
STEP: delete the pod
Jan  9 23:48:17.877: INFO: Waiting for pod pod-service-account-074c96e4-1469-11e9-a046-02505600000d-flc6v to disappear
Jan  9 23:48:17.879: INFO: Pod pod-service-account-074c96e4-1469-11e9-a046-02505600000d-flc6v no longer exists
STEP: Creating a pod to test consume service account root CA
Jan  9 23:48:17.882: INFO: Waiting up to 5m0s for pod "pod-service-account-074c96e4-1469-11e9-a046-02505600000d-sn7n6" in namespace "e2e-tests-svcaccounts-vtdfw" to be "success or failure"
Jan  9 23:48:17.889: INFO: Pod "pod-service-account-074c96e4-1469-11e9-a046-02505600000d-sn7n6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.512324ms
Jan  9 23:48:19.895: INFO: Pod "pod-service-account-074c96e4-1469-11e9-a046-02505600000d-sn7n6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012297927s
Jan  9 23:48:21.898: INFO: Pod "pod-service-account-074c96e4-1469-11e9-a046-02505600000d-sn7n6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015483426s
STEP: Saw pod success
Jan  9 23:48:21.898: INFO: Pod "pod-service-account-074c96e4-1469-11e9-a046-02505600000d-sn7n6" satisfied condition "success or failure"
Jan  9 23:48:21.901: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-service-account-074c96e4-1469-11e9-a046-02505600000d-sn7n6 container root-ca-test: <nil>
STEP: delete the pod
Jan  9 23:48:21.933: INFO: Waiting for pod pod-service-account-074c96e4-1469-11e9-a046-02505600000d-sn7n6 to disappear
Jan  9 23:48:21.936: INFO: Pod pod-service-account-074c96e4-1469-11e9-a046-02505600000d-sn7n6 no longer exists
STEP: Creating a pod to test consume service account namespace
Jan  9 23:48:21.940: INFO: Waiting up to 5m0s for pod "pod-service-account-074c96e4-1469-11e9-a046-02505600000d-27vd2" in namespace "e2e-tests-svcaccounts-vtdfw" to be "success or failure"
Jan  9 23:48:21.944: INFO: Pod "pod-service-account-074c96e4-1469-11e9-a046-02505600000d-27vd2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.179957ms
Jan  9 23:48:23.948: INFO: Pod "pod-service-account-074c96e4-1469-11e9-a046-02505600000d-27vd2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008025196s
Jan  9 23:48:25.953: INFO: Pod "pod-service-account-074c96e4-1469-11e9-a046-02505600000d-27vd2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012210495s
STEP: Saw pod success
Jan  9 23:48:25.953: INFO: Pod "pod-service-account-074c96e4-1469-11e9-a046-02505600000d-27vd2" satisfied condition "success or failure"
Jan  9 23:48:25.957: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-service-account-074c96e4-1469-11e9-a046-02505600000d-27vd2 container namespace-test: <nil>
STEP: delete the pod
Jan  9 23:48:25.976: INFO: Waiting for pod pod-service-account-074c96e4-1469-11e9-a046-02505600000d-27vd2 to disappear
Jan  9 23:48:25.982: INFO: Pod pod-service-account-074c96e4-1469-11e9-a046-02505600000d-27vd2 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:48:25.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-vtdfw" for this suite.
Jan  9 23:48:31.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:48:32.101: INFO: namespace: e2e-tests-svcaccounts-vtdfw, resource: bindings, ignored listing per whitelist
Jan  9 23:48:32.111: INFO: namespace e2e-tests-svcaccounts-vtdfw deletion completed in 6.122864722s

• [SLOW TEST:18.987 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:48:32.114: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-db2th
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan  9 23:48:32.323: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan  9 23:48:32.333: INFO: Waiting for terminating namespaces to be deleted...
Jan  9 23:48:32.337: INFO: 
Logging pods the kubelet thinks is on node 362e6945-cc10-4a7c-ad11-8cf4815006e1 before test
Jan  9 23:48:32.350: INFO: heapster-85647cf566-dbhkz from kube-system started at 2019-01-09 20:59:03 +0000 UTC (1 container statuses recorded)
Jan  9 23:48:32.350: INFO: 	Container heapster ready: true, restart count 0
Jan  9 23:48:32.350: INFO: event-controller-6c77ddd949-gfsgs from pks-system started at 2019-01-09 20:59:12 +0000 UTC (2 container statuses recorded)
Jan  9 23:48:32.350: INFO: 	Container event-controller ready: true, restart count 1
Jan  9 23:48:32.350: INFO: 	Container ghostunnel ready: true, restart count 0
Jan  9 23:48:32.350: INFO: sonobuoy-systemd-logs-daemon-set-6feb07c93b6e401e-cnswx from heptio-sonobuoy started at 2019-01-09 22:37:31 +0000 UTC (2 container statuses recorded)
Jan  9 23:48:32.350: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jan  9 23:48:32.350: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jan  9 23:48:32.350: INFO: fluent-bit-v8nfk from pks-system started at 2019-01-09 20:59:12 +0000 UTC (2 container statuses recorded)
Jan  9 23:48:32.350: INFO: 	Container fluent-bit ready: true, restart count 0
Jan  9 23:48:32.350: INFO: 	Container ghostunnel ready: true, restart count 0
Jan  9 23:48:32.350: INFO: sink-controller-65595c498b-m5gzm from pks-system started at 2019-01-09 20:59:12 +0000 UTC (1 container statuses recorded)
Jan  9 23:48:32.350: INFO: 	Container sink-controller ready: true, restart count 0
Jan  9 23:48:32.351: INFO: kubernetes-dashboard-5f4b59b97f-jtrxq from kube-system started at 2019-01-09 20:59:08 +0000 UTC (1 container statuses recorded)
Jan  9 23:48:32.351: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jan  9 23:48:32.351: INFO: telemetry-agent-559f9c8855-t6jq6 from pks-system started at 2019-01-09 21:04:33 +0000 UTC (1 container statuses recorded)
Jan  9 23:48:32.351: INFO: 	Container fluent-bit ready: true, restart count 0
Jan  9 23:48:32.351: INFO: 
Logging pods the kubelet thinks is on node 50ed3ea8-4626-444e-b102-822e7e7faeed before test
Jan  9 23:48:32.360: INFO: metrics-server-555d98886f-l762x from kube-system started at 2019-01-09 20:59:01 +0000 UTC (1 container statuses recorded)
Jan  9 23:48:32.360: INFO: 	Container metrics-server ready: true, restart count 0
Jan  9 23:48:32.360: INFO: fluent-bit-gqfg4 from pks-system started at 2019-01-09 20:59:12 +0000 UTC (2 container statuses recorded)
Jan  9 23:48:32.360: INFO: 	Container fluent-bit ready: true, restart count 0
Jan  9 23:48:32.360: INFO: 	Container ghostunnel ready: true, restart count 0
Jan  9 23:48:32.360: INFO: sonobuoy-systemd-logs-daemon-set-6feb07c93b6e401e-lpnvh from heptio-sonobuoy started at 2019-01-09 22:37:31 +0000 UTC (2 container statuses recorded)
Jan  9 23:48:32.360: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jan  9 23:48:32.360: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jan  9 23:48:32.360: INFO: monitoring-influxdb-cdcf4674-w7x2z from kube-system started at 2019-01-09 20:59:06 +0000 UTC (1 container statuses recorded)
Jan  9 23:48:32.360: INFO: 	Container influxdb ready: true, restart count 0
Jan  9 23:48:32.360: INFO: wavefront-proxy-bf5f4c667-sbklh from kube-system started at 2019-01-09 21:01:51 +0000 UTC (4 container statuses recorded)
Jan  9 23:48:32.360: INFO: 	Container heapster ready: true, restart count 0
Jan  9 23:48:32.360: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jan  9 23:48:32.360: INFO: 	Container telegraf ready: true, restart count 0
Jan  9 23:48:32.360: INFO: 	Container wavefront-proxy ready: true, restart count 0
Jan  9 23:48:32.360: INFO: cert-generator-v0.11-9ntzp from pks-system started at 2019-01-09 20:59:12 +0000 UTC (1 container statuses recorded)
Jan  9 23:48:32.361: INFO: 	Container cert-generator ready: false, restart count 0
Jan  9 23:48:32.361: INFO: 
Logging pods the kubelet thinks is on node 582539c0-37f1-42db-85f2-2655dcef1574 before test
Jan  9 23:48:32.383: INFO: sonobuoy-e2e-job-28ffb20a9ad5428e from heptio-sonobuoy started at 2019-01-09 22:37:31 +0000 UTC (2 container statuses recorded)
Jan  9 23:48:32.383: INFO: 	Container e2e ready: true, restart count 0
Jan  9 23:48:32.383: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan  9 23:48:32.383: INFO: kube-dns-7559c96fc4-l8tbn from kube-system started at 2019-01-09 20:58:49 +0000 UTC (3 container statuses recorded)
Jan  9 23:48:32.383: INFO: 	Container dnsmasq ready: true, restart count 0
Jan  9 23:48:32.383: INFO: 	Container kubedns ready: true, restart count 0
Jan  9 23:48:32.383: INFO: 	Container sidecar ready: true, restart count 0
Jan  9 23:48:32.383: INFO: fluent-bit-4rtck from pks-system started at 2019-01-09 20:59:12 +0000 UTC (2 container statuses recorded)
Jan  9 23:48:32.383: INFO: 	Container fluent-bit ready: true, restart count 0
Jan  9 23:48:32.383: INFO: 	Container ghostunnel ready: true, restart count 0
Jan  9 23:48:32.383: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-09 22:37:25 +0000 UTC (1 container statuses recorded)
Jan  9 23:48:32.383: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan  9 23:48:32.383: INFO: sonobuoy-systemd-logs-daemon-set-6feb07c93b6e401e-fvdm7 from heptio-sonobuoy started at 2019-01-09 22:37:31 +0000 UTC (2 container statuses recorded)
Jan  9 23:48:32.383: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jan  9 23:48:32.383: INFO: 	Container sonobuoy-worker ready: true, restart count 1
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-14c8862d-1469-11e9-a046-02505600000d 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-14c8862d-1469-11e9-a046-02505600000d off the node 362e6945-cc10-4a7c-ad11-8cf4815006e1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-14c8862d-1469-11e9-a046-02505600000d
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:48:40.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-db2th" for this suite.
Jan  9 23:48:48.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:48:48.628: INFO: namespace: e2e-tests-sched-pred-db2th, resource: bindings, ignored listing per whitelist
Jan  9 23:48:48.628: INFO: namespace e2e-tests-sched-pred-db2th deletion completed in 8.135441349s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:16.515 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:48:48.629: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-68sq8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-1c2b1298-1469-11e9-a046-02505600000d
STEP: Creating a pod to test consume secrets
Jan  9 23:48:48.836: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1c2bbb8f-1469-11e9-a046-02505600000d" in namespace "e2e-tests-projected-68sq8" to be "success or failure"
Jan  9 23:48:48.849: INFO: Pod "pod-projected-secrets-1c2bbb8f-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.403146ms
Jan  9 23:48:50.854: INFO: Pod "pod-projected-secrets-1c2bbb8f-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017418352s
Jan  9 23:48:52.859: INFO: Pod "pod-projected-secrets-1c2bbb8f-1469-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022665889s
STEP: Saw pod success
Jan  9 23:48:52.859: INFO: Pod "pod-projected-secrets-1c2bbb8f-1469-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:48:52.863: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-projected-secrets-1c2bbb8f-1469-11e9-a046-02505600000d container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan  9 23:48:52.892: INFO: Waiting for pod pod-projected-secrets-1c2bbb8f-1469-11e9-a046-02505600000d to disappear
Jan  9 23:48:52.895: INFO: Pod pod-projected-secrets-1c2bbb8f-1469-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:48:52.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-68sq8" for this suite.
Jan  9 23:48:58.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:48:58.951: INFO: namespace: e2e-tests-projected-68sq8, resource: bindings, ignored listing per whitelist
Jan  9 23:48:59.028: INFO: namespace e2e-tests-projected-68sq8 deletion completed in 6.128309146s

• [SLOW TEST:10.400 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:48:59.031: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9xg2c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-225e5348-1469-11e9-a046-02505600000d
STEP: Creating a pod to test consume secrets
Jan  9 23:48:59.236: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-225edc6b-1469-11e9-a046-02505600000d" in namespace "e2e-tests-projected-9xg2c" to be "success or failure"
Jan  9 23:48:59.271: INFO: Pod "pod-projected-secrets-225edc6b-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 34.858236ms
Jan  9 23:49:01.276: INFO: Pod "pod-projected-secrets-225edc6b-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039464607s
Jan  9 23:49:03.282: INFO: Pod "pod-projected-secrets-225edc6b-1469-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045484098s
STEP: Saw pod success
Jan  9 23:49:03.282: INFO: Pod "pod-projected-secrets-225edc6b-1469-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:49:03.286: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-projected-secrets-225edc6b-1469-11e9-a046-02505600000d container secret-volume-test: <nil>
STEP: delete the pod
Jan  9 23:49:03.313: INFO: Waiting for pod pod-projected-secrets-225edc6b-1469-11e9-a046-02505600000d to disappear
Jan  9 23:49:03.319: INFO: Pod pod-projected-secrets-225edc6b-1469-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:49:03.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9xg2c" for this suite.
Jan  9 23:49:09.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:49:09.389: INFO: namespace: e2e-tests-projected-9xg2c, resource: bindings, ignored listing per whitelist
Jan  9 23:49:09.431: INFO: namespace e2e-tests-projected-9xg2c deletion completed in 6.107495945s

• [SLOW TEST:10.401 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:49:09.433: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4kqcn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan  9 23:49:09.638: INFO: Waiting up to 5m0s for pod "downward-api-28922835-1469-11e9-a046-02505600000d" in namespace "e2e-tests-downward-api-4kqcn" to be "success or failure"
Jan  9 23:49:09.655: INFO: Pod "downward-api-28922835-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 17.49734ms
Jan  9 23:49:11.660: INFO: Pod "downward-api-28922835-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021794445s
Jan  9 23:49:13.664: INFO: Pod "downward-api-28922835-1469-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026281164s
STEP: Saw pod success
Jan  9 23:49:13.664: INFO: Pod "downward-api-28922835-1469-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:49:13.667: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod downward-api-28922835-1469-11e9-a046-02505600000d container dapi-container: <nil>
STEP: delete the pod
Jan  9 23:49:13.693: INFO: Waiting for pod downward-api-28922835-1469-11e9-a046-02505600000d to disappear
Jan  9 23:49:13.695: INFO: Pod downward-api-28922835-1469-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:49:13.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4kqcn" for this suite.
Jan  9 23:49:19.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:49:19.737: INFO: namespace: e2e-tests-downward-api-4kqcn, resource: bindings, ignored listing per whitelist
Jan  9 23:49:19.794: INFO: namespace e2e-tests-downward-api-4kqcn deletion completed in 6.094709897s

• [SLOW TEST:10.361 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:49:19.795: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-42chw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  9 23:49:19.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-42chw'
Jan  9 23:49:20.839: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan  9 23:49:20.839: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Jan  9 23:49:24.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-42chw'
Jan  9 23:49:24.984: INFO: stderr: ""
Jan  9 23:49:24.984: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:49:24.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-42chw" for this suite.
Jan  9 23:49:47.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:49:47.085: INFO: namespace: e2e-tests-kubectl-42chw, resource: bindings, ignored listing per whitelist
Jan  9 23:49:47.094: INFO: namespace e2e-tests-kubectl-42chw deletion completed in 22.106003214s

• [SLOW TEST:27.299 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:49:47.095: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-lw9rk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 23:49:47.304: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3f05ccbe-1469-11e9-a046-02505600000d" in namespace "e2e-tests-downward-api-lw9rk" to be "success or failure"
Jan  9 23:49:47.313: INFO: Pod "downwardapi-volume-3f05ccbe-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.777416ms
Jan  9 23:49:49.317: INFO: Pod "downwardapi-volume-3f05ccbe-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012123343s
Jan  9 23:49:51.321: INFO: Pod "downwardapi-volume-3f05ccbe-1469-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016442356s
STEP: Saw pod success
Jan  9 23:49:51.321: INFO: Pod "downwardapi-volume-3f05ccbe-1469-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:49:51.324: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod downwardapi-volume-3f05ccbe-1469-11e9-a046-02505600000d container client-container: <nil>
STEP: delete the pod
Jan  9 23:49:51.347: INFO: Waiting for pod downwardapi-volume-3f05ccbe-1469-11e9-a046-02505600000d to disappear
Jan  9 23:49:51.351: INFO: Pod downwardapi-volume-3f05ccbe-1469-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:49:51.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lw9rk" for this suite.
Jan  9 23:49:57.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:49:57.439: INFO: namespace: e2e-tests-downward-api-lw9rk, resource: bindings, ignored listing per whitelist
Jan  9 23:49:57.456: INFO: namespace e2e-tests-downward-api-lw9rk deletion completed in 6.101003315s

• [SLOW TEST:10.362 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:49:57.460: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mdqll
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan  9 23:50:02.200: INFO: Successfully updated pod "labelsupdate45333dae-1469-11e9-a046-02505600000d"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:50:06.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mdqll" for this suite.
Jan  9 23:50:28.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:50:28.287: INFO: namespace: e2e-tests-projected-mdqll, resource: bindings, ignored listing per whitelist
Jan  9 23:50:28.349: INFO: namespace e2e-tests-projected-mdqll deletion completed in 22.1115467s

• [SLOW TEST:30.890 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:50:28.350: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-brgh2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 23:50:28.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 version'
Jan  9 23:50:28.682: INFO: stderr: ""
Jan  9 23:50:28.682: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.4\", GitCommit:\"f49fa022dbe63faafd0da106ef7e05a29721d3f1\", GitTreeState:\"clean\", BuildDate:\"2018-12-14T06:59:37Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:50:28.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-brgh2" for this suite.
Jan  9 23:50:34.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:50:34.796: INFO: namespace: e2e-tests-kubectl-brgh2, resource: bindings, ignored listing per whitelist
Jan  9 23:50:34.819: INFO: namespace e2e-tests-kubectl-brgh2 deletion completed in 6.132278287s

• [SLOW TEST:6.469 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:50:34.820: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2zwb9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-5b7609f4-1469-11e9-a046-02505600000d
STEP: Creating a pod to test consume configMaps
Jan  9 23:50:35.025: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5b76b3b5-1469-11e9-a046-02505600000d" in namespace "e2e-tests-projected-2zwb9" to be "success or failure"
Jan  9 23:50:35.030: INFO: Pod "pod-projected-configmaps-5b76b3b5-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.535072ms
Jan  9 23:50:37.038: INFO: Pod "pod-projected-configmaps-5b76b3b5-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013466273s
Jan  9 23:50:39.044: INFO: Pod "pod-projected-configmaps-5b76b3b5-1469-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019215456s
STEP: Saw pod success
Jan  9 23:50:39.044: INFO: Pod "pod-projected-configmaps-5b76b3b5-1469-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:50:39.047: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-projected-configmaps-5b76b3b5-1469-11e9-a046-02505600000d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 23:50:39.067: INFO: Waiting for pod pod-projected-configmaps-5b76b3b5-1469-11e9-a046-02505600000d to disappear
Jan  9 23:50:39.078: INFO: Pod pod-projected-configmaps-5b76b3b5-1469-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:50:39.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2zwb9" for this suite.
Jan  9 23:50:45.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:50:45.144: INFO: namespace: e2e-tests-projected-2zwb9, resource: bindings, ignored listing per whitelist
Jan  9 23:50:45.184: INFO: namespace e2e-tests-projected-2zwb9 deletion completed in 6.098523707s

• [SLOW TEST:10.364 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:50:45.184: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-q2vt7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-61a6202b-1469-11e9-a046-02505600000d
STEP: Creating a pod to test consume secrets
Jan  9 23:50:45.403: INFO: Waiting up to 5m0s for pod "pod-secrets-61a6cd7e-1469-11e9-a046-02505600000d" in namespace "e2e-tests-secrets-q2vt7" to be "success or failure"
Jan  9 23:50:45.420: INFO: Pod "pod-secrets-61a6cd7e-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 16.561443ms
Jan  9 23:50:47.424: INFO: Pod "pod-secrets-61a6cd7e-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020150673s
Jan  9 23:50:49.427: INFO: Pod "pod-secrets-61a6cd7e-1469-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023988014s
STEP: Saw pod success
Jan  9 23:50:49.428: INFO: Pod "pod-secrets-61a6cd7e-1469-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:50:49.431: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-secrets-61a6cd7e-1469-11e9-a046-02505600000d container secret-volume-test: <nil>
STEP: delete the pod
Jan  9 23:50:49.457: INFO: Waiting for pod pod-secrets-61a6cd7e-1469-11e9-a046-02505600000d to disappear
Jan  9 23:50:49.462: INFO: Pod pod-secrets-61a6cd7e-1469-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:50:49.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-q2vt7" for this suite.
Jan  9 23:50:55.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:50:55.510: INFO: namespace: e2e-tests-secrets-q2vt7, resource: bindings, ignored listing per whitelist
Jan  9 23:50:55.580: INFO: namespace e2e-tests-secrets-q2vt7 deletion completed in 6.113786638s

• [SLOW TEST:10.396 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:50:55.580: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4l6gv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan  9 23:50:55.792: INFO: Waiting up to 5m0s for pod "downward-api-67d7ae8d-1469-11e9-a046-02505600000d" in namespace "e2e-tests-downward-api-4l6gv" to be "success or failure"
Jan  9 23:50:55.800: INFO: Pod "downward-api-67d7ae8d-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.055218ms
Jan  9 23:50:57.804: INFO: Pod "downward-api-67d7ae8d-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012019478s
Jan  9 23:50:59.808: INFO: Pod "downward-api-67d7ae8d-1469-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015806475s
STEP: Saw pod success
Jan  9 23:50:59.808: INFO: Pod "downward-api-67d7ae8d-1469-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:50:59.814: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod downward-api-67d7ae8d-1469-11e9-a046-02505600000d container dapi-container: <nil>
STEP: delete the pod
Jan  9 23:50:59.841: INFO: Waiting for pod downward-api-67d7ae8d-1469-11e9-a046-02505600000d to disappear
Jan  9 23:50:59.846: INFO: Pod downward-api-67d7ae8d-1469-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:50:59.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4l6gv" for this suite.
Jan  9 23:51:05.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:51:05.917: INFO: namespace: e2e-tests-downward-api-4l6gv, resource: bindings, ignored listing per whitelist
Jan  9 23:51:05.979: INFO: namespace e2e-tests-downward-api-4l6gv deletion completed in 6.127974342s

• [SLOW TEST:10.399 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:51:05.980: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xwrwf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-6e0aa3ae-1469-11e9-a046-02505600000d
STEP: Creating a pod to test consume secrets
Jan  9 23:51:06.195: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6e0b3d43-1469-11e9-a046-02505600000d" in namespace "e2e-tests-projected-xwrwf" to be "success or failure"
Jan  9 23:51:06.240: INFO: Pod "pod-projected-secrets-6e0b3d43-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 45.55145ms
Jan  9 23:51:08.244: INFO: Pod "pod-projected-secrets-6e0b3d43-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04938026s
Jan  9 23:51:10.248: INFO: Pod "pod-projected-secrets-6e0b3d43-1469-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052875924s
STEP: Saw pod success
Jan  9 23:51:10.248: INFO: Pod "pod-projected-secrets-6e0b3d43-1469-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:51:10.250: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-projected-secrets-6e0b3d43-1469-11e9-a046-02505600000d container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan  9 23:51:10.276: INFO: Waiting for pod pod-projected-secrets-6e0b3d43-1469-11e9-a046-02505600000d to disappear
Jan  9 23:51:10.281: INFO: Pod pod-projected-secrets-6e0b3d43-1469-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:51:10.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xwrwf" for this suite.
Jan  9 23:51:16.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:51:16.376: INFO: namespace: e2e-tests-projected-xwrwf, resource: bindings, ignored listing per whitelist
Jan  9 23:51:16.407: INFO: namespace e2e-tests-projected-xwrwf deletion completed in 6.121122593s

• [SLOW TEST:10.427 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:51:16.409: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-j5pt7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-m54wr
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Jan  9 23:51:20.820: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-mmwkb
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:51:45.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-j5pt7" for this suite.
Jan  9 23:51:51.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:51:51.171: INFO: namespace: e2e-tests-namespaces-j5pt7, resource: bindings, ignored listing per whitelist
Jan  9 23:51:51.219: INFO: namespace e2e-tests-namespaces-j5pt7 deletion completed in 6.123363269s
STEP: Destroying namespace "e2e-tests-nsdeletetest-m54wr" for this suite.
Jan  9 23:51:51.222: INFO: Namespace e2e-tests-nsdeletetest-m54wr was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-mmwkb" for this suite.
Jan  9 23:51:57.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:51:57.262: INFO: namespace: e2e-tests-nsdeletetest-mmwkb, resource: bindings, ignored listing per whitelist
Jan  9 23:51:57.328: INFO: namespace e2e-tests-nsdeletetest-mmwkb deletion completed in 6.106068812s

• [SLOW TEST:40.919 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:51:57.328: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-28666
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-8ca452f0-1469-11e9-a046-02505600000d
STEP: Creating a pod to test consume configMaps
Jan  9 23:51:57.539: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8ca545ef-1469-11e9-a046-02505600000d" in namespace "e2e-tests-projected-28666" to be "success or failure"
Jan  9 23:51:57.556: INFO: Pod "pod-projected-configmaps-8ca545ef-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 16.400121ms
Jan  9 23:51:59.560: INFO: Pod "pod-projected-configmaps-8ca545ef-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020163353s
Jan  9 23:52:01.563: INFO: Pod "pod-projected-configmaps-8ca545ef-1469-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023736382s
STEP: Saw pod success
Jan  9 23:52:01.563: INFO: Pod "pod-projected-configmaps-8ca545ef-1469-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:52:01.566: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-projected-configmaps-8ca545ef-1469-11e9-a046-02505600000d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 23:52:01.591: INFO: Waiting for pod pod-projected-configmaps-8ca545ef-1469-11e9-a046-02505600000d to disappear
Jan  9 23:52:01.597: INFO: Pod pod-projected-configmaps-8ca545ef-1469-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:52:01.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-28666" for this suite.
Jan  9 23:52:07.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:52:07.713: INFO: namespace: e2e-tests-projected-28666, resource: bindings, ignored listing per whitelist
Jan  9 23:52:07.723: INFO: namespace e2e-tests-projected-28666 deletion completed in 6.12193925s

• [SLOW TEST:10.395 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:52:07.726: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-h8pmt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 23:52:07.961: INFO: Waiting up to 5m0s for pod "downwardapi-volume-92d78330-1469-11e9-a046-02505600000d" in namespace "e2e-tests-projected-h8pmt" to be "success or failure"
Jan  9 23:52:07.973: INFO: Pod "downwardapi-volume-92d78330-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.527066ms
Jan  9 23:52:09.977: INFO: Pod "downwardapi-volume-92d78330-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016806728s
Jan  9 23:52:11.981: INFO: Pod "downwardapi-volume-92d78330-1469-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020741842s
STEP: Saw pod success
Jan  9 23:52:11.982: INFO: Pod "downwardapi-volume-92d78330-1469-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:52:11.984: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod downwardapi-volume-92d78330-1469-11e9-a046-02505600000d container client-container: <nil>
STEP: delete the pod
Jan  9 23:52:12.005: INFO: Waiting for pod downwardapi-volume-92d78330-1469-11e9-a046-02505600000d to disappear
Jan  9 23:52:12.009: INFO: Pod downwardapi-volume-92d78330-1469-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:52:12.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h8pmt" for this suite.
Jan  9 23:52:18.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:52:18.094: INFO: namespace: e2e-tests-projected-h8pmt, resource: bindings, ignored listing per whitelist
Jan  9 23:52:18.172: INFO: namespace e2e-tests-projected-h8pmt deletion completed in 6.158784525s

• [SLOW TEST:10.448 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:52:18.179: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-s8mnr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Jan  9 23:52:18.381: INFO: Waiting up to 5m0s for pod "client-containers-9911aa42-1469-11e9-a046-02505600000d" in namespace "e2e-tests-containers-s8mnr" to be "success or failure"
Jan  9 23:52:18.386: INFO: Pod "client-containers-9911aa42-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.965553ms
Jan  9 23:52:20.392: INFO: Pod "client-containers-9911aa42-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01098878s
Jan  9 23:52:22.395: INFO: Pod "client-containers-9911aa42-1469-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014428555s
STEP: Saw pod success
Jan  9 23:52:22.396: INFO: Pod "client-containers-9911aa42-1469-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:52:22.399: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod client-containers-9911aa42-1469-11e9-a046-02505600000d container test-container: <nil>
STEP: delete the pod
Jan  9 23:52:22.421: INFO: Waiting for pod client-containers-9911aa42-1469-11e9-a046-02505600000d to disappear
Jan  9 23:52:22.428: INFO: Pod client-containers-9911aa42-1469-11e9-a046-02505600000d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:52:22.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-s8mnr" for this suite.
Jan  9 23:52:28.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:52:28.467: INFO: namespace: e2e-tests-containers-s8mnr, resource: bindings, ignored listing per whitelist
Jan  9 23:52:28.526: INFO: namespace e2e-tests-containers-s8mnr deletion completed in 6.094332241s

• [SLOW TEST:10.348 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:52:28.526: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-f2wd8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Jan  9 23:52:32.749: INFO: Pod pod-hostip-9f3dd825-1469-11e9-a046-02505600000d has hostIP: 30.0.3.4
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:52:32.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-f2wd8" for this suite.
Jan  9 23:52:54.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:52:54.824: INFO: namespace: e2e-tests-pods-f2wd8, resource: bindings, ignored listing per whitelist
Jan  9 23:52:54.861: INFO: namespace e2e-tests-pods-f2wd8 deletion completed in 22.107242098s

• [SLOW TEST:26.334 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:52:54.862: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-bssm9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan  9 23:52:55.094: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan  9 23:52:55.103: INFO: Waiting for terminating namespaces to be deleted...
Jan  9 23:52:55.107: INFO: 
Logging pods the kubelet thinks is on node 362e6945-cc10-4a7c-ad11-8cf4815006e1 before test
Jan  9 23:52:55.120: INFO: fluent-bit-v8nfk from pks-system started at 2019-01-09 20:59:12 +0000 UTC (2 container statuses recorded)
Jan  9 23:52:55.120: INFO: 	Container fluent-bit ready: true, restart count 0
Jan  9 23:52:55.120: INFO: 	Container ghostunnel ready: true, restart count 0
Jan  9 23:52:55.120: INFO: sink-controller-65595c498b-m5gzm from pks-system started at 2019-01-09 20:59:12 +0000 UTC (1 container statuses recorded)
Jan  9 23:52:55.120: INFO: 	Container sink-controller ready: true, restart count 0
Jan  9 23:52:55.120: INFO: kubernetes-dashboard-5f4b59b97f-jtrxq from kube-system started at 2019-01-09 20:59:08 +0000 UTC (1 container statuses recorded)
Jan  9 23:52:55.120: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jan  9 23:52:55.120: INFO: telemetry-agent-559f9c8855-t6jq6 from pks-system started at 2019-01-09 21:04:33 +0000 UTC (1 container statuses recorded)
Jan  9 23:52:55.120: INFO: 	Container fluent-bit ready: true, restart count 0
Jan  9 23:52:55.120: INFO: heapster-85647cf566-dbhkz from kube-system started at 2019-01-09 20:59:03 +0000 UTC (1 container statuses recorded)
Jan  9 23:52:55.120: INFO: 	Container heapster ready: true, restart count 0
Jan  9 23:52:55.120: INFO: event-controller-6c77ddd949-gfsgs from pks-system started at 2019-01-09 20:59:12 +0000 UTC (2 container statuses recorded)
Jan  9 23:52:55.121: INFO: 	Container event-controller ready: true, restart count 1
Jan  9 23:52:55.121: INFO: 	Container ghostunnel ready: true, restart count 0
Jan  9 23:52:55.121: INFO: sonobuoy-systemd-logs-daemon-set-6feb07c93b6e401e-cnswx from heptio-sonobuoy started at 2019-01-09 22:37:31 +0000 UTC (2 container statuses recorded)
Jan  9 23:52:55.121: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jan  9 23:52:55.121: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jan  9 23:52:55.121: INFO: 
Logging pods the kubelet thinks is on node 50ed3ea8-4626-444e-b102-822e7e7faeed before test
Jan  9 23:52:55.129: INFO: sonobuoy-systemd-logs-daemon-set-6feb07c93b6e401e-lpnvh from heptio-sonobuoy started at 2019-01-09 22:37:31 +0000 UTC (2 container statuses recorded)
Jan  9 23:52:55.129: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jan  9 23:52:55.129: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jan  9 23:52:55.129: INFO: monitoring-influxdb-cdcf4674-w7x2z from kube-system started at 2019-01-09 20:59:06 +0000 UTC (1 container statuses recorded)
Jan  9 23:52:55.130: INFO: 	Container influxdb ready: true, restart count 0
Jan  9 23:52:55.130: INFO: fluent-bit-gqfg4 from pks-system started at 2019-01-09 20:59:12 +0000 UTC (2 container statuses recorded)
Jan  9 23:52:55.130: INFO: 	Container fluent-bit ready: true, restart count 0
Jan  9 23:52:55.130: INFO: 	Container ghostunnel ready: true, restart count 0
Jan  9 23:52:55.130: INFO: cert-generator-v0.11-9ntzp from pks-system started at 2019-01-09 20:59:12 +0000 UTC (1 container statuses recorded)
Jan  9 23:52:55.130: INFO: 	Container cert-generator ready: false, restart count 0
Jan  9 23:52:55.130: INFO: wavefront-proxy-bf5f4c667-sbklh from kube-system started at 2019-01-09 21:01:51 +0000 UTC (4 container statuses recorded)
Jan  9 23:52:55.131: INFO: 	Container heapster ready: true, restart count 0
Jan  9 23:52:55.131: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jan  9 23:52:55.131: INFO: 	Container telegraf ready: true, restart count 0
Jan  9 23:52:55.131: INFO: 	Container wavefront-proxy ready: true, restart count 0
Jan  9 23:52:55.131: INFO: metrics-server-555d98886f-l762x from kube-system started at 2019-01-09 20:59:01 +0000 UTC (1 container statuses recorded)
Jan  9 23:52:55.131: INFO: 	Container metrics-server ready: true, restart count 0
Jan  9 23:52:55.131: INFO: 
Logging pods the kubelet thinks is on node 582539c0-37f1-42db-85f2-2655dcef1574 before test
Jan  9 23:52:55.138: INFO: kube-dns-7559c96fc4-l8tbn from kube-system started at 2019-01-09 20:58:49 +0000 UTC (3 container statuses recorded)
Jan  9 23:52:55.139: INFO: 	Container dnsmasq ready: true, restart count 0
Jan  9 23:52:55.139: INFO: 	Container kubedns ready: true, restart count 0
Jan  9 23:52:55.139: INFO: 	Container sidecar ready: true, restart count 0
Jan  9 23:52:55.139: INFO: fluent-bit-4rtck from pks-system started at 2019-01-09 20:59:12 +0000 UTC (2 container statuses recorded)
Jan  9 23:52:55.139: INFO: 	Container fluent-bit ready: true, restart count 0
Jan  9 23:52:55.139: INFO: 	Container ghostunnel ready: true, restart count 0
Jan  9 23:52:55.139: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-09 22:37:25 +0000 UTC (1 container statuses recorded)
Jan  9 23:52:55.139: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan  9 23:52:55.139: INFO: sonobuoy-systemd-logs-daemon-set-6feb07c93b6e401e-fvdm7 from heptio-sonobuoy started at 2019-01-09 22:37:31 +0000 UTC (2 container statuses recorded)
Jan  9 23:52:55.139: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jan  9 23:52:55.139: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jan  9 23:52:55.139: INFO: sonobuoy-e2e-job-28ffb20a9ad5428e from heptio-sonobuoy started at 2019-01-09 22:37:31 +0000 UTC (2 container statuses recorded)
Jan  9 23:52:55.139: INFO: 	Container e2e ready: true, restart count 0
Jan  9 23:52:55.139: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15785338bd9c9950], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:52:56.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-bssm9" for this suite.
Jan  9 23:53:02.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:53:02.211: INFO: namespace: e2e-tests-sched-pred-bssm9, resource: bindings, ignored listing per whitelist
Jan  9 23:53:02.283: INFO: namespace e2e-tests-sched-pred-bssm9 deletion completed in 6.107723085s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.422 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:53:02.286: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-q7xbw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-q7xbw
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan  9 23:53:02.464: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan  9 23:53:24.577: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://40.0.6.5:8080/dial?request=hostName&protocol=http&host=40.0.6.2&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-q7xbw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 23:53:24.578: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 23:53:24.683: INFO: Waiting for endpoints: map[]
Jan  9 23:53:24.686: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://40.0.6.5:8080/dial?request=hostName&protocol=http&host=40.0.6.3&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-q7xbw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 23:53:24.686: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 23:53:24.784: INFO: Waiting for endpoints: map[]
Jan  9 23:53:24.788: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://40.0.6.5:8080/dial?request=hostName&protocol=http&host=40.0.6.4&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-q7xbw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan  9 23:53:24.788: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan  9 23:53:24.884: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:53:24.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-q7xbw" for this suite.
Jan  9 23:53:46.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:53:46.913: INFO: namespace: e2e-tests-pod-network-test-q7xbw, resource: bindings, ignored listing per whitelist
Jan  9 23:53:46.978: INFO: namespace e2e-tests-pod-network-test-q7xbw deletion completed in 22.089539905s

• [SLOW TEST:44.693 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:53:46.979: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-xzwgc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-xzwgc
Jan  9 23:53:51.185: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-xzwgc
STEP: checking the pod's current state and verifying that restartCount is present
Jan  9 23:53:51.190: INFO: Initial restart count of pod liveness-http is 0
Jan  9 23:54:13.230: INFO: Restart count of pod e2e-tests-container-probe-xzwgc/liveness-http is now 1 (22.040543137s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:54:13.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-xzwgc" for this suite.
Jan  9 23:54:19.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:54:19.302: INFO: namespace: e2e-tests-container-probe-xzwgc, resource: bindings, ignored listing per whitelist
Jan  9 23:54:19.353: INFO: namespace e2e-tests-container-probe-xzwgc deletion completed in 6.102371517s

• [SLOW TEST:32.374 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:54:19.356: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-tvq57
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-e14b771e-1469-11e9-a046-02505600000d
STEP: Creating a pod to test consume configMaps
Jan  9 23:54:19.553: INFO: Waiting up to 5m0s for pod "pod-configmaps-e14c0be4-1469-11e9-a046-02505600000d" in namespace "e2e-tests-configmap-tvq57" to be "success or failure"
Jan  9 23:54:19.555: INFO: Pod "pod-configmaps-e14c0be4-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.980652ms
Jan  9 23:54:21.558: INFO: Pod "pod-configmaps-e14c0be4-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005201358s
Jan  9 23:54:23.562: INFO: Pod "pod-configmaps-e14c0be4-1469-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009000677s
STEP: Saw pod success
Jan  9 23:54:23.562: INFO: Pod "pod-configmaps-e14c0be4-1469-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:54:23.566: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-configmaps-e14c0be4-1469-11e9-a046-02505600000d container configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 23:54:23.585: INFO: Waiting for pod pod-configmaps-e14c0be4-1469-11e9-a046-02505600000d to disappear
Jan  9 23:54:23.589: INFO: Pod pod-configmaps-e14c0be4-1469-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:54:23.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tvq57" for this suite.
Jan  9 23:54:29.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:54:29.682: INFO: namespace: e2e-tests-configmap-tvq57, resource: bindings, ignored listing per whitelist
Jan  9 23:54:29.702: INFO: namespace e2e-tests-configmap-tvq57 deletion completed in 6.107960719s

• [SLOW TEST:10.346 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:54:29.702: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-njqnc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-e7783991-1469-11e9-a046-02505600000d
STEP: Creating a pod to test consume configMaps
Jan  9 23:54:29.914: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e778c95f-1469-11e9-a046-02505600000d" in namespace "e2e-tests-projected-njqnc" to be "success or failure"
Jan  9 23:54:29.926: INFO: Pod "pod-projected-configmaps-e778c95f-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.997853ms
Jan  9 23:54:31.946: INFO: Pod "pod-projected-configmaps-e778c95f-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031633777s
Jan  9 23:54:33.950: INFO: Pod "pod-projected-configmaps-e778c95f-1469-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035960729s
STEP: Saw pod success
Jan  9 23:54:33.950: INFO: Pod "pod-projected-configmaps-e778c95f-1469-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:54:33.953: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-projected-configmaps-e778c95f-1469-11e9-a046-02505600000d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan  9 23:54:33.975: INFO: Waiting for pod pod-projected-configmaps-e778c95f-1469-11e9-a046-02505600000d to disappear
Jan  9 23:54:33.986: INFO: Pod pod-projected-configmaps-e778c95f-1469-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:54:33.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-njqnc" for this suite.
Jan  9 23:54:40.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:54:40.090: INFO: namespace: e2e-tests-projected-njqnc, resource: bindings, ignored listing per whitelist
Jan  9 23:54:40.128: INFO: namespace e2e-tests-projected-njqnc deletion completed in 6.136592162s

• [SLOW TEST:10.426 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:54:40.128: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-8qrnb
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan  9 23:54:40.344: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:54:41.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-8qrnb" for this suite.
Jan  9 23:54:47.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:54:47.456: INFO: namespace: e2e-tests-custom-resource-definition-8qrnb, resource: bindings, ignored listing per whitelist
Jan  9 23:54:47.536: INFO: namespace e2e-tests-custom-resource-definition-8qrnb deletion completed in 6.111590515s

• [SLOW TEST:7.408 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:54:47.539: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-5lqhk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0109 23:54:53.797357      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan  9 23:54:53.797: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:54:53.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-5lqhk" for this suite.
Jan  9 23:54:59.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:54:59.852: INFO: namespace: e2e-tests-gc-5lqhk, resource: bindings, ignored listing per whitelist
Jan  9 23:54:59.905: INFO: namespace e2e-tests-gc-5lqhk deletion completed in 6.102727952s

• [SLOW TEST:12.367 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:54:59.909: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-xk2lc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-8zljl
STEP: Creating secret with name secret-test-f974b63a-1469-11e9-a046-02505600000d
STEP: Creating a pod to test consume secrets
Jan  9 23:55:00.238: INFO: Waiting up to 5m0s for pod "pod-secrets-f98b6f76-1469-11e9-a046-02505600000d" in namespace "e2e-tests-secrets-xk2lc" to be "success or failure"
Jan  9 23:55:00.242: INFO: Pod "pod-secrets-f98b6f76-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.335129ms
Jan  9 23:55:02.246: INFO: Pod "pod-secrets-f98b6f76-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007459948s
Jan  9 23:55:04.250: INFO: Pod "pod-secrets-f98b6f76-1469-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011979881s
Jan  9 23:55:06.255: INFO: Pod "pod-secrets-f98b6f76-1469-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.016710793s
STEP: Saw pod success
Jan  9 23:55:06.255: INFO: Pod "pod-secrets-f98b6f76-1469-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:55:06.258: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-secrets-f98b6f76-1469-11e9-a046-02505600000d container secret-volume-test: <nil>
STEP: delete the pod
Jan  9 23:55:06.282: INFO: Waiting for pod pod-secrets-f98b6f76-1469-11e9-a046-02505600000d to disappear
Jan  9 23:55:06.287: INFO: Pod pod-secrets-f98b6f76-1469-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:55:06.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xk2lc" for this suite.
Jan  9 23:55:12.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:55:12.374: INFO: namespace: e2e-tests-secrets-xk2lc, resource: bindings, ignored listing per whitelist
Jan  9 23:55:12.386: INFO: namespace e2e-tests-secrets-xk2lc deletion completed in 6.095070633s
STEP: Destroying namespace "e2e-tests-secret-namespace-8zljl" for this suite.
Jan  9 23:55:18.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:55:18.431: INFO: namespace: e2e-tests-secret-namespace-8zljl, resource: bindings, ignored listing per whitelist
Jan  9 23:55:18.485: INFO: namespace e2e-tests-secret-namespace-8zljl deletion completed in 6.099450558s

• [SLOW TEST:18.577 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:55:18.486: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wpglb
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Jan  9 23:55:18.675: INFO: Waiting up to 5m0s for pod "pod-0488ead4-146a-11e9-a046-02505600000d" in namespace "e2e-tests-emptydir-wpglb" to be "success or failure"
Jan  9 23:55:18.689: INFO: Pod "pod-0488ead4-146a-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.245193ms
Jan  9 23:55:20.693: INFO: Pod "pod-0488ead4-146a-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01748195s
Jan  9 23:55:22.696: INFO: Pod "pod-0488ead4-146a-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021055873s
STEP: Saw pod success
Jan  9 23:55:22.696: INFO: Pod "pod-0488ead4-146a-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:55:22.699: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-0488ead4-146a-11e9-a046-02505600000d container test-container: <nil>
STEP: delete the pod
Jan  9 23:55:22.724: INFO: Waiting for pod pod-0488ead4-146a-11e9-a046-02505600000d to disappear
Jan  9 23:55:22.728: INFO: Pod pod-0488ead4-146a-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:55:22.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wpglb" for this suite.
Jan  9 23:55:28.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:55:28.761: INFO: namespace: e2e-tests-emptydir-wpglb, resource: bindings, ignored listing per whitelist
Jan  9 23:55:28.841: INFO: namespace e2e-tests-emptydir-wpglb deletion completed in 6.107303621s

• [SLOW TEST:10.355 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:55:28.842: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-kv6rx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan  9 23:55:29.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-kv6rx'
Jan  9 23:55:29.137: INFO: stderr: ""
Jan  9 23:55:29.137: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jan  9 23:55:34.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-kv6rx -o json'
Jan  9 23:55:34.288: INFO: stderr: ""
Jan  9 23:55:34.288: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-01-09T23:55:29Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-kv6rx\",\n        \"resourceVersion\": \"25792\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-kv6rx/pods/e2e-test-nginx-pod\",\n        \"uid\": \"0ac54573-146a-11e9-9de1-005056902d46\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-zndwj\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"362e6945-cc10-4a7c-ad11-8cf4815006e1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-zndwj\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-zndwj\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-09T23:55:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-09T23:55:31Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-09T23:55:31Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-09T23:55:29Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://47a91551ba65e8da9a0fd7a7ea11b4ee449b6faf8e9f2b3b672db8f2ba6f3873\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-01-09T23:55:31Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"30.0.3.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"40.0.5.2\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-01-09T23:55:29Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jan  9 23:55:34.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 replace -f - --namespace=e2e-tests-kubectl-kv6rx'
Jan  9 23:55:34.532: INFO: stderr: ""
Jan  9 23:55:34.532: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Jan  9 23:55:34.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-kv6rx'
Jan  9 23:55:36.066: INFO: stderr: ""
Jan  9 23:55:36.066: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:55:36.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kv6rx" for this suite.
Jan  9 23:55:42.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:55:42.169: INFO: namespace: e2e-tests-kubectl-kv6rx, resource: bindings, ignored listing per whitelist
Jan  9 23:55:42.186: INFO: namespace e2e-tests-kubectl-kv6rx deletion completed in 6.115898792s

• [SLOW TEST:13.344 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:55:42.187: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-57qx8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Jan  9 23:55:42.388: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jan  9 23:55:42.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 create -f - --namespace=e2e-tests-kubectl-57qx8'
Jan  9 23:55:42.639: INFO: stderr: ""
Jan  9 23:55:42.639: INFO: stdout: "service/redis-slave created\n"
Jan  9 23:55:42.639: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jan  9 23:55:42.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 create -f - --namespace=e2e-tests-kubectl-57qx8'
Jan  9 23:55:42.878: INFO: stderr: ""
Jan  9 23:55:42.878: INFO: stdout: "service/redis-master created\n"
Jan  9 23:55:42.878: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jan  9 23:55:42.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 create -f - --namespace=e2e-tests-kubectl-57qx8'
Jan  9 23:55:43.143: INFO: stderr: ""
Jan  9 23:55:43.143: INFO: stdout: "service/frontend created\n"
Jan  9 23:55:43.147: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jan  9 23:55:43.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 create -f - --namespace=e2e-tests-kubectl-57qx8'
Jan  9 23:55:43.451: INFO: stderr: ""
Jan  9 23:55:43.451: INFO: stdout: "deployment.extensions/frontend created\n"
Jan  9 23:55:43.451: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jan  9 23:55:43.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 create -f - --namespace=e2e-tests-kubectl-57qx8'
Jan  9 23:55:43.702: INFO: stderr: ""
Jan  9 23:55:43.702: INFO: stdout: "deployment.extensions/redis-master created\n"
Jan  9 23:55:43.703: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jan  9 23:55:43.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 create -f - --namespace=e2e-tests-kubectl-57qx8'
Jan  9 23:55:44.158: INFO: stderr: ""
Jan  9 23:55:44.158: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Jan  9 23:55:44.158: INFO: Waiting for all frontend pods to be Running.
Jan  9 23:57:54.215: INFO: Waiting for frontend to serve content.
Jan  9 23:57:54.241: INFO: Trying to add a new entry to the guestbook.
Jan  9 23:57:54.266: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jan  9 23:57:54.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-57qx8'
Jan  9 23:57:54.440: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 23:57:54.440: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jan  9 23:57:54.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-57qx8'
Jan  9 23:57:54.576: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 23:57:54.576: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan  9 23:57:54.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-57qx8'
Jan  9 23:57:54.706: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 23:57:54.706: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan  9 23:57:54.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-57qx8'
Jan  9 23:57:54.842: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 23:57:54.842: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan  9 23:57:54.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-57qx8'
Jan  9 23:57:54.989: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 23:57:54.989: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan  9 23:57:54.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-076648363 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-57qx8'
Jan  9 23:57:55.177: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan  9 23:57:55.178: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:57:55.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-57qx8" for this suite.
Jan  9 23:58:37.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:58:37.295: INFO: namespace: e2e-tests-kubectl-57qx8, resource: bindings, ignored listing per whitelist
Jan  9 23:58:37.301: INFO: namespace e2e-tests-kubectl-57qx8 deletion completed in 42.112775561s

• [SLOW TEST:175.114 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:58:37.302: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-g4jng
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan  9 23:58:37.501: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7b0a9872-146a-11e9-a046-02505600000d" in namespace "e2e-tests-downward-api-g4jng" to be "success or failure"
Jan  9 23:58:37.512: INFO: Pod "downwardapi-volume-7b0a9872-146a-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.820619ms
Jan  9 23:58:39.518: INFO: Pod "downwardapi-volume-7b0a9872-146a-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016823371s
Jan  9 23:58:41.522: INFO: Pod "downwardapi-volume-7b0a9872-146a-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021044377s
STEP: Saw pod success
Jan  9 23:58:41.522: INFO: Pod "downwardapi-volume-7b0a9872-146a-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:58:41.525: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod downwardapi-volume-7b0a9872-146a-11e9-a046-02505600000d container client-container: <nil>
STEP: delete the pod
Jan  9 23:58:41.550: INFO: Waiting for pod downwardapi-volume-7b0a9872-146a-11e9-a046-02505600000d to disappear
Jan  9 23:58:41.555: INFO: Pod downwardapi-volume-7b0a9872-146a-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:58:41.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-g4jng" for this suite.
Jan  9 23:58:47.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:58:47.648: INFO: namespace: e2e-tests-downward-api-g4jng, resource: bindings, ignored listing per whitelist
Jan  9 23:58:47.660: INFO: namespace e2e-tests-downward-api-g4jng deletion completed in 6.099945412s

• [SLOW TEST:10.359 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:58:47.661: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-4xkz7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-813844b0-146a-11e9-a046-02505600000d
STEP: Creating a pod to test consume secrets
Jan  9 23:58:47.868: INFO: Waiting up to 5m0s for pod "pod-secrets-813904e7-146a-11e9-a046-02505600000d" in namespace "e2e-tests-secrets-4xkz7" to be "success or failure"
Jan  9 23:58:47.882: INFO: Pod "pod-secrets-813904e7-146a-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.440892ms
Jan  9 23:58:49.888: INFO: Pod "pod-secrets-813904e7-146a-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020677824s
Jan  9 23:58:51.905: INFO: Pod "pod-secrets-813904e7-146a-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037501159s
STEP: Saw pod success
Jan  9 23:58:51.906: INFO: Pod "pod-secrets-813904e7-146a-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan  9 23:58:51.909: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-secrets-813904e7-146a-11e9-a046-02505600000d container secret-volume-test: <nil>
STEP: delete the pod
Jan  9 23:58:51.929: INFO: Waiting for pod pod-secrets-813904e7-146a-11e9-a046-02505600000d to disappear
Jan  9 23:58:51.932: INFO: Pod pod-secrets-813904e7-146a-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:58:51.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4xkz7" for this suite.
Jan  9 23:58:57.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:58:57.985: INFO: namespace: e2e-tests-secrets-4xkz7, resource: bindings, ignored listing per whitelist
Jan  9 23:58:58.026: INFO: namespace e2e-tests-secrets-4xkz7 deletion completed in 6.089866255s

• [SLOW TEST:10.365 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:58:58.026: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-mxh75
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan  9 23:58:58.267: INFO: Number of nodes with available pods: 0
Jan  9 23:58:58.267: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:58:59.275: INFO: Number of nodes with available pods: 0
Jan  9 23:58:59.275: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:59:00.277: INFO: Number of nodes with available pods: 0
Jan  9 23:59:00.277: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:59:01.275: INFO: Number of nodes with available pods: 1
Jan  9 23:59:01.275: INFO: Node 50ed3ea8-4626-444e-b102-822e7e7faeed is running more than one daemon pod
Jan  9 23:59:02.276: INFO: Number of nodes with available pods: 3
Jan  9 23:59:02.276: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jan  9 23:59:02.334: INFO: Number of nodes with available pods: 2
Jan  9 23:59:02.334: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:59:03.344: INFO: Number of nodes with available pods: 2
Jan  9 23:59:03.344: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:59:04.345: INFO: Number of nodes with available pods: 2
Jan  9 23:59:04.345: INFO: Node 362e6945-cc10-4a7c-ad11-8cf4815006e1 is running more than one daemon pod
Jan  9 23:59:05.342: INFO: Number of nodes with available pods: 3
Jan  9 23:59:05.342: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-mxh75, will wait for the garbage collector to delete the pods
Jan  9 23:59:05.410: INFO: Deleting {extensions DaemonSet} daemon-set took: 6.623288ms
Jan  9 23:59:05.510: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.456363ms
Jan  9 23:59:45.314: INFO: Number of nodes with available pods: 0
Jan  9 23:59:45.314: INFO: Number of running nodes: 0, number of available pods: 0
Jan  9 23:59:45.318: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-mxh75/daemonsets","resourceVersion":"26498"},"items":null}

Jan  9 23:59:45.320: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-mxh75/pods","resourceVersion":"26498"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan  9 23:59:45.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-mxh75" for this suite.
Jan  9 23:59:51.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan  9 23:59:51.426: INFO: namespace: e2e-tests-daemonsets-mxh75, resource: bindings, ignored listing per whitelist
Jan  9 23:59:51.442: INFO: namespace e2e-tests-daemonsets-mxh75 deletion completed in 6.104564364s

• [SLOW TEST:53.416 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan  9 23:59:51.442: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-2gw8p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jan  9 23:59:51.636: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2gw8p,SelfLink:/api/v1/namespaces/e2e-tests-watch-2gw8p/configmaps/e2e-watch-test-configmap-a,UID:a73c58d5-146a-11e9-9de1-005056902d46,ResourceVersion:26543,Generation:0,CreationTimestamp:2019-01-09 23:59:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan  9 23:59:51.637: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2gw8p,SelfLink:/api/v1/namespaces/e2e-tests-watch-2gw8p/configmaps/e2e-watch-test-configmap-a,UID:a73c58d5-146a-11e9-9de1-005056902d46,ResourceVersion:26543,Generation:0,CreationTimestamp:2019-01-09 23:59:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jan 10 00:00:01.648: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2gw8p,SelfLink:/api/v1/namespaces/e2e-tests-watch-2gw8p/configmaps/e2e-watch-test-configmap-a,UID:a73c58d5-146a-11e9-9de1-005056902d46,ResourceVersion:26558,Generation:0,CreationTimestamp:2019-01-09 23:59:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 10 00:00:01.648: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2gw8p,SelfLink:/api/v1/namespaces/e2e-tests-watch-2gw8p/configmaps/e2e-watch-test-configmap-a,UID:a73c58d5-146a-11e9-9de1-005056902d46,ResourceVersion:26558,Generation:0,CreationTimestamp:2019-01-09 23:59:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jan 10 00:00:11.657: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2gw8p,SelfLink:/api/v1/namespaces/e2e-tests-watch-2gw8p/configmaps/e2e-watch-test-configmap-a,UID:a73c58d5-146a-11e9-9de1-005056902d46,ResourceVersion:26573,Generation:0,CreationTimestamp:2019-01-09 23:59:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 10 00:00:11.658: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2gw8p,SelfLink:/api/v1/namespaces/e2e-tests-watch-2gw8p/configmaps/e2e-watch-test-configmap-a,UID:a73c58d5-146a-11e9-9de1-005056902d46,ResourceVersion:26573,Generation:0,CreationTimestamp:2019-01-09 23:59:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jan 10 00:00:21.666: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2gw8p,SelfLink:/api/v1/namespaces/e2e-tests-watch-2gw8p/configmaps/e2e-watch-test-configmap-a,UID:a73c58d5-146a-11e9-9de1-005056902d46,ResourceVersion:26588,Generation:0,CreationTimestamp:2019-01-09 23:59:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 10 00:00:21.666: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2gw8p,SelfLink:/api/v1/namespaces/e2e-tests-watch-2gw8p/configmaps/e2e-watch-test-configmap-a,UID:a73c58d5-146a-11e9-9de1-005056902d46,ResourceVersion:26588,Generation:0,CreationTimestamp:2019-01-09 23:59:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jan 10 00:00:31.679: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-2gw8p,SelfLink:/api/v1/namespaces/e2e-tests-watch-2gw8p/configmaps/e2e-watch-test-configmap-b,UID:bf19b088-146a-11e9-9de1-005056902d46,ResourceVersion:26603,Generation:0,CreationTimestamp:2019-01-10 00:00:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 10 00:00:31.680: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-2gw8p,SelfLink:/api/v1/namespaces/e2e-tests-watch-2gw8p/configmaps/e2e-watch-test-configmap-b,UID:bf19b088-146a-11e9-9de1-005056902d46,ResourceVersion:26603,Generation:0,CreationTimestamp:2019-01-10 00:00:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jan 10 00:00:41.691: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-2gw8p,SelfLink:/api/v1/namespaces/e2e-tests-watch-2gw8p/configmaps/e2e-watch-test-configmap-b,UID:bf19b088-146a-11e9-9de1-005056902d46,ResourceVersion:26618,Generation:0,CreationTimestamp:2019-01-10 00:00:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 10 00:00:41.691: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-2gw8p,SelfLink:/api/v1/namespaces/e2e-tests-watch-2gw8p/configmaps/e2e-watch-test-configmap-b,UID:bf19b088-146a-11e9-9de1-005056902d46,ResourceVersion:26618,Generation:0,CreationTimestamp:2019-01-10 00:00:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 10 00:00:51.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-2gw8p" for this suite.
Jan 10 00:00:57.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 10 00:00:57.735: INFO: namespace: e2e-tests-watch-2gw8p, resource: bindings, ignored listing per whitelist
Jan 10 00:00:57.811: INFO: namespace e2e-tests-watch-2gw8p deletion completed in 6.110764121s

• [SLOW TEST:66.369 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 10 00:00:57.811: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-nkbrb
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-cecbc4af-146a-11e9-a046-02505600000d
STEP: Creating secret with name s-test-opt-upd-cecbc609-146a-11e9-a046-02505600000d
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-cecbc4af-146a-11e9-a046-02505600000d
STEP: Updating secret s-test-opt-upd-cecbc609-146a-11e9-a046-02505600000d
STEP: Creating secret with name s-test-opt-create-cecbc622-146a-11e9-a046-02505600000d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 10 00:01:04.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nkbrb" for this suite.
Jan 10 00:01:26.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 10 00:01:26.219: INFO: namespace: e2e-tests-secrets-nkbrb, resource: bindings, ignored listing per whitelist
Jan 10 00:01:26.258: INFO: namespace e2e-tests-secrets-nkbrb deletion completed in 22.106243967s

• [SLOW TEST:28.447 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 10 00:01:26.260: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-p4mlz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-fsmz
STEP: Creating a pod to test atomic-volume-subpath
Jan 10 00:01:26.475: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-fsmz" in namespace "e2e-tests-subpath-p4mlz" to be "success or failure"
Jan 10 00:01:26.492: INFO: Pod "pod-subpath-test-secret-fsmz": Phase="Pending", Reason="", readiness=false. Elapsed: 16.662274ms
Jan 10 00:01:28.497: INFO: Pod "pod-subpath-test-secret-fsmz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021593568s
Jan 10 00:01:30.501: INFO: Pod "pod-subpath-test-secret-fsmz": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025342176s
Jan 10 00:01:32.505: INFO: Pod "pod-subpath-test-secret-fsmz": Phase="Running", Reason="", readiness=false. Elapsed: 6.029305323s
Jan 10 00:01:34.509: INFO: Pod "pod-subpath-test-secret-fsmz": Phase="Running", Reason="", readiness=false. Elapsed: 8.033862191s
Jan 10 00:01:36.513: INFO: Pod "pod-subpath-test-secret-fsmz": Phase="Running", Reason="", readiness=false. Elapsed: 10.037776936s
Jan 10 00:01:38.517: INFO: Pod "pod-subpath-test-secret-fsmz": Phase="Running", Reason="", readiness=false. Elapsed: 12.04187485s
Jan 10 00:01:40.522: INFO: Pod "pod-subpath-test-secret-fsmz": Phase="Running", Reason="", readiness=false. Elapsed: 14.046657049s
Jan 10 00:01:42.527: INFO: Pod "pod-subpath-test-secret-fsmz": Phase="Running", Reason="", readiness=false. Elapsed: 16.051595594s
Jan 10 00:01:44.530: INFO: Pod "pod-subpath-test-secret-fsmz": Phase="Running", Reason="", readiness=false. Elapsed: 18.054938772s
Jan 10 00:01:46.537: INFO: Pod "pod-subpath-test-secret-fsmz": Phase="Running", Reason="", readiness=false. Elapsed: 20.062011695s
Jan 10 00:01:48.542: INFO: Pod "pod-subpath-test-secret-fsmz": Phase="Running", Reason="", readiness=false. Elapsed: 22.066410225s
Jan 10 00:01:50.546: INFO: Pod "pod-subpath-test-secret-fsmz": Phase="Running", Reason="", readiness=false. Elapsed: 24.070628718s
Jan 10 00:01:52.551: INFO: Pod "pod-subpath-test-secret-fsmz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.075374679s
STEP: Saw pod success
Jan 10 00:01:52.551: INFO: Pod "pod-subpath-test-secret-fsmz" satisfied condition "success or failure"
Jan 10 00:01:52.558: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-subpath-test-secret-fsmz container test-container-subpath-secret-fsmz: <nil>
STEP: delete the pod
Jan 10 00:01:52.581: INFO: Waiting for pod pod-subpath-test-secret-fsmz to disappear
Jan 10 00:01:52.585: INFO: Pod pod-subpath-test-secret-fsmz no longer exists
STEP: Deleting pod pod-subpath-test-secret-fsmz
Jan 10 00:01:52.585: INFO: Deleting pod "pod-subpath-test-secret-fsmz" in namespace "e2e-tests-subpath-p4mlz"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 10 00:01:52.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-p4mlz" for this suite.
Jan 10 00:01:58.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 10 00:01:58.658: INFO: namespace: e2e-tests-subpath-p4mlz, resource: bindings, ignored listing per whitelist
Jan 10 00:01:58.707: INFO: namespace e2e-tests-subpath-p4mlz deletion completed in 6.115038176s

• [SLOW TEST:32.447 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 10 00:01:58.708: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-kx66t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 10 00:01:58.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-kx66t" for this suite.
Jan 10 00:02:04.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 10 00:02:04.994: INFO: namespace: e2e-tests-services-kx66t, resource: bindings, ignored listing per whitelist
Jan 10 00:02:05.037: INFO: namespace e2e-tests-services-kx66t deletion completed in 6.10968341s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.330 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 10 00:02:05.038: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-pjnvv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 10 00:02:05.241: INFO: (0) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.678218ms)
Jan 10 00:02:05.245: INFO: (1) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.360398ms)
Jan 10 00:02:05.251: INFO: (2) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.639652ms)
Jan 10 00:02:05.256: INFO: (3) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.337354ms)
Jan 10 00:02:05.266: INFO: (4) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 9.421745ms)
Jan 10 00:02:05.270: INFO: (5) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.562256ms)
Jan 10 00:02:05.276: INFO: (6) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.806776ms)
Jan 10 00:02:05.280: INFO: (7) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.50958ms)
Jan 10 00:02:05.283: INFO: (8) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.947954ms)
Jan 10 00:02:05.286: INFO: (9) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.019073ms)
Jan 10 00:02:05.290: INFO: (10) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.962372ms)
Jan 10 00:02:05.296: INFO: (11) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.807803ms)
Jan 10 00:02:05.300: INFO: (12) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.357834ms)
Jan 10 00:02:05.303: INFO: (13) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.149094ms)
Jan 10 00:02:05.306: INFO: (14) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.045695ms)
Jan 10 00:02:05.312: INFO: (15) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.838972ms)
Jan 10 00:02:05.315: INFO: (16) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 3.270316ms)
Jan 10 00:02:05.318: INFO: (17) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.857152ms)
Jan 10 00:02:05.321: INFO: (18) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 2.885789ms)
Jan 10 00:02:05.325: INFO: (19) /api/v1/nodes/362e6945-cc10-4a7c-ad11-8cf4815006e1/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href... (200; 4.065406ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 10 00:02:05.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-pjnvv" for this suite.
Jan 10 00:02:11.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 10 00:02:11.400: INFO: namespace: e2e-tests-proxy-pjnvv, resource: bindings, ignored listing per whitelist
Jan 10 00:02:11.437: INFO: namespace e2e-tests-proxy-pjnvv deletion completed in 6.107158742s

• [SLOW TEST:6.400 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 10 00:02:11.440: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-wrpf8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jan 10 00:02:11.655: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-wrpf8,SelfLink:/api/v1/namespaces/e2e-tests-watch-wrpf8/configmaps/e2e-watch-test-resource-version,UID:faae3758-146a-11e9-9de1-005056902d46,ResourceVersion:26873,Generation:0,CreationTimestamp:2019-01-10 00:02:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 10 00:02:11.656: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-wrpf8,SelfLink:/api/v1/namespaces/e2e-tests-watch-wrpf8/configmaps/e2e-watch-test-resource-version,UID:faae3758-146a-11e9-9de1-005056902d46,ResourceVersion:26874,Generation:0,CreationTimestamp:2019-01-10 00:02:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 10 00:02:11.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-wrpf8" for this suite.
Jan 10 00:02:17.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 10 00:02:17.771: INFO: namespace: e2e-tests-watch-wrpf8, resource: bindings, ignored listing per whitelist
Jan 10 00:02:17.776: INFO: namespace e2e-tests-watch-wrpf8 deletion completed in 6.112927706s

• [SLOW TEST:6.337 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 10 00:02:17.777: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-f44mb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 10 00:02:17.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-f44mb" for this suite.
Jan 10 00:02:40.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 10 00:02:40.038: INFO: namespace: e2e-tests-pods-f44mb, resource: bindings, ignored listing per whitelist
Jan 10 00:02:40.092: INFO: namespace e2e-tests-pods-f44mb deletion completed in 22.100473278s

• [SLOW TEST:22.315 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 10 00:02:40.096: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-h7wkl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-0bc229b3-146b-11e9-a046-02505600000d
STEP: Creating a pod to test consume configMaps
Jan 10 00:02:40.297: INFO: Waiting up to 5m0s for pod "pod-configmaps-0bc2de22-146b-11e9-a046-02505600000d" in namespace "e2e-tests-configmap-h7wkl" to be "success or failure"
Jan 10 00:02:40.301: INFO: Pod "pod-configmaps-0bc2de22-146b-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.32151ms
Jan 10 00:02:42.306: INFO: Pod "pod-configmaps-0bc2de22-146b-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008332587s
Jan 10 00:02:44.311: INFO: Pod "pod-configmaps-0bc2de22-146b-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013649135s
STEP: Saw pod success
Jan 10 00:02:44.311: INFO: Pod "pod-configmaps-0bc2de22-146b-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan 10 00:02:44.314: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-configmaps-0bc2de22-146b-11e9-a046-02505600000d container configmap-volume-test: <nil>
STEP: delete the pod
Jan 10 00:02:44.336: INFO: Waiting for pod pod-configmaps-0bc2de22-146b-11e9-a046-02505600000d to disappear
Jan 10 00:02:44.339: INFO: Pod pod-configmaps-0bc2de22-146b-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 10 00:02:44.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-h7wkl" for this suite.
Jan 10 00:02:50.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 10 00:02:50.432: INFO: namespace: e2e-tests-configmap-h7wkl, resource: bindings, ignored listing per whitelist
Jan 10 00:02:50.454: INFO: namespace e2e-tests-configmap-h7wkl deletion completed in 6.107816546s

• [SLOW TEST:10.358 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 10 00:02:50.457: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-f77jp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-f77jp
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-f77jp to expose endpoints map[]
Jan 10 00:02:50.664: INFO: Get endpoints failed (2.085311ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jan 10 00:02:51.669: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-f77jp exposes endpoints map[] (1.007039273s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-f77jp
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-f77jp to expose endpoints map[pod1:[100]]
Jan 10 00:02:54.708: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-f77jp exposes endpoints map[pod1:[100]] (3.031256775s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-f77jp
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-f77jp to expose endpoints map[pod1:[100] pod2:[101]]
Jan 10 00:02:57.756: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-f77jp exposes endpoints map[pod1:[100] pod2:[101]] (3.043581851s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-f77jp
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-f77jp to expose endpoints map[pod2:[101]]
Jan 10 00:02:57.789: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-f77jp exposes endpoints map[pod2:[101]] (22.840559ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-f77jp
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-f77jp to expose endpoints map[]
Jan 10 00:02:57.807: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-f77jp exposes endpoints map[] (12.196168ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 10 00:02:57.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-f77jp" for this suite.
Jan 10 00:03:03.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 10 00:03:03.920: INFO: namespace: e2e-tests-services-f77jp, resource: bindings, ignored listing per whitelist
Jan 10 00:03:03.951: INFO: namespace e2e-tests-services-f77jp deletion completed in 6.092807423s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:13.495 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 10 00:03:03.952: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-kgs44
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-kgs44
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 10 00:03:04.152: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 10 00:03:30.263: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 40.0.5.2 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-kgs44 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 10 00:03:30.263: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan 10 00:03:31.390: INFO: Found all expected endpoints: [netserver-0]
Jan 10 00:03:31.393: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 40.0.5.3 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-kgs44 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 10 00:03:31.393: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan 10 00:03:32.490: INFO: Found all expected endpoints: [netserver-1]
Jan 10 00:03:32.494: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 40.0.5.4 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-kgs44 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 10 00:03:32.495: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
Jan 10 00:03:33.592: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 10 00:03:33.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-kgs44" for this suite.
Jan 10 00:03:55.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 10 00:03:55.670: INFO: namespace: e2e-tests-pod-network-test-kgs44, resource: bindings, ignored listing per whitelist
Jan 10 00:03:55.697: INFO: namespace e2e-tests-pod-network-test-kgs44 deletion completed in 22.100144627s

• [SLOW TEST:51.745 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 10 00:03:55.697: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-2tbhr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-2tbhr
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Jan 10 00:03:55.918: INFO: Found 0 stateful pods, waiting for 3
Jan 10 00:04:05.923: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 10 00:04:05.923: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 10 00:04:05.923: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 10 00:04:05.962: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jan 10 00:04:15.992: INFO: Updating stateful set ss2
Jan 10 00:04:16.011: INFO: Waiting for Pod e2e-tests-statefulset-2tbhr/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jan 10 00:04:26.069: INFO: Found 1 stateful pods, waiting for 3
Jan 10 00:04:36.075: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 10 00:04:36.075: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 10 00:04:36.075: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jan 10 00:04:36.102: INFO: Updating stateful set ss2
Jan 10 00:04:36.110: INFO: Waiting for Pod e2e-tests-statefulset-2tbhr/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 10 00:04:46.119: INFO: Waiting for Pod e2e-tests-statefulset-2tbhr/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 10 00:04:56.138: INFO: Updating stateful set ss2
Jan 10 00:04:56.144: INFO: Waiting for StatefulSet e2e-tests-statefulset-2tbhr/ss2 to complete update
Jan 10 00:04:56.144: INFO: Waiting for Pod e2e-tests-statefulset-2tbhr/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 10 00:05:06.152: INFO: Waiting for StatefulSet e2e-tests-statefulset-2tbhr/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 10 00:05:16.156: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2tbhr
Jan 10 00:05:16.160: INFO: Scaling statefulset ss2 to 0
Jan 10 00:05:36.188: INFO: Waiting for statefulset status.replicas updated to 0
Jan 10 00:05:36.191: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 10 00:05:36.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-2tbhr" for this suite.
Jan 10 00:05:42.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 10 00:05:42.282: INFO: namespace: e2e-tests-statefulset-2tbhr, resource: bindings, ignored listing per whitelist
Jan 10 00:05:42.347: INFO: namespace e2e-tests-statefulset-2tbhr deletion completed in 6.12591305s

• [SLOW TEST:106.650 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 10 00:05:42.348: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2jkfc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 10 00:05:42.547: INFO: Waiting up to 5m0s for pod "downwardapi-volume-78641c59-146b-11e9-a046-02505600000d" in namespace "e2e-tests-projected-2jkfc" to be "success or failure"
Jan 10 00:05:42.554: INFO: Pod "downwardapi-volume-78641c59-146b-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.31434ms
Jan 10 00:05:44.559: INFO: Pod "downwardapi-volume-78641c59-146b-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011428711s
Jan 10 00:05:46.567: INFO: Pod "downwardapi-volume-78641c59-146b-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018848716s
STEP: Saw pod success
Jan 10 00:05:46.567: INFO: Pod "downwardapi-volume-78641c59-146b-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan 10 00:05:46.571: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod downwardapi-volume-78641c59-146b-11e9-a046-02505600000d container client-container: <nil>
STEP: delete the pod
Jan 10 00:05:46.600: INFO: Waiting for pod downwardapi-volume-78641c59-146b-11e9-a046-02505600000d to disappear
Jan 10 00:05:46.605: INFO: Pod downwardapi-volume-78641c59-146b-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 10 00:05:46.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2jkfc" for this suite.
Jan 10 00:05:52.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 10 00:05:52.640: INFO: namespace: e2e-tests-projected-2jkfc, resource: bindings, ignored listing per whitelist
Jan 10 00:05:52.715: INFO: namespace e2e-tests-projected-2jkfc deletion completed in 6.105540858s

• [SLOW TEST:10.367 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 10 00:05:52.716: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-5jmwp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 10 00:05:52.921: INFO: Waiting up to 5m0s for pod "pod-7e92b1dd-146b-11e9-a046-02505600000d" in namespace "e2e-tests-emptydir-5jmwp" to be "success or failure"
Jan 10 00:05:52.939: INFO: Pod "pod-7e92b1dd-146b-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 17.725873ms
Jan 10 00:05:54.944: INFO: Pod "pod-7e92b1dd-146b-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022714368s
Jan 10 00:05:56.948: INFO: Pod "pod-7e92b1dd-146b-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026444216s
STEP: Saw pod success
Jan 10 00:05:56.948: INFO: Pod "pod-7e92b1dd-146b-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan 10 00:05:56.951: INFO: Trying to get logs from node 362e6945-cc10-4a7c-ad11-8cf4815006e1 pod pod-7e92b1dd-146b-11e9-a046-02505600000d container test-container: <nil>
STEP: delete the pod
Jan 10 00:05:56.977: INFO: Waiting for pod pod-7e92b1dd-146b-11e9-a046-02505600000d to disappear
Jan 10 00:05:56.982: INFO: Pod pod-7e92b1dd-146b-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 10 00:05:56.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5jmwp" for this suite.
Jan 10 00:06:02.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 10 00:06:03.042: INFO: namespace: e2e-tests-emptydir-5jmwp, resource: bindings, ignored listing per whitelist
Jan 10 00:06:03.087: INFO: namespace e2e-tests-emptydir-5jmwp deletion completed in 6.100110869s

• [SLOW TEST:10.372 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 10 00:06:03.089: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-7d4ff
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-vvsw
STEP: Creating a pod to test atomic-volume-subpath
Jan 10 00:06:03.333: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-vvsw" in namespace "e2e-tests-subpath-7d4ff" to be "success or failure"
Jan 10 00:06:03.338: INFO: Pod "pod-subpath-test-downwardapi-vvsw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.267529ms
Jan 10 00:06:05.342: INFO: Pod "pod-subpath-test-downwardapi-vvsw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008574295s
Jan 10 00:06:07.345: INFO: Pod "pod-subpath-test-downwardapi-vvsw": Phase="Running", Reason="", readiness=false. Elapsed: 4.012177801s
Jan 10 00:06:09.350: INFO: Pod "pod-subpath-test-downwardapi-vvsw": Phase="Running", Reason="", readiness=false. Elapsed: 6.016255695s
Jan 10 00:06:11.355: INFO: Pod "pod-subpath-test-downwardapi-vvsw": Phase="Running", Reason="", readiness=false. Elapsed: 8.02139949s
Jan 10 00:06:13.358: INFO: Pod "pod-subpath-test-downwardapi-vvsw": Phase="Running", Reason="", readiness=false. Elapsed: 10.024473823s
Jan 10 00:06:15.365: INFO: Pod "pod-subpath-test-downwardapi-vvsw": Phase="Running", Reason="", readiness=false. Elapsed: 12.03139988s
Jan 10 00:06:17.368: INFO: Pod "pod-subpath-test-downwardapi-vvsw": Phase="Running", Reason="", readiness=false. Elapsed: 14.035124223s
Jan 10 00:06:19.373: INFO: Pod "pod-subpath-test-downwardapi-vvsw": Phase="Running", Reason="", readiness=false. Elapsed: 16.039198094s
Jan 10 00:06:21.377: INFO: Pod "pod-subpath-test-downwardapi-vvsw": Phase="Running", Reason="", readiness=false. Elapsed: 18.043267932s
Jan 10 00:06:23.381: INFO: Pod "pod-subpath-test-downwardapi-vvsw": Phase="Running", Reason="", readiness=false. Elapsed: 20.047919012s
Jan 10 00:06:25.384: INFO: Pod "pod-subpath-test-downwardapi-vvsw": Phase="Running", Reason="", readiness=false. Elapsed: 22.050562448s
Jan 10 00:06:27.387: INFO: Pod "pod-subpath-test-downwardapi-vvsw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.053913028s
STEP: Saw pod success
Jan 10 00:06:27.387: INFO: Pod "pod-subpath-test-downwardapi-vvsw" satisfied condition "success or failure"
Jan 10 00:06:27.390: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-subpath-test-downwardapi-vvsw container test-container-subpath-downwardapi-vvsw: <nil>
STEP: delete the pod
Jan 10 00:06:27.417: INFO: Waiting for pod pod-subpath-test-downwardapi-vvsw to disappear
Jan 10 00:06:27.419: INFO: Pod pod-subpath-test-downwardapi-vvsw no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-vvsw
Jan 10 00:06:27.419: INFO: Deleting pod "pod-subpath-test-downwardapi-vvsw" in namespace "e2e-tests-subpath-7d4ff"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 10 00:06:27.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-7d4ff" for this suite.
Jan 10 00:06:33.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 10 00:06:33.503: INFO: namespace: e2e-tests-subpath-7d4ff, resource: bindings, ignored listing per whitelist
Jan 10 00:06:33.528: INFO: namespace e2e-tests-subpath-7d4ff deletion completed in 6.101782856s

• [SLOW TEST:30.440 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 10 00:06:33.531: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-6bgnf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 10 00:06:33.723: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 10 00:06:37.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-6bgnf" for this suite.
Jan 10 00:06:43.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 10 00:06:43.838: INFO: namespace: e2e-tests-init-container-6bgnf, resource: bindings, ignored listing per whitelist
Jan 10 00:06:43.930: INFO: namespace e2e-tests-init-container-6bgnf deletion completed in 6.155712813s

• [SLOW TEST:10.399 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 10 00:06:43.931: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-qwwd9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 10 00:06:52.429: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 10 00:06:52.437: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 10 00:06:54.438: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 10 00:06:54.446: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 10 00:06:56.438: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 10 00:06:56.443: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 10 00:06:58.438: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 10 00:06:58.441: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 10 00:07:00.438: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 10 00:07:00.441: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 10 00:07:02.438: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 10 00:07:02.442: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 10 00:07:04.438: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 10 00:07:04.441: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 10 00:07:06.438: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 10 00:07:06.441: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 10 00:07:08.438: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 10 00:07:08.441: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 10 00:07:10.438: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 10 00:07:10.442: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 10 00:07:12.438: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 10 00:07:12.441: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 10 00:07:14.438: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 10 00:07:14.441: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 10 00:07:16.438: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 10 00:07:16.441: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 10 00:07:18.438: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 10 00:07:18.442: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 10 00:07:18.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-qwwd9" for this suite.
Jan 10 00:07:40.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 10 00:07:40.519: INFO: namespace: e2e-tests-container-lifecycle-hook-qwwd9, resource: bindings, ignored listing per whitelist
Jan 10 00:07:40.545: INFO: namespace e2e-tests-container-lifecycle-hook-qwwd9 deletion completed in 22.091028208s

• [SLOW TEST:56.614 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 10 00:07:40.545: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-fvjtb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 10 00:07:40.745: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jan 10 00:07:40.762: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 10 00:07:45.766: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 10 00:07:45.766: INFO: Creating deployment "test-rolling-update-deployment"
Jan 10 00:07:45.772: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jan 10 00:07:45.779: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jan 10 00:07:47.786: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jan 10 00:07:47.789: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682675665, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682675665, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63682675665, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63682675665, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 10 00:07:49.793: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 10 00:07:49.804: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-fvjtb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fvjtb/deployments/test-rolling-update-deployment,UID:c1d77d86-146b-11e9-9de1-005056902d46,ResourceVersion:28019,Generation:1,CreationTimestamp:2019-01-10 00:07:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-10 00:07:45 +0000 UTC 2019-01-10 00:07:45 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-10 00:07:47 +0000 UTC 2019-01-10 00:07:45 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 10 00:07:49.807: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-fvjtb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fvjtb/replicasets/test-rolling-update-deployment-65b7695dcf,UID:c1da47ae-146b-11e9-9de1-005056902d46,ResourceVersion:28010,Generation:1,CreationTimestamp:2019-01-10 00:07:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment c1d77d86-146b-11e9-9de1-005056902d46 0xc422a98d27 0xc422a98d28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 10 00:07:49.807: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jan 10 00:07:49.807: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-fvjtb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fvjtb/replicasets/test-rolling-update-controller,UID:bed99436-146b-11e9-9de1-005056902d46,ResourceVersion:28018,Generation:2,CreationTimestamp:2019-01-10 00:07:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment c1d77d86-146b-11e9-9de1-005056902d46 0xc422a98bee 0xc422a98bef}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 10 00:07:49.811: INFO: Pod "test-rolling-update-deployment-65b7695dcf-dr7mb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-dr7mb,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-fvjtb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fvjtb/pods/test-rolling-update-deployment-65b7695dcf-dr7mb,UID:c1db9ec1-146b-11e9-9de1-005056902d46,ResourceVersion:28009,Generation:0,CreationTimestamp:2019-01-10 00:07:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf c1da47ae-146b-11e9-9de1-005056902d46 0xc422a996f7 0xc422a996f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tk6qc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tk6qc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-tk6qc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:362e6945-cc10-4a7c-ad11-8cf4815006e1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422a99760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422a99780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-10 00:07:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-10 00:07:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-10 00:07:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-10 00:07:45 +0000 UTC  }],Message:,Reason:,HostIP:30.0.3.4,PodIP:40.0.6.3,StartTime:2019-01-10 00:07:45 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-10 00:07:47 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://85f06183d8064e15eec36784deb5b89bea58e7291711e638fbf53c07b4b85dbd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 10 00:07:49.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-fvjtb" for this suite.
Jan 10 00:07:55.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 10 00:07:55.852: INFO: namespace: e2e-tests-deployment-fvjtb, resource: bindings, ignored listing per whitelist
Jan 10 00:07:55.925: INFO: namespace e2e-tests-deployment-fvjtb deletion completed in 6.107794921s

• [SLOW TEST:15.380 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 10 00:07:55.926: INFO: >>> kubeConfig: /tmp/kubeconfig-076648363
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-7z4xc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 10 00:07:56.127: INFO: Waiting up to 5m0s for pod "pod-c80167f1-146b-11e9-a046-02505600000d" in namespace "e2e-tests-emptydir-7z4xc" to be "success or failure"
Jan 10 00:07:56.129: INFO: Pod "pod-c80167f1-146b-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.377518ms
Jan 10 00:07:58.132: INFO: Pod "pod-c80167f1-146b-11e9-a046-02505600000d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00577238s
Jan 10 00:08:00.138: INFO: Pod "pod-c80167f1-146b-11e9-a046-02505600000d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010912105s
STEP: Saw pod success
Jan 10 00:08:00.138: INFO: Pod "pod-c80167f1-146b-11e9-a046-02505600000d" satisfied condition "success or failure"
Jan 10 00:08:00.141: INFO: Trying to get logs from node 50ed3ea8-4626-444e-b102-822e7e7faeed pod pod-c80167f1-146b-11e9-a046-02505600000d container test-container: <nil>
STEP: delete the pod
Jan 10 00:08:00.163: INFO: Waiting for pod pod-c80167f1-146b-11e9-a046-02505600000d to disappear
Jan 10 00:08:00.166: INFO: Pod pod-c80167f1-146b-11e9-a046-02505600000d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 10 00:08:00.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7z4xc" for this suite.
Jan 10 00:08:06.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 10 00:08:06.244: INFO: namespace: e2e-tests-emptydir-7z4xc, resource: bindings, ignored listing per whitelist
Jan 10 00:08:06.265: INFO: namespace e2e-tests-emptydir-7z4xc deletion completed in 6.095035379s

• [SLOW TEST:10.340 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
Jan 10 00:08:06.266: INFO: Running AfterSuite actions on all node
Jan 10 00:08:06.266: INFO: Running AfterSuite actions on node 1
Jan 10 00:08:06.266: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5407.856 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h30m8.678299159s
Test Suite Passed
